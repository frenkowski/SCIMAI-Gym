{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**TITLE:** SCIMAI Gym  \n",
    "**AUTHOR:** Francesco Stranieri  \n",
    "**INSTITUTION:** Polytechnic of Turin/University of Milano-Bicocca  \n",
    "**EMAIL:** *francesco.stranieri@unimib.it*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[The MIT License (MIT)](https://github.com/frenkowski/SCIMAI-Gym/blob/main/LICENSE)\n",
    "\n",
    "Copyright (c) 2023 Francesco Stranieri"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code inspired by hands-on tutorial ['Deep reinforcement learning for supply chain and price optimization'](https://blog.griddynamics.com/deep-reinforcement-learning-for-supply-chain-and-price-optimization/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "VEoTunnryTUu"
   },
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T14:18:57.915743Z",
     "start_time": "2023-03-05T14:18:52.283718Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OpenAI Gym is a toolkit for developing and comparing Reinforcement Learning\n",
    "algorithms.\n",
    "https://www.gymlibrary.dev/\n",
    "\"\"\"\n",
    "%pip install -U gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T14:19:01.870692Z",
     "start_time": "2023-03-05T14:18:57.921428Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ray provides a simple, universal API for building distributed applications.\n",
    "For accelerating Machine Learning workloads, Ray is packaged with:\n",
    "- RLlib: a Scalable Reinforcement Learning library;\n",
    "- Tune: a Scalable Hyperparameter Tuning library.\n",
    "https://ray.io/\n",
    "\"\"\"\n",
    "%pip install \"ray==2.3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T14:19:45.980844Z",
     "start_time": "2023-03-05T14:19:01.878237Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ax is a platform for optimizing any kind of experiment, including Machine\n",
    "Learning experiments, A/B tests, and simulations. Ax can optimize discrete\n",
    "configurations (e.g., variants of an A/B test) using multi-armed bandit\n",
    "optimization, and continuous (e.g., integer or floating point)-valued\n",
    "configurations using Bayesian optimization.\n",
    "https://ax.dev/\n",
    "\"\"\"\n",
    "%pip install -U ax-platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T14:19:55.016049Z",
     "start_time": "2023-03-05T14:19:45.984554Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Google Optimization Tools (a.k.a., OR-Tools) is an open-source, fast and\n",
    "portable software suite for solving combinatorial optimization problems.\n",
    "After modeling the problem in the programming language of choice, it is\n",
    "possible to use any of a half dozen solvers to solve it: commercial solvers\n",
    "such as Gurobi or open-source solvers such as SCIP.\n",
    "https://developers.google.com/optimization\n",
    "\"\"\"\n",
    "%pip install -U ortools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T14:21:06.711858Z",
     "start_time": "2023-03-05T14:19:55.023011Z"
    }
   },
   "outputs": [],
   "source": [
    "# for embedding pandas DataFrames as images\n",
    "%pip install -U dataframe_image\n",
    "# for working with nested data structures\n",
    "%pip install -U dm-tree\n",
    "# for developing and comparing reinforcement learning algorithms\n",
    "%pip install -U gymnasium\n",
    "# for generating static images\n",
    "%pip install -U kaleido\n",
    "# for processing XML and HTML\n",
    "%pip install -U lxml\n",
    "# interface for the LZ4 compression library\n",
    "%pip install -U lz4\n",
    "# for creating publication-quality figures\n",
    "%pip install -U matplotlib\n",
    "# for studying graphs and networks\n",
    "%pip install -U networkx[default]\n",
    "# for scientific computing\n",
    "%pip install -U numpy\n",
    "# for handling DOT language files\n",
    "%pip install -U pydot\n",
    "# data analysis and manipulation tool\n",
    "%pip install -U pandas\n",
    "# for making statistical graphics\n",
    "%pip install -U seaborn\n",
    "# pretty-print tabular data\n",
    "%pip install -U tabulate\n",
    "# Tune automatically outputs TensorBoard files\n",
    "%pip install -U tensorboardx\n",
    "# for getting the GPU status\n",
    "%pip install -U GPUtil\n",
    "# for building expressive and extensible templates\n",
    "%pip install -U Jinja2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-05T14:21:07.626488Z",
     "start_time": "2023-03-05T14:21:06.714629Z"
    }
   },
   "outputs": [],
   "source": [
    "# required to use Tune with Python >= 3.7\n",
    "import sys\n",
    "\n",
    "version_info = sys.version_info\n",
    "print(f\"Python version is {version_info}\")\n",
    "\n",
    "if sys.version_info >= (3, 7):\n",
    "    %pip uninstall -y dataclasses\n",
    "else:\n",
    "    %pip install  dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-05T14:18:52.308Z"
    }
   },
   "outputs": [],
   "source": [
    "# a hack to force the runtime to restart, needed to include the above\n",
    "# dependencies\n",
    "import os\n",
    "\n",
    "os._exit(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "rjl7Ka3XyjoD"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:25.215720Z",
     "start_time": "2023-03-29T11:14:25.212542Z"
    },
    "gather": {
     "logged": 1633592872064
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "MhOyL_TDJ2iO"
   },
   "outputs": [],
   "source": [
    "# Python logging\n",
    "import logging\n",
    "\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger('LOGGING_SCIMAI-Gym_V5')\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:26.566201Z",
     "start_time": "2023-03-29T11:14:25.222835Z"
    },
    "gather": {
     "logged": 1633592872889
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "spDLrcrkpn7o"
   },
   "outputs": [],
   "source": [
    "# importing Gym\n",
    "import gymnasium\n",
    "from gymnasium.spaces import Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:29.981395Z",
     "start_time": "2023-03-29T11:14:26.569486Z"
    },
    "gather": {
     "logged": 1633592874996
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "4Tqoqypcf6u_",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# importing Ray\n",
    "import ray.rllib.algorithms.ppo as ppo\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "from ray.tune.stopper import (CombinedStopper,\n",
    "                              MaximumIterationStopper,\n",
    "                              ExperimentPlateauStopper)\n",
    "\n",
    "from ray.rllib.utils import try_import_torch\n",
    "torch = try_import_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:31.271662Z",
     "start_time": "2023-03-29T11:14:29.983610Z"
    },
    "gather": {
     "logged": 1633592877125
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "m5hYuJRv0tSF",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing Ax\n",
    "from ax import optimize\n",
    "\n",
    "from ax.plot.contour import interact_contour, plot_contour_plotly\n",
    "from ax.plot.trace import optimization_trace_single_method_plotly\n",
    "\n",
    "from ax.utils.notebook.plotting import render, init_notebook_plotting\n",
    "init_notebook_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:31.365348Z",
     "start_time": "2023-03-29T11:14:31.276687Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing ortools\n",
    "from ortools.linear_solver import pywraplp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:31.674176Z",
     "start_time": "2023-03-29T11:14:31.367197Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing Gurobi\n",
    "import gurobipy as grb\n",
    "import networkx as nx\n",
    "\n",
    "from networkx.drawing.nx_pydot import graphviz_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.067180Z",
     "start_time": "2023-03-29T11:14:31.676586Z"
    },
    "gather": {
     "logged": 1633592877459
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "IZflD-Ppoqfi"
   },
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import collections\n",
    "import dataframe_image as dfi\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "\n",
    "from datetime import datetime\n",
    "from itertools import chain\n",
    "from tabulate import tabulate\n",
    "from timeit import default_timer\n",
    "from IPython.display import display\n",
    "\n",
    "sns.set_theme(context='paper', style='whitegrid', font_scale=2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.072154Z",
     "start_time": "2023-03-29T11:14:32.069383Z"
    },
    "gather": {
     "logged": 1633592877751
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "# setting seed for reproducibility\n",
    "SEED = 2023\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.076827Z",
     "start_time": "2023-03-29T11:14:32.073899Z"
    },
    "code_folding": [],
    "gather": {
     "logged": 1633592878023
    },
    "hideCode": true,
    "hidePrompt": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# setting output views only in case of debug\n",
    "if logger.level == 10:\n",
    "    VERBOSE = 3\n",
    "    plt.ion()\n",
    "else:\n",
    "    VERBOSE = 0\n",
    "    plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.081936Z",
     "start_time": "2023-03-29T11:14:32.078669Z"
    },
    "gather": {
     "logged": 1633592878307
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "ldKuxKJbf6u_"
   },
   "outputs": [],
   "source": [
    "# getting the number of CPUs\n",
    "import multiprocessing\n",
    "\n",
    "try:\n",
    "    NUM_CPUS = multiprocessing.cpu_count()\n",
    "except Exception as e:\n",
    "    print(f\"{e.__class__} occurred!\")\n",
    "    NUM_CPUS = 0\n",
    "\n",
    "print(f\"num cpus is {NUM_CPUS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.105218Z",
     "start_time": "2023-03-29T11:14:32.086785Z"
    },
    "code_folding": [],
    "gather": {
     "logged": 1633592878585
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "GVf7tvofDhnj"
   },
   "outputs": [],
   "source": [
    "# getting the number of GPUs\n",
    "import GPUtil as GPU\n",
    "\n",
    "try:\n",
    "    NUM_GPUS = len(GPU.getGPUs())\n",
    "except Exception as e:\n",
    "    print(f\"{e.__class__} occurred!\")\n",
    "    NUM_GPUS = 0\n",
    "\n",
    "print(f\"num gpus is {NUM_GPUS}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "xh1UU-78yoU7"
   },
   "source": [
    "# Reinforcement Learning Classes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "BH70DLoUzFRI"
   },
   "source": [
    "## State Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.118040Z",
     "start_time": "2023-03-29T11:14:32.108655Z"
    },
    "gather": {
     "logged": 1633592878862
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "2LVOAZI7pJaB"
   },
   "outputs": [],
   "source": [
    "class State:\n",
    "    \"\"\"\n",
    "    We choose the state vector to include all current stock levels for each\n",
    "    warehouse and product type, plus the last demand values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, product_types_num, distr_warehouses_num, T,\n",
    "                 lead_times, demand_history, t=0):\n",
    "        self.product_types_num = product_types_num\n",
    "        self.factory_stocks = np.zeros(\n",
    "            (self.product_types_num,),\n",
    "            dtype=np.int32)\n",
    "        self.distr_warehouses_num = distr_warehouses_num\n",
    "        self.distr_warehouses_stocks = np.zeros(\n",
    "            (self.distr_warehouses_num, self.product_types_num),\n",
    "            dtype=np.int32)\n",
    "        self.T = T\n",
    "        self.lead_times = lead_times\n",
    "        self.demand_history = demand_history\n",
    "        self.t = t\n",
    "\n",
    "        logger.debug(f\"\\n--- State --- __init__\"\n",
    "                     f\"\\nproduct_types_num is \"\n",
    "                     f\"{self.product_types_num}\"\n",
    "                     f\"\\nfactory_stocks is \"\n",
    "                     f\"{self.factory_stocks}\"\n",
    "                     f\"\\ndistr_warehouses_num is \"\n",
    "                     f\"{self.distr_warehouses_num}\"\n",
    "                     f\"\\ndistr_warehouses_stocks is \"\n",
    "                     f\"{self.distr_warehouses_stocks}\"\n",
    "                     f\"\\nT is \"\n",
    "                     f\"{self.T}\"\n",
    "                     f\"\\nlead_times is \"\n",
    "                     f\"{self.lead_times}\"\n",
    "                     f\"\\ndemand_history is \"\n",
    "                     f\"{self.demand_history}\"\n",
    "                     f\"\\nt is \"\n",
    "                     f\"{self.t}\")\n",
    "\n",
    "    def to_array(self):\n",
    "        if len(self.lead_times) > 0:\n",
    "            logger.debug(\n",
    "                f\"\\n--- State --- to_array\"\n",
    "                f\"\\nnp.concatenate is \"\n",
    "                f\"\"\"{np.concatenate((\n",
    "                    self.factory_stocks,\n",
    "                    np.hstack(list(chain(*chain(*self.lead_times)))),\n",
    "                    self.distr_warehouses_stocks.flatten(),\n",
    "                    np.hstack(list(chain(*chain(*self.demand_history)))),\n",
    "                    [self.t]))}\"\"\")\n",
    "\n",
    "            return np.concatenate((\n",
    "                self.factory_stocks,\n",
    "                np.hstack(list(chain(*chain(*self.lead_times)))),\n",
    "                self.distr_warehouses_stocks.flatten(),\n",
    "                np.hstack(list(chain(*chain(*self.demand_history)))),\n",
    "                [self.t]))\n",
    "        else:\n",
    "            logger.debug(\n",
    "                f\"\\n--- State --- to_array\"\n",
    "                f\"\\nnp.concatenate is \"\n",
    "                f\"\"\"{np.concatenate((\n",
    "                     self.factory_stocks,\n",
    "                     self.distr_warehouses_stocks.flatten(),\n",
    "                     np.hstack(list(chain(*chain(*self.demand_history)))),\n",
    "                     [self.t]))}\"\"\")\n",
    "\n",
    "            return np.concatenate((\n",
    "                self.factory_stocks,\n",
    "                self.distr_warehouses_stocks.flatten(),\n",
    "                np.hstack(list(chain(*chain(*self.demand_history)))),\n",
    "                [self.t]))\n",
    "\n",
    "    def stock_levels(self):\n",
    "        logger.debug(f\"\\n--- State --- stock_levels\"\n",
    "                     f\"\\nnp.concatenate is \"\n",
    "                     f\"\"\"{np.concatenate((\n",
    "                         self.factory_stocks,\n",
    "                         self.distr_warehouses_stocks.flatten()))}\"\"\")\n",
    "\n",
    "        return np.concatenate((\n",
    "            self.factory_stocks,\n",
    "            self.distr_warehouses_stocks.flatten()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "C9uyi5YKzKkB"
   },
   "source": [
    "## Action Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.123472Z",
     "start_time": "2023-03-29T11:14:32.119899Z"
    },
    "gather": {
     "logged": 1633592879156
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "3vmjf1wf6J6q"
   },
   "outputs": [],
   "source": [
    "class Action:\n",
    "    \"\"\"\n",
    "    The action vector consists of production and shipping controls.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, product_types_num, distr_warehouses_num):\n",
    "        self.production_level = np.zeros(\n",
    "            (product_types_num,),\n",
    "            dtype=np.int32)\n",
    "        self.shipped_stocks = np.zeros(\n",
    "            (distr_warehouses_num, product_types_num),\n",
    "            dtype=np.int32)\n",
    "\n",
    "        logger.debug(f\"\\n--- Action --- __init__\"\n",
    "                     f\"\\nproduction_level is \"\n",
    "                     f\"{self.production_level}\"\n",
    "                     f\"\\nshipped_stocks is \"\n",
    "                     f\"{self.shipped_stocks}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "dV01Of0pzOmi"
   },
   "source": [
    "## Supply Chain Environment Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupplyChainEnvironment:\n",
    "    \"\"\"\n",
    "    We designed a divergent two-echelon supply chain that includes a single\n",
    "    factory, multiple distribution warehouses, and multiple product types over\n",
    "    a fixed number of time steps. At each time step, the agent is asked to find\n",
    "    the number of products to be produced and preserved at the factory, as well\n",
    "    as the number of products to be shipped to different distribution\n",
    "    warehouses. To make the supply chain more realistic, we set capacity\n",
    "    constraints on warehouses (and consequently, on how many units to produce\n",
    "    at the factory), along with storage and transportation costs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, seed=SEED):\n",
    "        # number of product types (e.g., 2 product types)\n",
    "        self.product_types_num = 1\n",
    "        # number of distribution warehouses (e.g., 2 distribution warehouses)\n",
    "        self.distr_warehouses_num = 2\n",
    "\n",
    "        # lead times length, time steps (e.g., 5)\n",
    "        self.lead_times_len = 0\n",
    "        # final time step (e.g., an episode takes 25 time steps)\n",
    "        self.T = 7+(2*self.lead_times_len)\n",
    "\n",
    "        # type of demand (e.g., 'stationary', 'probabilistic', 'stochastic')\n",
    "        self.demand_type = 'probabilistic'\n",
    "        # maximum demand value, units (e.g., [3, 6])\n",
    "        self.d_max = np.array(\n",
    "            [5],\n",
    "            np.int32)\n",
    "        # maximum demand variation according to a uniform distribution,\n",
    "        # units (e.g., [2])\n",
    "        self.d_var = np.array(\n",
    "            [5],\n",
    "            np.int32)\n",
    "\n",
    "        # sale prices, per unit (e.g., [20, 10])\n",
    "        self.sale_prices = np.array(\n",
    "            [0],\n",
    "            np.int32)\n",
    "        # production costs, per unit (e.g., [2, 1])\n",
    "        self.production_costs = np.array(\n",
    "            [1],\n",
    "            np.int32)\n",
    "\n",
    "        # storage capacities for each product type at each warehouse,\n",
    "        # units (e.g., [[3, 4], [6, 8], [9, 12]])\n",
    "        self.storage_capacities = np.array(\n",
    "            [[20], [10], [10]],\n",
    "            np.int32)\n",
    "        # storage costs of each product type at each warehouse,\n",
    "        # per unit (e.g., [[6, 3], [4, 2], [2, 1]])\n",
    "        self.storage_costs = np.array(\n",
    "            [[.1], [1], [1]],\n",
    "            np.float32)\n",
    "        # maximum production level, unit (e.g., [2, 1])\n",
    "        self.prod_level_max = np.array(\n",
    "            [15],\n",
    "            np.int32)\n",
    "\n",
    "        # transportation capacities for each product type at each distribution\n",
    "        # warehouse, units (e.g., [[3, 4], [6, 8]])\n",
    "        self.transportation_capacities = np.array(\n",
    "            [[3], [3]],\n",
    "            np.int32)\n",
    "        # transportation costs for each transportation capacity filled,\n",
    "        # fixed (e.g., [[1, 3], [2, 6]])\n",
    "        self.transportation_costs_fixed = np.array(\n",
    "            [[.7], [.7]],\n",
    "            np.float32)\n",
    "        # transportation costs of each product type for each distribution\n",
    "        # warehouse, per unit (e.g., [[.1, .3], [.2, .6]])\n",
    "        self.transportation_costs_unit = np.array(\n",
    "            [[.03], [.03]],\n",
    "            np.float32)\n",
    "\n",
    "        # penalty costs, per unit (e.g., [10, 5])\n",
    "        self.penalty_costs = 10*self.production_costs\n",
    "        # management of excess demand (e.g., 'backorder', 'lost-sales')\n",
    "        self.excess_demand = 'backorder'\n",
    "\n",
    "        # demand history length, time steps (e.g., 7)\n",
    "        self.demand_history_len = 2\n",
    "\n",
    "        print(f\"\\n--- SupplyChainEnvironment --- __init__\"\n",
    "              f\"\\nproduct_types_num is \"\n",
    "              f\"{self.product_types_num}\"\n",
    "              f\"\\ndistr_warehouses_num is \"\n",
    "              f\"{self.distr_warehouses_num}\"\n",
    "              f\"\\nT is \"\n",
    "              f\"{self.T}\"\n",
    "              f\"\\ndemand_type is \"\n",
    "              f\"{self.demand_type}\"\n",
    "              f\"\\nd_max is \"\n",
    "              f\"{self.d_max}\"\n",
    "              f\"\\nd_var is \"\n",
    "              f\"{self.d_var}\"\n",
    "              f\"\\nsale_prices is \"\n",
    "              f\"{self.sale_prices}\"\n",
    "              f\"\\nproduction_costs is \"\n",
    "              f\"{self.production_costs}\"\n",
    "              f\"\\nstorage_capacities is \"\n",
    "              f\"{self.storage_capacities}\"\n",
    "              f\"\\nstorage_costs is \"\n",
    "              f\"{self.storage_costs}\"\n",
    "              f\"\\nprod_level_max is \"\n",
    "              f\"{self.prod_level_max}\"\n",
    "              f\"\\ntransportation_capacities is \"\n",
    "              f\"{self.transportation_capacities}\"\n",
    "              f\"\\ntransportation_costs_fixed is \"\n",
    "              f\"{self.transportation_costs_fixed}\"\n",
    "              f\"\\ntransportation_costs_unit is \"\n",
    "              f\"{self.transportation_costs_unit}\"\n",
    "              f\"\\npenalty_costs is \"\n",
    "              f\"{self.penalty_costs}\"\n",
    "              f\"\\nexcess_demand is \"\n",
    "              f\"{self.excess_demand}\"\n",
    "              f\"\\nlead_times_len is \"\n",
    "              f\"{self.lead_times_len}\"\n",
    "              f\"\\ndemand_history_len is \"\n",
    "              f\"{self.demand_history_len}\")\n",
    "\n",
    "        self.reset(seed=seed)\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        if seed:\n",
    "            self.demand_random_generator = np.random.default_rng(seed=seed)\n",
    "\n",
    "        self.lead_times = collections.deque(maxlen=self.lead_times_len)\n",
    "        self.demand_history = collections.deque(maxlen=self.demand_history_len)\n",
    "\n",
    "        logger.debug(f\"\\n--- SupplyChainEnvironment --- reset\"\n",
    "                     f\"\\nlead_times_len is \"\n",
    "                     f\"{self.lead_times_len}\"\n",
    "                     f\"\\ndemand_history_len is \"\n",
    "                     f\"{self.demand_history_len}\"\n",
    "                     f\"\\nlead_times is \"\n",
    "                     f\"{self.lead_times}\"\n",
    "                     f\"\\ndemand_history is \"\n",
    "                     f\"{self.demand_history}\")\n",
    "\n",
    "        if self.lead_times_len > 0:\n",
    "            for l in range(self.lead_times_len):\n",
    "                self.lead_times.appendleft(np.zeros(\n",
    "                    (self.distr_warehouses_num, self.product_types_num),\n",
    "                    dtype=np.int32))\n",
    "\n",
    "        for d in range(self.demand_history_len):\n",
    "            self.demand_history.append(np.zeros(\n",
    "                (self.distr_warehouses_num, self.product_types_num),\n",
    "                dtype=np.int32))\n",
    "        self.t = 0\n",
    "\n",
    "        logger.debug(f\"\\nlead_times is \"\n",
    "                     f\"{self.lead_times}\"\n",
    "                     f\"\\ndemand_history is \"\n",
    "                     f\"{self.demand_history}\"\n",
    "                     f\"\\nt is \"\n",
    "                     f\"{self.t}\")\n",
    "\n",
    "\n",
    "    def generate_demand(self, t):\n",
    "        if self.demand_type == 'stationary':\n",
    "            demands = np.fromfunction(\n",
    "                lambda j, i: self.stationary_demand(j+1, i+1, t),\n",
    "                (self.distr_warehouses_num, self.product_types_num),\n",
    "                dtype=np.int32)\n",
    "        elif self.demand_type == 'probabilistic':\n",
    "            demands = np.fromfunction(\n",
    "                lambda j, i: self.stationary_demand(j+1, i+1, t),\n",
    "                (self.distr_warehouses_num, self.product_types_num),\n",
    "                dtype=np.int32) + \\\n",
    "                    self.demand_random_generator.choice(\n",
    "                [0, self.d_var[0]],\n",
    "                p=[.5, .5],\n",
    "                size=(self.distr_warehouses_num,\n",
    "                      self.product_types_num))\n",
    "        elif self.demand_type == 'negbinomial':\n",
    "            demands = np.fromfunction(\n",
    "                lambda j, i: self.stationary_demand(j+1, i+1, t),\n",
    "                (self.distr_warehouses_num, self.product_types_num),\n",
    "                dtype=np.int32) + \\\n",
    "                    self.demand_random_generator.negative_binomial(\n",
    "                self.d_var[0],\n",
    "                .7,\n",
    "                size=(self.distr_warehouses_num,\n",
    "                      self.product_types_num))\n",
    "        elif self.demand_type == 'stochastic':\n",
    "            # we simulate a seasonal behavior by representing the demand as\n",
    "            # a co-sinusoidal function with a stochastic component (a\n",
    "            # random variable assumed to be distributed according to a\n",
    "            # uniform distribution), in order to evaluate the agent\n",
    "            demands = np.fromfunction(\n",
    "                lambda j, i: self.stationary_demand(j+1, i+1, t),\n",
    "                (self.distr_warehouses_num, self.product_types_num),\n",
    "                dtype=np.int32) + \\\n",
    "                self.demand_random_generator.integers(\n",
    "                0, self.d_var[0]+1,\n",
    "                size=(self.distr_warehouses_num,\n",
    "                      self.product_types_num))\n",
    "            \n",
    "        return demands\n",
    "\n",
    "\n",
    "    def generate_episode_demands(self):\n",
    "        demands_episode = []\n",
    "        for t in range(self.T):\n",
    "            if (t < self.lead_times_len):\n",
    "                demands = np.zeros(\n",
    "                    (self.distr_warehouses_num, self.product_types_num),\n",
    "                    dtype=np.int32)\n",
    "            else:\n",
    "                demands = self.generate_demand(t)\n",
    "            demands_episode.append(demands)\n",
    "\n",
    "        demands_episode = np.array(demands_episode)\n",
    "        \n",
    "        return demands_episode\n",
    "\n",
    "    def stationary_demand(self, j, i, t):\n",
    "        # we simulate a seasonal behavior by representing the demand as a\n",
    "        # co-sinusoidal function\n",
    "        demand = np.round(\n",
    "            self.d_max[i-1]/2 +\n",
    "            self.d_max[i-1]/2*np.sin(-5*np.pi*(t)/self.T))\n",
    "\n",
    "        logger.debug(f\"\\n--- SupplyChainEnvironment --- stationary_demand\"\n",
    "                     f\"\\nj is \"\n",
    "                     f\"{j}\"\n",
    "                     f\"\\ni is \"\n",
    "                     f\"{i}\"\n",
    "                     f\"\\nt is \"\n",
    "                     f\"{t}\"\n",
    "                     f\"\\ndemand is \"\n",
    "                     f\"{demand}\")\n",
    "\n",
    "        return demand\n",
    "\n",
    "    def initial_state(self):\n",
    "        logger.debug(f\"\\n--- SupplyChainEnvironment --- initial_state\"\n",
    "                     f\"\\nState is \"\n",
    "                     f\"\"\"{State(\n",
    "                         self.product_types_num, self.distr_warehouses_num,\n",
    "                         self.T,\n",
    "                         list(self.lead_times),\n",
    "                         list(self.demand_history))}\"\"\")\n",
    "\n",
    "        return State(self.product_types_num, self.distr_warehouses_num,\n",
    "                     self.T, list(self.lead_times), list(self.demand_history))\n",
    "\n",
    "    def step(self, state, action):\n",
    "        if (self.t < self.lead_times_len):\n",
    "            demands = np.zeros(\n",
    "                (self.distr_warehouses_num, self.product_types_num),\n",
    "                dtype=np.int32)\n",
    "        else:\n",
    "            demands = self.generate_demand(self.t)\n",
    "            \n",
    "        logger.debug(f\"\\n--- SupplyChainEnvironment --- step\"\n",
    "                     f\"\\nstate is \"\n",
    "                     f\"{state}\"\n",
    "                     f\"\\nstate.factory_stocks is \"\n",
    "                     f\"{state.factory_stocks}\"\n",
    "                     f\"\\nstate.distr_warehouses_stocks is \"\n",
    "                     f\"{state.distr_warehouses_stocks}\"\n",
    "                     f\"\\naction is \"\n",
    "                     f\"{action}\"\n",
    "                     f\"\\naction.production_level is \"\n",
    "                     f\"{action.production_level}\"\n",
    "                     f\"\\naction.shipped_stocks is \"\n",
    "                     f\"{action.shipped_stocks}\"\n",
    "                     f\"\\ndemands is \"\n",
    "                     f\"{demands}\")\n",
    "\n",
    "        # next state\n",
    "        next_state = State(self.product_types_num, self.distr_warehouses_num,\n",
    "                           self.T,\n",
    "                           list(self.lead_times), list(self.demand_history),\n",
    "                           self.t+1)\n",
    "\n",
    "        if self.lead_times_len > 0:\n",
    "            # next state (distribution warehouses)\n",
    "            distr_warehouses_stocks = np.minimum(\n",
    "                np.add(state.distr_warehouses_stocks,\n",
    "                       self.lead_times[self.lead_times_len-1]),\n",
    "                self.storage_capacities[1:])\n",
    "            next_state.distr_warehouses_stocks = np.subtract(\n",
    "                distr_warehouses_stocks,\n",
    "                demands)\n",
    "\n",
    "        # excess_stocks\n",
    "        factory_stocks = np.minimum(\n",
    "            np.add(state.factory_stocks,\n",
    "                   np.minimum(\n",
    "                       action.production_level,\n",
    "                       self.prod_level_max)),\n",
    "            self.storage_capacities[0])\n",
    "\n",
    "        shipped_stocks = np.minimum(\n",
    "            np.maximum(factory_stocks,\n",
    "                       np.zeros(\n",
    "                           (self.product_types_num,),\n",
    "                           dtype=np.int32)),\n",
    "            np.sum(action.shipped_stocks, axis=0))\n",
    "\n",
    "        logger.debug(f\"\\nshipped stocks is \"\n",
    "                     f\"{shipped_stocks}\")\n",
    "\n",
    "        for i in range(self.product_types_num):\n",
    "            if (np.sum(\n",
    "                    action.shipped_stocks, axis=0)[i] >\n",
    "                    shipped_stocks[i]):\n",
    "                j_indexes = np.arange(self.distr_warehouses_num, dtype=int)\n",
    "\n",
    "                while np.sum(\n",
    "                        action.shipped_stocks, axis=0)[i] > shipped_stocks[i]:\n",
    "                    j_index = np.random.choice(j_indexes)\n",
    "                    if action.shipped_stocks[j_index][i] > 0:\n",
    "                        action.shipped_stocks[j_index][i] -= 1\n",
    "                    else:\n",
    "                        j_indexes = j_indexes[j_indexes != j_index]\n",
    "\n",
    "                    logger.debug(f\"\\nt is \"\n",
    "                                 f\"{self.t}\"\n",
    "                                 f\"\\nj_indexes is \"\n",
    "                                 f\"{j_indexes}\"\n",
    "                                 f\"\\nj_index is \"\n",
    "                                 f\"{j_index}\"\n",
    "                                 f\"\\nshipped stocks[i] is \"\n",
    "                                 f\"{shipped_stocks[i]}\"\n",
    "                                 f\"\\naction.shipped_stocks is \"\n",
    "                                 f\"{action.shipped_stocks}\")\n",
    "\n",
    "        # next state (factory)\n",
    "        next_state.factory_stocks = np.subtract(\n",
    "            factory_stocks,\n",
    "            np.sum(action.shipped_stocks, axis=0))\n",
    "\n",
    "        logger.debug(f\"\\n-- SupplyChainEnvironment -- next state\"\n",
    "                     f\"\\naction is \"\n",
    "                     f\"{action}\"\n",
    "                     f\"\\naction.production_level is \"\n",
    "                     f\"{action.production_level}\"\n",
    "                     f\"\\naction.shipped_stocks is \"\n",
    "                     f\"{action.shipped_stocks}\"\n",
    "                     f\"\\nnext_state is \"\n",
    "                     f\"{next_state}\"\n",
    "                     f\"\\nnext_state.factory_stocks is \"\n",
    "                     f\"{next_state.factory_stocks}\"\n",
    "                     f\"\\nnext_state.distr_warehouses_stocks is \"\n",
    "                     f\"{next_state.distr_warehouses_stocks}\"\n",
    "                     f\"\\nnext_state.lead_times is \"\n",
    "                     f\"{next_state.lead_times}\"\n",
    "                     f\"\\nnext_state.demand_history is \"\n",
    "                     f\"{next_state.demand_history}\"\n",
    "                     f\"\\nnext_state.t is \"\n",
    "                     f\"{next_state.t}\")\n",
    "\n",
    "        if self.lead_times_len > 0:\n",
    "            self.lead_times.appendleft(action.shipped_stocks)\n",
    "        else:\n",
    "            distr_warehouses_stocks = np.minimum(\n",
    "                np.add(state.distr_warehouses_stocks,\n",
    "                       action.shipped_stocks),\n",
    "                self.storage_capacities[1:])\n",
    "            next_state.distr_warehouses_stocks = np.subtract(\n",
    "                distr_warehouses_stocks,\n",
    "                demands)\n",
    "\n",
    "        # the actual demand for the current time step will not be known until\n",
    "        # the next time step. This implementation choice ensures that the agent\n",
    "        # may benefit from learning the demand pattern so as to integrate a\n",
    "        # sort of demand forecasting directly into the policy\n",
    "        self.demand_history.append(demands)\n",
    "        # actual time step value is (not) observed (for now)\n",
    "        self.t += 1\n",
    "\n",
    "        logger.debug(f\"\\nlead_times is \"\n",
    "                     f\"{self.lead_times}\"\n",
    "                     f\"\\ndemand_history is \"\n",
    "                     f\"{self.demand_history}\"\n",
    "                     f\"\\nt is \"\n",
    "                     f\"{self.t}\")\n",
    "\n",
    "        # revenues\n",
    "        unsatisfied_demands = np.zeros(\n",
    "            (self.distr_warehouses_num, self.product_types_num),\n",
    "            dtype=np.int32)\n",
    "        for i in range(self.product_types_num):\n",
    "            for j in range(self.distr_warehouses_num):\n",
    "                if (distr_warehouses_stocks[j][i] >= 0 and\n",
    "                        next_state.distr_warehouses_stocks[j][i] < 0):\n",
    "                    unsatisfied_demands[j][i] = np.abs(\n",
    "                        next_state.distr_warehouses_stocks[j][i])\n",
    "                elif (distr_warehouses_stocks[j][i] < 0 and\n",
    "                        next_state.distr_warehouses_stocks[j][i] < 0):\n",
    "                    unsatisfied_demands[j][i] = demands[j][i]\n",
    "\n",
    "        total_revenues = np.dot(\n",
    "            self.sale_prices,\n",
    "            np.sum(np.subtract(demands,\n",
    "                               unsatisfied_demands), axis=0))\n",
    "        # production costs\n",
    "        total_production_costs = np.dot(self.production_costs,\n",
    "                                        action.production_level)\n",
    "        # transportation costs fixed\n",
    "        total_transportation_costs_fixed = np.dot(\n",
    "            np.ceil(np.divide(action.shipped_stocks,\n",
    "                              self.transportation_capacities)).flatten(),\n",
    "            self.transportation_costs_fixed.flatten())\n",
    "        # transportation costs unit\n",
    "        total_transportation_costs_unit = np.dot(\n",
    "            self.transportation_costs_unit.flatten(),\n",
    "            action.shipped_stocks.flatten())\n",
    "        # transportation costs\n",
    "        total_transportation_costs = np.add(total_transportation_costs_fixed,\n",
    "                                            total_transportation_costs_unit)\n",
    "        # storage costs\n",
    "        total_storage_costs = np.dot(\n",
    "            self.storage_costs.flatten(),\n",
    "            np.maximum(next_state.stock_levels(),\n",
    "                       np.zeros(\n",
    "                           ((self.distr_warehouses_num+1) *\n",
    "                            self.product_types_num),\n",
    "                           dtype=np.int32)\n",
    "                       )\n",
    "        )\n",
    "        # penalty costs (minus sign because stock levels would be already\n",
    "        # negative in case of unfulfilled demand)\n",
    "        total_penalty_costs = -np.dot(\n",
    "            self.penalty_costs,\n",
    "            np.add(\n",
    "                np.sum(\n",
    "                    np.minimum(next_state.distr_warehouses_stocks,\n",
    "                               np.zeros(\n",
    "                                   (self.distr_warehouses_num,\n",
    "                                    self.product_types_num),\n",
    "                                   dtype=np.int32)\n",
    "                               ),\n",
    "                    axis=0),\n",
    "                np.minimum(next_state.factory_stocks,\n",
    "                           np.zeros(\n",
    "                               (self.product_types_num,),\n",
    "                               dtype=np.int32)\n",
    "                           )\n",
    "            )\n",
    "        )\n",
    "        # reward function\n",
    "        reward = total_revenues - total_production_costs - \\\n",
    "            total_transportation_costs - total_storage_costs - \\\n",
    "            total_penalty_costs\n",
    "\n",
    "        logger.debug(f\"\\n-- SupplyChainEnvironment -- reward\"\n",
    "                     f\"\\ntotal_revenues is \"\n",
    "                     f\"{total_revenues}\"\n",
    "                     f\"\\ntotal_production_costs is \"\n",
    "                     f\"{total_production_costs}\"\n",
    "                     f\"\\ntotal_transportation_costs_fixed is \"\n",
    "                     f\"{total_transportation_costs_fixed}\"\n",
    "                     f\"\\ntotal_transportation_costs_unit is \"\n",
    "                     f\"{total_transportation_costs_unit}\"\n",
    "                     f\"\\ntotal_transportation_costs is \"\n",
    "                     f\"{total_transportation_costs}\"\n",
    "                     f\"\\ntotal_storage_costs is \"\n",
    "                     f\"{total_storage_costs}\"\n",
    "                     f\"\\ntotal_penalty_costs is \"\n",
    "                     f\"{total_penalty_costs}\"\n",
    "                     f\"\\nreward is \"\n",
    "                     f\"{reward}\")\n",
    "\n",
    "        if self.excess_demand == 'lost-sales':\n",
    "            next_state.distr_warehouses_stocks = np.maximum(\n",
    "                next_state.distr_warehouses_stocks,\n",
    "                np.zeros(\n",
    "                    (self.distr_warehouses_num,\n",
    "                     self.product_types_num),\n",
    "                    dtype=np.int32))\n",
    "\n",
    "        logger.debug(f\"\\n-- SupplyChainEnvironment -- return\"\n",
    "                     f\"\\nnext_state is \"\n",
    "                     f\"{next_state}, \"\n",
    "                     f\"\\nreward is \"\n",
    "                     f\"{reward}, \"\n",
    "                     f\"\\ndone is \"\n",
    "                     f\"{self.t == self.T-1}\")\n",
    "\n",
    "        return next_state, reward, self.t == self.T-1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "BLU1e41QzUfw"
   },
   "source": [
    "## Supply Chain Gym Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.176285Z",
     "start_time": "2023-03-29T11:14:32.162937Z"
    }
   },
   "outputs": [],
   "source": [
    "class SupplyChain(gymnasium.Env):\n",
    "    \"\"\"\n",
    "    Gym environment wrapper.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.supply_chain = SupplyChainEnvironment()\n",
    "        self.reset()\n",
    "\n",
    "        # space size\n",
    "        factory_size = self.supply_chain.product_types_num\n",
    "        lead_times_size = (self.supply_chain.lead_times_len *\n",
    "                           self.supply_chain.distr_warehouses_num *\n",
    "                           self.supply_chain.product_types_num)\n",
    "        distr_warehouses_size = (self.supply_chain.distr_warehouses_num *\n",
    "                                 self.supply_chain.product_types_num)\n",
    "\n",
    "        # low values for action space (no negative actions)\n",
    "        low_act = np.zeros(\n",
    "            ((self.supply_chain.distr_warehouses_num+1) *\n",
    "             self.supply_chain.product_types_num),\n",
    "            dtype=np.int32)\n",
    "        # high values for action space\n",
    "        high_act = np.zeros(\n",
    "            ((self.supply_chain.distr_warehouses_num+1) *\n",
    "             self.supply_chain.product_types_num),\n",
    "            dtype=np.int32)\n",
    "        # high values for action space (factory)\n",
    "        high_act[\n",
    "            :factory_size\n",
    "        ] = self.supply_chain.prod_level_max\n",
    "        # high values for action space (distribution warehouses, according to\n",
    "        # storage capacities)\n",
    "        high_act[\n",
    "            factory_size:\n",
    "        ] = self.supply_chain.storage_capacities.flatten()[\n",
    "            self.supply_chain.product_types_num:]\n",
    "        # action space\n",
    "        self.action_space = Box(low=low_act,\n",
    "                                high=high_act,\n",
    "                                dtype=np.int32)\n",
    "\n",
    "        # low values for observation space\n",
    "        low_obs = np.zeros(\n",
    "            (len(self.supply_chain.initial_state().to_array()),),\n",
    "            dtype=np.int32)\n",
    "        # low values for observation space (distribution warehouses, worst case\n",
    "        # scenario in case of non-shipments and maximum demand)\n",
    "        low_obs[\n",
    "            factory_size+lead_times_size:\n",
    "            factory_size+lead_times_size+distr_warehouses_size\n",
    "        ] = np.array(\n",
    "            [-(self.supply_chain.d_max+self.supply_chain.d_var) *\n",
    "             self.supply_chain.T] *\n",
    "            self.supply_chain.distr_warehouses_num).flatten()\n",
    "        # high values for observation space\n",
    "        high_obs = np.zeros(\n",
    "            (len(self.supply_chain.initial_state().to_array()),),\n",
    "            dtype=np.int32)\n",
    "        # high values for observation space (factory according to storage\n",
    "        # capacities)\n",
    "        high_obs[\n",
    "            :factory_size\n",
    "        ] = self.supply_chain.storage_capacities[:1].flatten()\n",
    "        # high values for observation space (lead times, according to storage\n",
    "        # capacities)\n",
    "        high_obs[\n",
    "            factory_size:\n",
    "            factory_size+lead_times_size\n",
    "        ] = np.repeat(\n",
    "            self.supply_chain.storage_capacities[:1],\n",
    "            self.supply_chain.distr_warehouses_num *\n",
    "            self.supply_chain.lead_times_len)\n",
    "        # high values for observation space (distribution\n",
    "        # warehouses, according to storage capacities)\n",
    "        high_obs[\n",
    "            factory_size+lead_times_size:\n",
    "            factory_size+lead_times_size+distr_warehouses_size\n",
    "        ] = self.supply_chain.storage_capacities[1:].flatten()\n",
    "        # high values for observation space (demand, according to the maximum\n",
    "        # demand value)\n",
    "        high_obs[\n",
    "            factory_size+lead_times_size+distr_warehouses_size:\n",
    "            len(high_obs)-1\n",
    "        ] = np.array(\n",
    "            [self.supply_chain.d_max+self.supply_chain.d_var] *\n",
    "            len(list(chain(*self.supply_chain.demand_history)))).flatten()\n",
    "        # high values for observation space (episode, according to the final\n",
    "        # time step)\n",
    "        high_obs[len(high_obs)-1] = self.supply_chain.T\n",
    "        # observation space\n",
    "        self.observation_space = Box(low=low_obs,\n",
    "                                     high=high_obs,\n",
    "                                     dtype=np.int32)\n",
    "\n",
    "        logger.debug(f\"\\n--- SupplyChain --- __init__\"\n",
    "                     f\"\\nfactory_size is \"\n",
    "                     f\"{factory_size}\"\n",
    "                     f\"\\nlead_times_size is \"\n",
    "                     f\"{lead_times_size}\"\n",
    "                     f\"\\ndistr_warehouses_size is \"\n",
    "                     f\"{distr_warehouses_size}\"\n",
    "                     f\"\\nlow_act is \"\n",
    "                     f\"{low_act}\"\n",
    "                     f\"\\nhigh_act is \"\n",
    "                     f\"{high_act}\"\n",
    "                     f\"\\naction_space is \"\n",
    "                     f\"{self.action_space}\"\n",
    "                     f\"\\nlow_obs is \"\n",
    "                     f\"{low_obs}\"\n",
    "                     f\"\\nhigh_obs is \"\n",
    "                     f\"{high_obs}\"\n",
    "                     f\"\\nobservation_space is \"\n",
    "                     f\"{self.observation_space}\")\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        self.supply_chain.reset(seed)\n",
    "        self.state = self.supply_chain.initial_state()\n",
    "\n",
    "        logger.debug(f\"\\n--- SupplyChain --- reset\"\n",
    "                     f\"\\nsupply_chain is \"\n",
    "                     f\"{self.supply_chain}\"\n",
    "                     f\"\\nstate is \"\n",
    "                     f\"{self.state}\"\n",
    "                     f\"\\nstate.to_array is \"\n",
    "                     f\"{self.state.to_array()}\")\n",
    "\n",
    "        return self.state.to_array()\n",
    "\n",
    "    def step(self, action):\n",
    "        # casting to integer actions (units of product to produce and ship)\n",
    "        action_obj = Action(\n",
    "            self.supply_chain.product_types_num,\n",
    "            self.supply_chain.distr_warehouses_num)\n",
    "        action_obj.production_level = action[\n",
    "            :self.supply_chain.product_types_num].astype(\n",
    "            np.int32)\n",
    "        action_obj.shipped_stocks = action[\n",
    "            self.supply_chain.product_types_num:\n",
    "        ].reshape((self.supply_chain.distr_warehouses_num,\n",
    "                   self.supply_chain.product_types_num)).astype(np.int32)\n",
    "\n",
    "        logger.debug(f\"\\n--- SupplyChain --- step\"\n",
    "                     f\"\\naction is \"\n",
    "                     f\"{action}\"\n",
    "                     f\"\\naction_obj is \"\n",
    "                     f\"{action_obj}\"\n",
    "                     f\"\\naction_obj.production_level is \"\n",
    "                     f\"{action_obj.production_level}\"\n",
    "                     f\"\\naction_obj.shipped_stocks is \"\n",
    "                     f\"{action_obj.shipped_stocks}\")\n",
    "\n",
    "        self.state, reward, done = self.supply_chain.step(\n",
    "            self.state, action_obj)\n",
    "\n",
    "        logger.debug(f\"\\n-- SupplyChain -- return\"\n",
    "                     f\"\\nstate.to_array is \"\n",
    "                     f\"{self.state.to_array()}\"\n",
    "                     f\"\\nreward is \"\n",
    "                     f\"{reward}\"\n",
    "                     f\"\\ndone is \"\n",
    "                     f\"{done}\")\n",
    "\n",
    "        return self.state.to_array(), reward, done, {}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.183578Z",
     "start_time": "2023-03-29T11:14:32.178750Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# supply chain env\n",
    "env = SupplyChainEnvironment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.188291Z",
     "start_time": "2023-03-29T11:14:32.185743Z"
    },
    "gather": {
     "logged": 1633592880059
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "AYTndqzPjsry"
   },
   "outputs": [],
   "source": [
    "# number of episodes for the simulations\n",
    "NUM_EPISODES = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.194672Z",
     "start_time": "2023-03-29T11:14:32.190160Z"
    }
   },
   "outputs": [],
   "source": [
    "# name of the experiment (e.g., '2P2W' stands for two product types and two\n",
    "# distribution warehouses)\n",
    "now = datetime.now()\n",
    "now_str = now.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "local_dir = f\"{env.product_types_num}P{env.distr_warehouses_num}W_{now_str}\"\n",
    "# dir to save plots\n",
    "plots_dir = 'plots'\n",
    "# creating necessary dirs\n",
    "if not os.path.exists(f\"{local_dir}\"):\n",
    "    os.makedirs(f\"{local_dir}\")\n",
    "if not os.path.exists(f\"{local_dir+'/'+plots_dir}\"):\n",
    "    os.makedirs(f\"{local_dir+'/'+plots_dir}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "dWCGN9yMz8T_"
   },
   "source": [
    "# Supply Chain Environment Initialization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "b3FX1yqx5j1r"
   },
   "source": [
    "## Visualize Demand Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_demand(env, num_episodes=1,\n",
    "                     local_dir=local_dir, plots_dir=plots_dir, seed=SEED):\n",
    "    \"\"\"\n",
    "    Visualize demand behavior for each distribution warehouses and for each\n",
    "    product type.\n",
    "    \"\"\"\n",
    "    if env.distr_warehouses_num <= 3 and env.product_types_num <= 2:\n",
    "        # generating demands (MIP solver knows the episodes' demands a priori)\n",
    "        env.reset(seed)\n",
    "        episode_duration = env.T-(2*env.lead_times_len)\n",
    "        demands_episodes = []\n",
    "        for _ in range(num_episodes):\n",
    "            demands_episode = env.generate_episode_demands()\n",
    "            demands_episodes.append(demands_episode)\n",
    "\n",
    "        demands_episodes = np.array(demands_episodes)\n",
    "\n",
    "        # mean of demands\n",
    "        demands_mean = np.array([np.mean(d, axis=0)\n",
    "                                 for d in zip(*demands_episodes)])\n",
    "    \n",
    "        # std of demands\n",
    "        demands_std = np.array([np.std(d, axis=0)\n",
    "                                for d in zip(*demands_episodes)])\n",
    "\n",
    "        logger.debug(f\"\\n-- visualize_demand --\"\n",
    "                     f\"\\ndemands_episodes is \"\n",
    "                     f\"{demands_episodes}\"\n",
    "                     f\"\\ndemands_mean is \"\n",
    "                     f\"{demands_mean}\"\n",
    "                     f\"\\ndemands_std is \"\n",
    "                     f\"{demands_std}\")\n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.xlabel('Time Steps')\n",
    "        plt.ylabel('Demand Value')\n",
    "\n",
    "        plt.xticks(np.arange(1, episode_duration+1))\n",
    "        plt.tick_params(axis='x', which='both',\n",
    "                        top=True, bottom=True,\n",
    "                        labelbottom=True)\n",
    "        plt.ticklabel_format(axis='y', style='plain',\n",
    "                             useOffset=False)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # same color for the same distribution warehouse, but different line\n",
    "        # style according to the different product type\n",
    "        color = [['b', 'b'], ['g', 'g'], ['r', 'r']]\n",
    "        line_style = [['b-', 'b--'], ['g-', 'g--'], ['r-', 'r--']]\n",
    "\n",
    "        timesteps = np.arange(1, episode_duration+1)\n",
    "        for j in range(env.distr_warehouses_num):\n",
    "            for i in range(env.product_types_num):\n",
    "                if env.product_types_num == 1:\n",
    "                    plt.plot(timesteps, demands_mean[:, j, i],\n",
    "                            line_style[j][i],\n",
    "                            label=f\"WH{j+1}\")\n",
    "                else:\n",
    "                    plt.plot(timesteps, demands_mean[:, j, i],\n",
    "                            line_style[j][i],\n",
    "                            label=f\"WH{j+1}, P{i+1}\")\n",
    "                plt.fill_between(timesteps,\n",
    "                                 demands_mean[:, j, i] - demands_std[:, j, i],\n",
    "                                 demands_mean[:, j, i] + demands_std[:, j, i],\n",
    "                                 color=color[j][i], alpha=.2)\n",
    "\n",
    "        # plotting legend\n",
    "        plt.legend()\n",
    "\n",
    "        # saving plot\n",
    "        plt.savefig(f\"{local_dir}/{plots_dir}\"\n",
    "                    f\"/demand.pdf\",\n",
    "                    format='pdf', bbox_inches='tight')\n",
    "\n",
    "\n",
    "def save_env_settings(env, local_dir=local_dir, plots_dir=plots_dir):\n",
    "    \"\"\"\n",
    "    Save the Supply Chain Environment settings.\n",
    "    \"\"\"\n",
    "    f = open(f\"{local_dir}/{plots_dir}\"\n",
    "             f\"/env_settings.txt\",\n",
    "             'w', encoding='utf-8')\n",
    "    f.write(f\"--- SupplyChainEnvironment ---\"\n",
    "            f\"\\nproduct_types_num is \"\n",
    "            f\"{env.product_types_num}\"\n",
    "            f\"\\ndistr_warehouses_num is \"\n",
    "            f\"{env.distr_warehouses_num}\"\n",
    "            f\"\\nT is \"\n",
    "            f\"{env.T}\"\n",
    "            f\"\\ndemand_type is \"\n",
    "            f\"{env.demand_type}\"\n",
    "            f\"\\nd_max is \"\n",
    "            f\"{env.d_max}\"\n",
    "            f\"\\nd_var is \"\n",
    "            f\"{env.d_var}\"\n",
    "            f\"\\nsale_prices is \"\n",
    "            f\"{env.sale_prices}\"\n",
    "            f\"\\nproduction_costs is \"\n",
    "            f\"{env.production_costs}\"\n",
    "            f\"\\nstorage_capacities is \"\n",
    "            f\"{env.storage_capacities}\"\n",
    "            f\"\\nstorage_costs is \"\n",
    "            f\"{env.storage_costs}\"\n",
    "            f\"\\nprod_level_max is \"\n",
    "            f\"{env.prod_level_max}\"\n",
    "            f\"\\ntransportation_capacities is \"\n",
    "            f\"{env.transportation_capacities}\"\n",
    "            f\"\\ntransportation_costs_fixed is \"\n",
    "            f\"{env.transportation_costs_fixed}\"\n",
    "            f\"\\ntransportation_costs_unit is \"\n",
    "            f\"{env.transportation_costs_unit}\"\n",
    "            f\"\\npenalty_costs is \"\n",
    "            f\"{env.penalty_costs}\"\n",
    "            f\"\\nexcess_demand is \"\n",
    "            f\"{env.excess_demand}\"\n",
    "            f\"\\nlead_times_len is \"\n",
    "            f\"{env.lead_times_len}\"\n",
    "            f\"\\ndemand_history_len is \"\n",
    "            f\"{env.demand_history_len}\")\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "Lk4KTfmv0H30"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.808250Z",
     "start_time": "2023-03-29T11:14:32.215431Z"
    },
    "gather": {
     "logged": 1633592884329
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "s_E3N5X5Kq49",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(SEED)\n",
    "env.reset(SEED)\n",
    "visualize_demand(env, NUM_EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.815635Z",
     "start_time": "2023-03-29T11:14:32.811011Z"
    },
    "gather": {
     "logged": 1633592881600
    },
    "hideCode": true,
    "hidePrompt": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# saving env settings\n",
    "save_env_settings(env)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "OrcmncGdCLWl"
   },
   "source": [
    "# Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "iVWW73Ge5_Gy"
   },
   "source": [
    "## Visualize Transitions Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.849476Z",
     "start_time": "2023-03-29T11:14:32.817940Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_metric_plot(ylabel, n,\n",
    "                        episode_duration=env.T-(2*env.lead_times_len),\n",
    "                        plots_n=4+(2*env.distr_warehouses_num)+(\n",
    "                            env.lead_times_len*env.distr_warehouses_num)):\n",
    "    \"\"\"\n",
    "    Auxiliary function.\n",
    "    \"\"\"\n",
    "    plt.subplot(plots_n, 1, n)\n",
    "    plt.ylabel(ylabel, fontsize='medium', ha='center')\n",
    "\n",
    "    plt.xticks(np.arange(min(range(episode_duration)),\n",
    "                         max(range(episode_duration))+1))\n",
    "    plt.tick_params(axis='x', which='both',\n",
    "                    top=True, bottom=True,\n",
    "                    labelbottom=False)\n",
    "\n",
    "\n",
    "def visualize_transitions(returns_trace, algorithm,\n",
    "                          local_dir=local_dir, plots_dir=plots_dir):\n",
    "    \"\"\"\n",
    "    Visualize transitions (stock levels, production and shipping controls,\n",
    "    reward) along the episodes.\n",
    "    \"\"\"\n",
    "    if env.distr_warehouses_num <= 3 and env.product_types_num <= 1:\n",
    "        transitions = np.array(\n",
    "            [(return_trace)\n",
    "             for return_trace in zip(*returns_trace)])\n",
    "        states_trace, actions_trace, rewards_trace = (transitions.T[0],\n",
    "                                                      transitions.T[1],\n",
    "                                                      abs(transitions.T[2]))\n",
    "        episode_duration = env.T-(2*env.lead_times_len)\n",
    "\n",
    "        logger.debug(f\"\\n-- visualize_transitions --\"\n",
    "                     f\"\\nstates_trace is \"\n",
    "                     f\"{states_trace}\"\n",
    "                     f\"\\nactions_trace is \"\n",
    "                     f\"{actions_trace}\"\n",
    "                     f\"\\nrewards_trace is \"\n",
    "                     f\"{rewards_trace}\")\n",
    "\n",
    "        if env.distr_warehouses_num == 3:\n",
    "            fig = plt.figure(figsize=(10, 40))\n",
    "        elif env.distr_warehouses_num == 2:\n",
    "            fig = plt.figure(figsize=(10, 30))\n",
    "        else:\n",
    "            fig = plt.figure(figsize=(10, 20))\n",
    "\n",
    "        # states transitions\n",
    "        states = np.array(\n",
    "            [(state_trace)\n",
    "             for state_trace in zip(*states_trace)])\n",
    "\n",
    "        logger.debug(f\"\\nstates is \"\n",
    "                     f\"{states}\")\n",
    "\n",
    "        # factory stocks\n",
    "        prepare_metric_plot('Stocks,\\nFactory',\n",
    "                            1)\n",
    "        tmp_mean = []\n",
    "        for t in range(len(states)):\n",
    "            tmp_mean.append(\n",
    "                np.mean(\n",
    "                    [np.sum(state.factory_stocks)\n",
    "                     for state in states[t]], axis=0))\n",
    "        tmp_std = []\n",
    "        for t in range(len(states)):\n",
    "            tmp_std.append(\n",
    "                np.std(\n",
    "                    [np.sum(state.factory_stocks)\n",
    "                     for state in states[t]], axis=0))\n",
    "        plt.plot(range(episode_duration),\n",
    "                 tmp_mean,\n",
    "                 color='purple', alpha=.5)\n",
    "        plt.fill_between(range(episode_duration),\n",
    "                         list(np.array(tmp_mean) -\n",
    "                              np.array(tmp_std)),\n",
    "                         list(np.array(tmp_mean) +\n",
    "                              np.array(tmp_std)),\n",
    "                         color='purple', alpha=.2)\n",
    "\n",
    "        logger.debug(f\"\\nfactory_stocks (mean) is \"\n",
    "                     f\"{tmp_mean}\"\n",
    "                     f\"\\nfactory_stocks (std) is \"\n",
    "                     f\"{tmp_std}\")\n",
    "\n",
    "        logger.debug(f\"\\nfactory_stocks (mean for product) is \"\n",
    "                     f\"{tmp_mean}\"\n",
    "                     f\"\\nfactory_stocks (std for product) is \"\n",
    "                     f\"{tmp_std}\")\n",
    "\n",
    "        # distribution warehouses stocks\n",
    "        for j in range(env.distr_warehouses_num):\n",
    "            prepare_metric_plot(f\"Stocks,\\nWH{j+1}\",\n",
    "                                2+j)\n",
    "            tmp_mean = []\n",
    "            for t in range(len(states)):\n",
    "                tmp_mean.append(\n",
    "                    np.mean(\n",
    "                        [np.sum(state.distr_warehouses_stocks[j])\n",
    "                         for state in states[t]], axis=0))\n",
    "            tmp_std = []\n",
    "            for t in range(len(states)):\n",
    "                tmp_std.append(\n",
    "                    np.std(\n",
    "                        [np.sum(state.distr_warehouses_stocks[j])\n",
    "                         for state in states[t]], axis=0))\n",
    "            plt.plot(range(episode_duration),\n",
    "                     tmp_mean,\n",
    "                     color='purple', alpha=.5)\n",
    "            plt.fill_between(range(episode_duration),\n",
    "                             list(np.array(tmp_mean) -\n",
    "                                  np.array(tmp_std)),\n",
    "                             list(np.array(tmp_mean) +\n",
    "                                  np.array(tmp_std)),\n",
    "                             color='purple', alpha=.2)\n",
    "\n",
    "        logger.debug(f\"\\ndistr_warehouses_stocks (mean) is \"\n",
    "                     f\"{tmp_mean}\"\n",
    "                     f\"\\ndistr_warehouses_stocks (std) is \"\n",
    "                     f\"{tmp_std}\")\n",
    "\n",
    "        # actions (transitions)\n",
    "        actions = np.array(\n",
    "            [(action_trace)\n",
    "             for action_trace in zip(*actions_trace)])\n",
    "\n",
    "        logger.debug(f\"\\nactions is \"\n",
    "                     f\"{actions}\")\n",
    "\n",
    "        # production level\n",
    "        prepare_metric_plot('Prod,\\nFactory',\n",
    "                            2+env.distr_warehouses_num)\n",
    "        tmp_mean = []\n",
    "        for t in range(len(actions)):\n",
    "            tmp_mean.append(\n",
    "                np.mean(\n",
    "                    [np.sum(action.production_level)\n",
    "                     for action in actions[t]], axis=0))\n",
    "        tmp_std = []\n",
    "        for t in range(len(actions)):\n",
    "            tmp_std.append(\n",
    "                np.std(\n",
    "                    [np.sum(action.production_level)\n",
    "                     for action in actions[t]], axis=0))\n",
    "        plt.plot(range(episode_duration),\n",
    "                 tmp_mean,\n",
    "                 color='blue', alpha=.5)\n",
    "        plt.fill_between(range(episode_duration),\n",
    "                         list(np.array(tmp_mean) -\n",
    "                              np.array(tmp_std)),\n",
    "                         list(np.array(tmp_mean) +\n",
    "                              np.array(tmp_std)),\n",
    "                         color='blue', alpha=.2)\n",
    "\n",
    "        logger.debug(f\"\\nproduction_level (mean) is \"\n",
    "                     f\"{tmp_mean}\"\n",
    "                     f\"\\nproduction_level (std) is \"\n",
    "                     f\"{tmp_std}\")\n",
    "\n",
    "        # shipped stocks\n",
    "        for j in range(env.distr_warehouses_num):\n",
    "            prepare_metric_plot(f\"Ship,\\nWH{j+1}\",\n",
    "                                3+env.distr_warehouses_num+j)\n",
    "            tmp_mean = []\n",
    "            for t in range(len(actions)):\n",
    "                tmp_mean.append(\n",
    "                    np.mean(\n",
    "                        [np.sum(action.shipped_stocks[j])\n",
    "                         for action in actions[t]], axis=0))\n",
    "            tmp_std = []\n",
    "            for t in range(len(actions)):\n",
    "                tmp_std.append(\n",
    "                    np.std(\n",
    "                        [np.sum(action.shipped_stocks[j])\n",
    "                         for action in actions[t]], axis=0))\n",
    "            plt.plot(range(episode_duration),\n",
    "                     tmp_mean,\n",
    "                     color='blue', alpha=.5)\n",
    "            plt.fill_between(range(episode_duration),\n",
    "                             list(np.array(tmp_mean) -\n",
    "                                  np.array(tmp_std)),\n",
    "                             list(np.array(tmp_mean) +\n",
    "                                  np.array(tmp_std)),\n",
    "                             color='blue', alpha=.2)\n",
    "\n",
    "        logger.debug(f\"\\nshipped_stocks (mean) is \"\n",
    "                     f\"{tmp_mean}\"\n",
    "                     f\"\\nshipped_stocks (std) is \"\n",
    "                     f\"{tmp_std}\")\n",
    "\n",
    "        # lead times stocks\n",
    "        cont = 0\n",
    "        for l in range(env.lead_times_len):\n",
    "            for j in range(env.distr_warehouses_num):\n",
    "                prepare_metric_plot(f\"In Transit,\\nL{l+1} WH{j+1}\",\n",
    "                                    3+(2*env.distr_warehouses_num)+j+cont)\n",
    "                tmp_mean = []\n",
    "                for t in range(len(states)):\n",
    "                    tmp_mean.append(\n",
    "                        np.mean(\n",
    "                            [np.sum(state.lead_times[l][j])\n",
    "                             for state in states[t]], axis=0))\n",
    "                tmp_std = []\n",
    "                for t in range(len(states)):\n",
    "                    tmp_std.append(\n",
    "                        np.std(\n",
    "                            [np.sum(state.lead_times[l][j])\n",
    "                             for state in states[t]], axis=0))\n",
    "                plt.plot(range(episode_duration),\n",
    "                         tmp_mean,\n",
    "                         color='green', alpha=.5)\n",
    "                plt.fill_between(range(episode_duration),\n",
    "                                 list(np.array(tmp_mean) -\n",
    "                                      np.array(tmp_std)),\n",
    "                                 list(np.array(tmp_mean) +\n",
    "                                      np.array(tmp_std)),\n",
    "                                 color='green', alpha=.2)\n",
    "            cont += env.distr_warehouses_num\n",
    "\n",
    "        logger.debug(f\"\\nlead_times_stocks (mean) is \"\n",
    "                     f\"{tmp_mean}\"\n",
    "                     f\"\\nlead_times_stocks (std) is \"\n",
    "                     f\"{tmp_std}\")\n",
    "\n",
    "        # profit\n",
    "        prepare_metric_plot('\\nCosts',\n",
    "                            3+(2*env.distr_warehouses_num)+(\n",
    "                                env.lead_times_len*env.distr_warehouses_num))\n",
    "        reward_mean = np.array(\n",
    "            np.mean(rewards_trace, axis=0),\n",
    "            dtype=np.int32)\n",
    "        reward_std = np.array(\n",
    "            np.std(rewards_trace.astype(np.int32), axis=0),\n",
    "            dtype=np.int32)\n",
    "        plt.plot(range(episode_duration),\n",
    "                 reward_mean,\n",
    "                 linewidth=2,\n",
    "                 color='red', alpha=.5)\n",
    "        plt.fill_between(range(episode_duration),\n",
    "                         reward_mean -\n",
    "                         reward_std,\n",
    "                         reward_mean +\n",
    "                         reward_std,\n",
    "                         color='red', alpha=.2)\n",
    "\n",
    "        logger.debug(f\"\\nprofit (mean) is \"\n",
    "                     f\"{reward_mean}\"\n",
    "                     f\"\\nprofit (std) is \"\n",
    "                     f\"{reward_std}\")\n",
    "\n",
    "        # cumulative profit\n",
    "        prepare_metric_plot('Cum\\nCosts',\n",
    "                            4+(2*env.distr_warehouses_num)+(\n",
    "                                env.lead_times_len*env.distr_warehouses_num))\n",
    "        cum_reward = np.array(\n",
    "            [np.cumsum(reward_trace)\n",
    "             for reward_trace in rewards_trace])\n",
    "        cum_reward_mean = np.array(\n",
    "            np.mean(cum_reward, axis=0),\n",
    "            dtype=np.int32)\n",
    "        cum_reward_std = np.array(\n",
    "            np.std(cum_reward.astype(np.int32), axis=0),\n",
    "            dtype=np.int32)\n",
    "        plt.plot(range(episode_duration),\n",
    "                 cum_reward_mean,\n",
    "                 linewidth=2,\n",
    "                 color='red', alpha=.5)\n",
    "        plt.fill_between(range(episode_duration),\n",
    "                         cum_reward_mean -\n",
    "                         cum_reward_std,\n",
    "                         cum_reward_mean +\n",
    "                         cum_reward_std,\n",
    "                         color='red', alpha=.2)\n",
    "\n",
    "        logger.debug(f\"\\ncumulative profit (mean) is \"\n",
    "                     f\"{cum_reward_mean}\"\n",
    "                     f\"\\ncumulative profit (std) is \"\n",
    "                     f\"{cum_reward_std}\")\n",
    "\n",
    "        fig.align_labels()\n",
    "        plt.ticklabel_format(axis='y', style='plain',\n",
    "                             useOffset=False)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # creating necessary subdir and saving plot\n",
    "        if not os.path.exists(f\"{local_dir}/{plots_dir}/{algorithm}\"):\n",
    "            os.makedirs(f\"{local_dir}/{plots_dir}/{algorithm}\")\n",
    "        plt.savefig(f\"{local_dir}/{plots_dir}/{algorithm}\"\n",
    "                    f\"/transitions_{algorithm}.pdf\",\n",
    "                    format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "WOArghzY52X-"
   },
   "source": [
    "## Visualize Cumulative Profit Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.860723Z",
     "start_time": "2023-03-29T11:14:32.851365Z"
    },
    "gather": {
     "logged": 1633592886888
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "DZ75Lkfwjsry"
   },
   "outputs": [],
   "source": [
    "def calculate_cum_profit(returns_trace, print_reward=True):\n",
    "    \"\"\"\n",
    "    Calculate the cumulative profit for each episode.\n",
    "    \"\"\"\n",
    "    rewards_trace = []\n",
    "    for return_trace in returns_trace:\n",
    "        rewards_trace.append(abs(\n",
    "            np.sum(return_trace.T[2])))\n",
    "\n",
    "    if print_reward:\n",
    "        print(f\"reward: mean \"\n",
    "              f\"{np.mean(rewards_trace)}, \"\n",
    "              f\"std \"\n",
    "              f\"{np.std(rewards_trace)}, \"\n",
    "              f\"max \"\n",
    "              f\"{np.max(rewards_trace)}, \"\n",
    "              f\"min \"\n",
    "              f\"{np.min(rewards_trace)}\")\n",
    "\n",
    "    return rewards_trace\n",
    "\n",
    "\n",
    "def visualize_cum_profit(rewards_trace, algorithm,\n",
    "                         local_dir=local_dir, plots_dir=plots_dir):\n",
    "    \"\"\"\n",
    "    Visualize the cumulative profit boxplot along the episodes.\n",
    "    \"\"\"\n",
    "    xticks = []\n",
    "    if not isinstance(algorithm, list):\n",
    "        xticks.append(algorithm)\n",
    "    else:\n",
    "        xticks = algorithm\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.boxplot(rewards_trace)\n",
    "\n",
    "    plt.ylabel('Cumulative Costs')\n",
    "    plt.xticks(np.arange(1,\n",
    "                         len(xticks)+1),\n",
    "               xticks)\n",
    "    plt.tick_params(axis='x', which='both',\n",
    "                    top=False, bottom=True,\n",
    "                    labelbottom=True)\n",
    "    plt.ticklabel_format(axis='y', style='plain',\n",
    "                         useOffset=False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # creating necessary subdir and saving plot\n",
    "    if not os.path.exists(f\"{local_dir}/{plots_dir}/{algorithm}\"):\n",
    "        os.makedirs(f\"{local_dir}/{plots_dir}/{algorithm}\")\n",
    "    plt.savefig(f\"{local_dir}/{plots_dir}/{algorithm}\"\n",
    "                f\"/cum_profit_{algorithm}.pdf\",\n",
    "                format='pdf', bbox_inches='tight')\n",
    "\n",
    "    # saving the cumulative profit as text\n",
    "    if not isinstance(algorithm, list):\n",
    "        f = open(f\"{local_dir}/{plots_dir}/{algorithm}\"\n",
    "                 f\"/cum_profit_{algorithm}.txt\",\n",
    "                 'w', encoding='utf-8')\n",
    "        f.write(f\"reward: mean \"\n",
    "                f\"{np.mean(rewards_trace)}, \"\n",
    "                f\"std \"\n",
    "                f\"{np.std(rewards_trace)}, \"\n",
    "                f\"max \"\n",
    "                f\"{np.max(rewards_trace)}, \"\n",
    "                f\"min \"\n",
    "                f\"{np.min(rewards_trace)}\")\n",
    "        f.close()\n",
    "\n",
    "\n",
    "def save_checkpoint(checkpoint, algorithm,\n",
    "                    local_dir=local_dir, plots_dir=plots_dir):\n",
    "    \"\"\"\n",
    "    Save Ax BS/(s, Q)-policy parameters or RLib Agent checkpoint.\n",
    "    \"\"\"\n",
    "    f = open(f\"{local_dir}/{plots_dir}/{algorithm}\"\n",
    "             f\"/best_checkpoint_{algorithm}.txt\",\n",
    "             'w', encoding='utf-8')\n",
    "    f.write(checkpoint)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def save_object(obj, obj_name, algorithm,\n",
    "                local_dir=local_dir, plots_dir=plots_dir):\n",
    "    try:\n",
    "        with open(f\"{local_dir}/{plots_dir}/{algorithm}/\"\n",
    "                  f\"/{obj_name}_{algorithm}.pickle\", \"wb\") as f:\n",
    "            pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    except Exception as e:\n",
    "        print(f\"{e.__class__} occurred!\")\n",
    "\n",
    "\n",
    "def convert_seconds_to_min_sec(seconds_float):\n",
    "    # Get the minutes part and the remaining seconds\n",
    "    minutes, seconds = divmod(seconds_float, 60)\n",
    "\n",
    "    # Combine minutes and seconds in requested format\n",
    "    min_sec = minutes + seconds / 100\n",
    "\n",
    "    return min_sec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR-Tools Methods"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code inspired by hands-on tutorial ['A Python OR-Tools Model for Seasonal Inventory Planning'](https://towardsdatascience.com/a-python-or-tools-model-for-seasonal-inventory-planning-483aaf5aa8b)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Methods [OR-Tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.876632Z",
     "start_time": "2023-03-29T11:14:32.863017Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_parameters_ortools(env, num_episodes=1):\n",
    "    \"\"\"\n",
    "    Transforms env parameters from numpy.array to lists.\n",
    "    \"\"\"\n",
    "    # number of (time) steps for MIP solver\n",
    "    num_steps = env.T\n",
    "    steps = np.arange(0, num_steps, 1)\n",
    "    steps = dict(enumerate(steps.flatten(), 0))\n",
    "    for t in steps:\n",
    "        steps[t] = f\"{steps[t]}\"\n",
    "\n",
    "    # generating demands (MIP solver knows the episodes' demands a priori)\n",
    "    demands_episodes = []\n",
    "    for _ in range(num_episodes):\n",
    "        demands_episode = env.generate_episode_demands()\n",
    "        demands_episodes.append(demands_episode)\n",
    "    demands_episodes = np.array(demands_episodes)\n",
    "\n",
    "    # mean of demands\n",
    "    demands_mean_episodes = np.array([np.mean(d, axis=0)\n",
    "                                      for d in zip(*demands_episodes)])\n",
    "    # demands as list\n",
    "    demands_mean_list = np.around(demands_mean_episodes).tolist()\n",
    "\n",
    "    # deterministic demand, equivalent to the mean value (as list)\n",
    "    demand = {}\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        demand[j] = {}\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        for i in range(env.product_types_num):\n",
    "            demand[j][i] = {}\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        for i in range(env.product_types_num):\n",
    "            for t in range(env.T):\n",
    "                demand[j][i][t] = demands_mean_list[t][j][i]\n",
    "\n",
    "    logger.debug(f\"\\n-- OR-Tools -- create_parameters_ortools\"\n",
    "                 f\"\\ndemands_mean_episodes is \"\n",
    "                 f\"{demands_mean_episodes}\"\n",
    "                 f\"\\ndemands_mean_list is \"\n",
    "                 f\"{demands_mean_list}\"\n",
    "                 f\"\\ndemand is \"\n",
    "                 f\"{demand}\")\n",
    "\n",
    "    # initial stocks and capacities (as lists)\n",
    "    initial_stocks = 0\n",
    "    factory_capacities = env.storage_capacities.tolist()[0]\n",
    "    distr_w_capacities = env.storage_capacities.tolist()[1:]\n",
    "    transportation_capacities = env.transportation_capacities.tolist()\n",
    "\n",
    "    # costs (as lists)\n",
    "    sale_prices = env.sale_prices.tolist()\n",
    "    production_costs = env.production_costs.tolist()\n",
    "\n",
    "    transportation_costs_fixed = env.transportation_costs_fixed.tolist()\n",
    "    transportation_costs_unit = env.transportation_costs_unit.tolist()\n",
    "\n",
    "    factory_storage_costs = env.storage_costs.tolist()[0]\n",
    "    distr_w_storage_costs = env.storage_costs.tolist()[1:]\n",
    "    penalty_costs = env.penalty_costs.tolist()\n",
    "\n",
    "    logger.debug(f\"\\nnum_steps is \"\n",
    "                 f\"{num_steps}\"\n",
    "                 f\"\\nsteps is \"\n",
    "                 f\"{steps}\"\n",
    "                 f\"\\ndemand is \"\n",
    "                 f\"{demand}\"\n",
    "                 f\"\\ninitial_stocks is \"\n",
    "                 f\"{initial_stocks}\"\n",
    "                 f\"\\nfactory_capacities is \"\n",
    "                 f\"{factory_capacities}\"\n",
    "                 f\"\\ndistr_w_capacities is \"\n",
    "                 f\"{distr_w_capacities}\"\n",
    "                 f\"\\ntransportation_capacities is \"\n",
    "                 f\"{transportation_capacities}\"\n",
    "                 f\"\\nsale_prices is \"\n",
    "                 f\"{sale_prices}\"\n",
    "                 f\"\\nproduction_costs is \"\n",
    "                 f\"{production_costs}\"\n",
    "                 f\"\\ntransportation_costs_fixed is \"\n",
    "                 f\"{transportation_costs_fixed}\"\n",
    "                 f\"\\ntransportation_costs_unit is \"\n",
    "                 f\"{transportation_costs_unit}\"\n",
    "                 f\"\\nfactory_storage_costs is \"\n",
    "                 f\"{factory_storage_costs}\"\n",
    "                 f\"\\ndistr_w_storage_costs is \"\n",
    "                 f\"{distr_w_storage_costs}\"\n",
    "                 f\"\\npenalty_costs is \"\n",
    "                 f\"{penalty_costs}\")\n",
    "\n",
    "    return (steps, demand, initial_stocks,\n",
    "            factory_capacities, distr_w_capacities,\n",
    "            transportation_capacities,\n",
    "            sale_prices, production_costs,\n",
    "            transportation_costs_fixed, transportation_costs_unit,\n",
    "            factory_storage_costs, distr_w_storage_costs,\n",
    "            penalty_costs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Variables [OR-Tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.896194Z",
     "start_time": "2023-03-29T11:14:32.879159Z"
    }
   },
   "outputs": [],
   "source": [
    "def decision_variables_ortools(env, solver):\n",
    "    \"\"\"\n",
    "    Defines OR-Tools decision variables for each warehouse (including factory)\n",
    "    and for each product type.\n",
    "    \"\"\"\n",
    "    # factory decision variables\n",
    "    prod_level = {}\n",
    "    stocks_factory = {}\n",
    "\n",
    "    for i in range(env.product_types_num):\n",
    "        prod_level[i] = {}\n",
    "        stocks_factory[i] = {}\n",
    "\n",
    "    for i in range(env.product_types_num):\n",
    "        for t in range(env.T):\n",
    "            prod_level[i][t] = solver.IntVar(\n",
    "                0, int(env.prod_level_max[i]),\n",
    "                'prod_level')\n",
    "            stocks_factory[i][t] = solver.IntVar(\n",
    "                0, solver.infinity(),\n",
    "                'stocks_factory')\n",
    "\n",
    "    # distr_w decision variables\n",
    "    in_transit_stocks = {}\n",
    "    shipped_stocks = {}\n",
    "    stocks_distr_w = {}\n",
    "    transportation_numbers = {}\n",
    "\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        shipped_stocks[j] = {}\n",
    "        stocks_distr_w[j] = {}\n",
    "        transportation_numbers[j] = {}\n",
    "\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        for i in range(env.product_types_num):\n",
    "            shipped_stocks[j][i] = {}\n",
    "            stocks_distr_w[j][i] = {}\n",
    "            transportation_numbers[j][i] = {}\n",
    "\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        for i in range(env.product_types_num):\n",
    "            for t in range(env.T):\n",
    "                shipped_stocks[j][i][t] = solver.IntVar(\n",
    "                    0, int(env.storage_capacities[j+1][i]),\n",
    "                    'shipped_stocks')\n",
    "                stocks_distr_w[j][i][t] = solver.IntVar(\n",
    "                    -solver.infinity(), solver.infinity(),\n",
    "                    'stocks_distr_w')\n",
    "                transportation_numbers[j][i][t] = solver.IntVar(\n",
    "                    0, solver.infinity(),\n",
    "                    'transportation_numbers')\n",
    "\n",
    "    if env.lead_times_len > 0:\n",
    "        for l in range(env.lead_times_len):\n",
    "            in_transit_stocks[l] = {}\n",
    "        for l in range(env.lead_times_len):\n",
    "            for j in range(env.distr_warehouses_num):\n",
    "                in_transit_stocks[l][j] = {}\n",
    "        for l in range(env.lead_times_len):\n",
    "            for j in range(env.distr_warehouses_num):\n",
    "                for i in range(env.product_types_num):\n",
    "                    in_transit_stocks[l][j][i] = {}\n",
    "        for l in range(env.lead_times_len):\n",
    "            for j in range(env.distr_warehouses_num):\n",
    "                for i in range(env.product_types_num):\n",
    "                    for t in range(env.T):\n",
    "                        in_transit_stocks[l][j][i][t] = solver.IntVar(\n",
    "                            0, int(env.storage_capacities[j+1][i]),\n",
    "                            'in_transit_stocks')\n",
    "\n",
    "    logger.debug(f\"\\n-- OR-Tools -- decision_variables_ortools\"\n",
    "                 f\"\\nprod_level is \"\n",
    "                 f\"{prod_level}\"\n",
    "                 f\"\\nstocks_factory \"\n",
    "                 f\"{stocks_factory}\"\n",
    "                 f\"\\nin_transit_stocks is \"\n",
    "                 f\"{in_transit_stocks}\"\n",
    "                 f\"\\nshipped_stocks is \"\n",
    "                 f\"{shipped_stocks}\"\n",
    "                 f\"\\nstocks_distr_w is \"\n",
    "                 f\"{stocks_distr_w}\"\n",
    "                 f\"\\ntransportation_numbers is \"\n",
    "                 f\"{transportation_numbers}\")\n",
    "\n",
    "    print(f\"number of variables is {solver.NumVariables()}\")\n",
    "\n",
    "    return (prod_level, stocks_factory,\n",
    "            in_transit_stocks,\n",
    "            shipped_stocks, stocks_distr_w,\n",
    "            transportation_numbers)\n",
    "\n",
    "\n",
    "def s_decision_variables_ortools(env, solver):\n",
    "    \"\"\"\n",
    "    Defines OR-Tools decision variables (storage costs) for each warehouse\n",
    "    (including factory) and for each product type.\n",
    "    \"\"\"\n",
    "    # dummy variable for storage costs (factory)\n",
    "    dummy_s_costs_factory = {}\n",
    "\n",
    "    for i in range(env.product_types_num):\n",
    "        dummy_s_costs_factory[i] = {}\n",
    "\n",
    "    for i in range(env.product_types_num):\n",
    "        for t in range(env.T):\n",
    "            dummy_s_costs_factory[i][t] = solver.IntVar(\n",
    "                0, solver.infinity(),\n",
    "                'dummy_s_costs_factory')\n",
    "\n",
    "    # dummy variable for storage costs (distr_w)\n",
    "    dummy_s_costs_distr_w = {}\n",
    "\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        dummy_s_costs_distr_w[j] = {}\n",
    "\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        for i in range(env.product_types_num):\n",
    "            dummy_s_costs_distr_w[j][i] = {}\n",
    "\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        for i in range(env.product_types_num):\n",
    "            for t in range(env.T):\n",
    "                dummy_s_costs_distr_w[j][i][t] = solver.IntVar(\n",
    "                    0, solver.infinity(),\n",
    "                    'dummy_s_costs_distr_w')\n",
    "\n",
    "    logger.debug(f\"\\n-- OR-Tools -- s_decision_variables_ortools\"\n",
    "                 f\"\\ndummy_s_costs_factory is \"\n",
    "                 f\"{dummy_s_costs_factory}\"\n",
    "                 f\"\\ndummy_s_costs_distr_w \"\n",
    "                 f\"{dummy_s_costs_distr_w}\")\n",
    "\n",
    "    print(f\"number of variables is {solver.NumVariables()}\")\n",
    "\n",
    "    return (dummy_s_costs_factory, dummy_s_costs_distr_w)\n",
    "\n",
    "\n",
    "def p_decision_variables_ortools(env, solver):\n",
    "    \"\"\"\n",
    "    Defines OR-Tools decision variables (penalty costs) for each warehouse\n",
    "    (including factory) and for each product type.\n",
    "    \"\"\"\n",
    "    # dummy variable for penalty costs (factory)\n",
    "    dummy_p_costs_factory = {}\n",
    "\n",
    "    for i in range(env.product_types_num):\n",
    "        dummy_p_costs_factory[i] = {}\n",
    "\n",
    "    for i in range(env.product_types_num):\n",
    "        for t in range(env.T):\n",
    "            dummy_p_costs_factory[i][t] = solver.IntVar(\n",
    "                -solver.infinity(), 0,\n",
    "                'dummy_p_costs_factory')\n",
    "\n",
    "    # dummy variable for penalty costs (distr_w)\n",
    "    dummy_p_costs_distr_w = {}\n",
    "\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        dummy_p_costs_distr_w[j] = {}\n",
    "\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        for i in range(env.product_types_num):\n",
    "            dummy_p_costs_distr_w[j][i] = {}\n",
    "\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        for i in range(env.product_types_num):\n",
    "            for t in range(env.T):\n",
    "                dummy_p_costs_distr_w[j][i][t] = solver.IntVar(\n",
    "                    -solver.infinity(), 0,\n",
    "                    'dummy_p_costs_distr_w')\n",
    "\n",
    "    logger.debug(f\"\\n-- OR-Tools -- p_decision_variables_ortools\"\n",
    "                 f\"\\ndummy_p_costs_factory is \"\n",
    "                 f\"{dummy_p_costs_factory}\"\n",
    "                 f\"\\ndummy_p_costs_distr_w \"\n",
    "                 f\"{dummy_p_costs_distr_w}\")\n",
    "\n",
    "    print(f\"number of variables is {solver.NumVariables()}\")\n",
    "\n",
    "    return (dummy_p_costs_factory, dummy_p_costs_distr_w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints [OR-Tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.918159Z",
     "start_time": "2023-03-29T11:14:32.898537Z"
    }
   },
   "outputs": [],
   "source": [
    "def constraints_ortools(env, solver, demands, initial_stocks,\n",
    "                        prod_level, stocks_factory,\n",
    "                        in_transit_stocks,\n",
    "                        shipped_stocks, stocks_distr_w,\n",
    "                        transportation_numbers, transportation_capacities,\n",
    "                        factory_capacities, distr_w_capacities):\n",
    "    \"\"\"\n",
    "    Defines OR-Tools constraints for each warehouse (including factory) and for\n",
    "    each product type.\n",
    "    \"\"\"\n",
    "    # step 0 (factory)\n",
    "    for i in range(env.product_types_num):\n",
    "        solver.Add(\n",
    "            stocks_factory[i][0]\n",
    "            == initial_stocks +\n",
    "            prod_level[i][0] -\n",
    "            sum(shipped_stocks[j][i][0]\n",
    "                for j in range(env.distr_warehouses_num)))\n",
    "        solver.Add(\n",
    "            initial_stocks + prod_level[i][0] >=\n",
    "            sum(shipped_stocks[j][i][0]\n",
    "                for j in range(env.distr_warehouses_num)))\n",
    "        solver.Add(\n",
    "            initial_stocks + prod_level[i][0] <=\n",
    "            factory_capacities[i])\n",
    "\n",
    "    # step 0 (distr_w)\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        for i in range(env.product_types_num):\n",
    "            if env.lead_times_len > 0:\n",
    "                solver.Add(\n",
    "                    stocks_distr_w[j][i][0]\n",
    "                    == initial_stocks -\n",
    "                    demands[j][i][0])\n",
    "                solver.Add(\n",
    "                    initial_stocks <=\n",
    "                    distr_w_capacities[j][i])\n",
    "            else:\n",
    "                solver.Add(\n",
    "                    stocks_distr_w[j][i][0]\n",
    "                    == initial_stocks +\n",
    "                    shipped_stocks[j][i][0] -\n",
    "                    demands[j][i][0])\n",
    "                solver.Add(\n",
    "                    initial_stocks +\n",
    "                    shipped_stocks[j][i][0] <=\n",
    "                    distr_w_capacities[j][i])\n",
    "            solver.Add(\n",
    "                transportation_numbers[j][i][0] >=\n",
    "                shipped_stocks[j][i][0] /\n",
    "                transportation_capacities[j][i])\n",
    "\n",
    "    if env.lead_times_len > 0:\n",
    "        # steps = 0 (lead_times)\n",
    "        for l in range(env.lead_times_len-1, 0, -1):\n",
    "            for j in range(env.distr_warehouses_num):\n",
    "                for i in range(env.product_types_num):\n",
    "                    solver.Add(\n",
    "                        in_transit_stocks[l][j][i][0]\n",
    "                        == initial_stocks)\n",
    "        for j in range(env.distr_warehouses_num):\n",
    "            for i in range(env.product_types_num):\n",
    "                solver.Add(\n",
    "                    in_transit_stocks[0][j][i][0]\n",
    "                    == shipped_stocks[j][i][0])\n",
    "\n",
    "    # steps > 0 (factory)\n",
    "    for i in range(env.product_types_num):\n",
    "        for t in range(1, env.T):\n",
    "            solver.Add(\n",
    "                stocks_factory[i][t]\n",
    "                == stocks_factory[i][t-1] +\n",
    "                prod_level[i][t] -\n",
    "                sum(shipped_stocks[j][i][t]\n",
    "                    for j in range(env.distr_warehouses_num)))\n",
    "            solver.Add(\n",
    "                stocks_factory[i][t-1] + prod_level[i][t] >=\n",
    "                sum(shipped_stocks[j][i][t]\n",
    "                    for j in range(env.distr_warehouses_num)))\n",
    "            solver.Add(\n",
    "                stocks_factory[i][t-1] + prod_level[i][t] <=\n",
    "                factory_capacities[i])\n",
    "\n",
    "    # steps > 0 (distr_w)\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        for i in range(env.product_types_num):\n",
    "            for t in range(1, env.T):\n",
    "                if env.lead_times_len > 0:\n",
    "                    solver.Add(\n",
    "                        stocks_distr_w[j][i][t]\n",
    "                        == stocks_distr_w[j][i][t-1] +\n",
    "                        in_transit_stocks[env.lead_times_len-1][j][i][t-1] -\n",
    "                        demands[j][i][t])\n",
    "                    solver.Add(\n",
    "                        stocks_distr_w[j][i][t-1] +\n",
    "                        in_transit_stocks[env.lead_times_len-1][j][i][t-1] <=\n",
    "                        distr_w_capacities[j][i])\n",
    "                else:\n",
    "                    solver.Add(\n",
    "                        stocks_distr_w[j][i][t]\n",
    "                        == stocks_distr_w[j][i][t-1] +\n",
    "                        shipped_stocks[j][i][t] -\n",
    "                        demands[j][i][t])\n",
    "                    solver.Add(\n",
    "                        stocks_distr_w[j][i][t-1] +\n",
    "                        shipped_stocks[j][i][t] <=\n",
    "                        distr_w_capacities[j][i])\n",
    "                solver.Add(\n",
    "                    transportation_numbers[j][i][t] >=\n",
    "                    shipped_stocks[j][i][t] /\n",
    "                    transportation_capacities[j][i])\n",
    "\n",
    "    if env.lead_times_len > 0:\n",
    "        # steps > 0 (lead_times)\n",
    "        for l in range(env.lead_times_len-1, 0, -1):\n",
    "            for j in range(env.distr_warehouses_num):\n",
    "                for i in range(env.product_types_num):\n",
    "                    for t in range(1, env.T):\n",
    "                        solver.Add(\n",
    "                            in_transit_stocks[l][j][i][t]\n",
    "                            == in_transit_stocks[l-1][j][i][t-1])\n",
    "        for j in range(env.distr_warehouses_num):\n",
    "            for i in range(env.product_types_num):\n",
    "                for t in range(1, env.T):\n",
    "                    solver.Add(\n",
    "                        in_transit_stocks[0][j][i][t]\n",
    "                        == shipped_stocks[j][i][t])\n",
    "\n",
    "    print(f\"number of constraints is {solver.NumConstraints()}\")\n",
    "\n",
    "\n",
    "def s_constraints_ortools(env, solver,\n",
    "                          stocks_factory, factory_storage_costs,\n",
    "                          stocks_distr_w, distr_w_storage_costs,\n",
    "                          dummy_s_costs_factory, dummy_s_costs_distr_w):\n",
    "    \"\"\"\n",
    "    Defines OR-Tools (storage costs) constraints for each warehouse (including\n",
    "    factory) and for each product type.\n",
    "    https://math.stackexchange.com/questions/679121/\n",
    "    \"\"\"\n",
    "    # steps >= 0 (factory)\n",
    "    for i in range(env.product_types_num):\n",
    "        for t in range(0, env.T):\n",
    "            solver.Add(dummy_s_costs_factory[i][t] >=\n",
    "                       factory_storage_costs[i]*stocks_factory[i][t])\n",
    "            solver.Add(dummy_s_costs_factory[i][t] >= 0)\n",
    "\n",
    "    # steps >= 0 (distr_w)\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        for i in range(env.product_types_num):\n",
    "            for t in range(0, env.T):\n",
    "                solver.Add(dummy_s_costs_distr_w[j][i][t] >=\n",
    "                           distr_w_storage_costs[j][i] *\n",
    "                           stocks_distr_w[j][i][t])\n",
    "                solver.Add(dummy_s_costs_distr_w[j][i][t] >= 0)\n",
    "\n",
    "    print(f\"number of constraints is {solver.NumConstraints()}\")\n",
    "\n",
    "\n",
    "def p_constraints_ortools(env, solver, penalty_costs,\n",
    "                          stocks_factory, stocks_distr_w,\n",
    "                          dummy_p_costs_factory, dummy_p_costs_distr_w):\n",
    "    \"\"\"\n",
    "    Defines OR-Tools (penalty costs) constraints for each warehouse (including\n",
    "    factory) and for each product type.\n",
    "    https://math.stackexchange.com/questions/679121/\n",
    "    \"\"\"\n",
    "    # steps >= 0 (factory)\n",
    "    for i in range(env.product_types_num):\n",
    "        for t in range(0, env.T):\n",
    "            solver.Add(dummy_p_costs_factory[i][t] <=\n",
    "                       penalty_costs[i]*stocks_factory[i][t])\n",
    "            solver.Add(dummy_p_costs_factory[i][t] <= 0)\n",
    "\n",
    "    # steps >= 0 (distr_w)\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        for i in range(env.product_types_num):\n",
    "            for t in range(0, env.T):\n",
    "                solver.Add(dummy_p_costs_distr_w[j][i][t] <=\n",
    "                           penalty_costs[i] *\n",
    "                           stocks_distr_w[j][i][t])\n",
    "                solver.Add(dummy_p_costs_distr_w[j][i][t] <= 0)\n",
    "\n",
    "    print(f\"number of constraints is {solver.NumConstraints()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function [OR-Tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.929225Z",
     "start_time": "2023-03-29T11:14:32.920381Z"
    }
   },
   "outputs": [],
   "source": [
    "def obj_func_ortools(env, demands, sale_prices,\n",
    "                     prod_level, production_costs,\n",
    "                     shipped_stocks, transportation_numbers,\n",
    "                     transportation_costs_fixed, transportation_costs_unit,\n",
    "                     dummy_s_costs_factory, dummy_s_costs_distr_w,\n",
    "                     dummy_p_costs_factory, dummy_p_costs_distr_w):\n",
    "    \"\"\"\n",
    "    Defines OR-Tools objective function.\n",
    "    \"\"\"\n",
    "    # revenues and transportation costs\n",
    "    total_revenues = []\n",
    "    total_transportation_costs_fixed = []\n",
    "    total_transportation_costs_unit = []\n",
    "    total_transportation_costs = []\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        for i in range(env.product_types_num):\n",
    "            for t in range(env.T):\n",
    "                total_revenues.append(sale_prices[i] *\n",
    "                                      demands[j][i][t])\n",
    "                total_transportation_costs_fixed.append(\n",
    "                    transportation_costs_fixed[j][i] *\n",
    "                    transportation_numbers[j][i][t])\n",
    "                total_transportation_costs_unit.append(\n",
    "                    transportation_costs_unit[j][i] *\n",
    "                    shipped_stocks[j][i][t])\n",
    "    total_revenues = sum(total_revenues)\n",
    "    total_transportation_costs_fixed = sum(total_transportation_costs_fixed)\n",
    "    total_transportation_costs_unit = sum(total_transportation_costs_unit)\n",
    "    total_transportation_costs = total_transportation_costs_fixed + \\\n",
    "        total_transportation_costs_unit\n",
    "\n",
    "    # production costs\n",
    "    total_production_costs = []\n",
    "    for i in range(env.product_types_num):\n",
    "        for t in range(env.T):\n",
    "            total_production_costs.append(production_costs[i]*prod_level[i][t])\n",
    "    total_production_costs = sum(total_production_costs)\n",
    "\n",
    "    # storage costs\n",
    "    total_storage_costs = []\n",
    "    for i in range(env.product_types_num):\n",
    "        for t in range(env.T):\n",
    "            total_storage_costs.append(dummy_s_costs_factory[i][t])\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        for i in range(env.product_types_num):\n",
    "            for t in range(env.T):\n",
    "                total_storage_costs.append(dummy_s_costs_distr_w[j][i][t])\n",
    "    total_storage_costs = sum(total_storage_costs)\n",
    "\n",
    "    # penalty costs\n",
    "    total_penalty_costs = []\n",
    "    for i in range(env.product_types_num):\n",
    "        for t in range(env.T):\n",
    "            total_penalty_costs.append(dummy_p_costs_factory[i][t])\n",
    "    for j in range(env.distr_warehouses_num):\n",
    "        for i in range(env.product_types_num):\n",
    "            for t in range(env.T):\n",
    "                total_penalty_costs.append(dummy_p_costs_distr_w[j][i][t])\n",
    "    total_penalty_costs = -sum(total_penalty_costs)\n",
    "\n",
    "    # reward\n",
    "    reward = total_revenues - total_production_costs - \\\n",
    "        total_transportation_costs - total_storage_costs - total_penalty_costs\n",
    "\n",
    "    logger.debug(f\"\\n--- OR-Tools --- objective_function_ortools\"\n",
    "                 f\"\\ntotal_revenues is \"\n",
    "                 f\"{total_revenues}\"\n",
    "                 f\"\\ntotal_production_costs is \"\n",
    "                 f\"{total_production_costs}\"\n",
    "                 f\"\\ntotal_transportation_costs_fixed is \"\n",
    "                 f\"{total_transportation_costs_fixed}\"\n",
    "                 f\"\\ntotal_transportation_costs_unit is \"\n",
    "                 f\"{total_transportation_costs_unit}\"\n",
    "                 f\"\\ntotal_transportation_costs is \"\n",
    "                 f\"{total_transportation_costs}\"\n",
    "                 f\"\\ntotal_storage_costs is \"\n",
    "                 f\"{total_storage_costs}\"\n",
    "                 f\"\\ntotal_penalty_costs is \"\n",
    "                 f\"{total_penalty_costs}\"\n",
    "                 f\"\\nreward is \"\n",
    "                 f\"{reward}\")\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results [OR-Tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.948071Z",
     "start_time": "2023-03-29T11:14:32.931459Z"
    }
   },
   "outputs": [],
   "source": [
    "def results_ortools(env, solver, steps, demands,\n",
    "                    prod_level, stocks_factory,\n",
    "                    in_transit_stocks,\n",
    "                    shipped_stocks, stocks_distr_w,\n",
    "                    factory_capacities, distr_w_capacities,\n",
    "                    transportation_numbers, transportation_capacities,\n",
    "                    local_dir, plots_dir):\n",
    "    \"\"\"\n",
    "    Prepare and display OR-Tools results.\n",
    "    \"\"\"\n",
    "    # factory results\n",
    "    results_stocks_factory = []\n",
    "    results_prod_level = []\n",
    "\n",
    "    for t in range(env.T):\n",
    "        for i in range(env.product_types_num):\n",
    "            results_stocks_factory.append(\n",
    "                stocks_factory[i][t].solution_value())\n",
    "            results_prod_level.append(\n",
    "                prod_level[i][t].solution_value())\n",
    "\n",
    "    # factory results (in terms of steps)\n",
    "    results_stocks_factory = np.array(\n",
    "        results_stocks_factory).reshape(env.T,\n",
    "                                        env.product_types_num)\n",
    "    results_prod_level = np.array(\n",
    "        results_prod_level).reshape(env.T,\n",
    "                                    env.product_types_num)\n",
    "\n",
    "    # distr_w results\n",
    "    results_in_transit_stocks = []\n",
    "    results_stocks_distr_w = []\n",
    "    results_demands = []\n",
    "    results_shipped_stocks = []\n",
    "    results_transportation_numbers = []\n",
    "\n",
    "    for t in range(env.T):\n",
    "        for i in range(env.product_types_num):\n",
    "            for j in range(env.distr_warehouses_num):\n",
    "                results_stocks_distr_w.append(\n",
    "                    stocks_distr_w[j][i][t].solution_value())\n",
    "                results_demands.append(\n",
    "                    demands[j][i][t])\n",
    "                results_shipped_stocks.append(\n",
    "                    shipped_stocks[j][i][t].solution_value())\n",
    "                results_transportation_numbers.append(\n",
    "                    transportation_numbers[j][i][t].solution_value())\n",
    "\n",
    "    if env.lead_times_len > 0:\n",
    "        for t in range(env.T):\n",
    "            for l in range(env.lead_times_len):\n",
    "                for j in range(env.distr_warehouses_num):\n",
    "                    for i in range(env.product_types_num):\n",
    "                        results_in_transit_stocks.append(\n",
    "                            in_transit_stocks[l][j][i][t].solution_value())\n",
    "\n",
    "    # distr_w results (in terms of steps)\n",
    "    results_stocks_distr_w = np.array(\n",
    "        results_stocks_distr_w).reshape(env.T,\n",
    "                                        env.product_types_num,\n",
    "                                        env.distr_warehouses_num)\n",
    "    results_demands = np.array(\n",
    "        results_demands).reshape(env.T,\n",
    "                                 env.product_types_num,\n",
    "                                 env.distr_warehouses_num)\n",
    "    results_shipped_stocks = np.array(\n",
    "        results_shipped_stocks).reshape(env.T,\n",
    "                                        env.product_types_num,\n",
    "                                        env.distr_warehouses_num)\n",
    "\n",
    "    if env.lead_times_len > 0:\n",
    "        results_in_transit_stocks = np.array(\n",
    "            results_in_transit_stocks).reshape(env.T,\n",
    "                                               env.lead_times_len,\n",
    "                                               env.product_types_num,\n",
    "                                               env.distr_warehouses_num)\n",
    "\n",
    "    results_transportation_numbers = np.array(\n",
    "        results_transportation_numbers).reshape(env.T,\n",
    "                                                env.product_types_num,\n",
    "                                                env.distr_warehouses_num)\n",
    "    transportation_capacities = np.array(\n",
    "        transportation_capacities).reshape(env.product_types_num,\n",
    "                                           env.distr_warehouses_num)\n",
    "\n",
    "    if env.lead_times_len > 0:\n",
    "        # results (as pandas DataFrame)\n",
    "        results_ortools = pd.DataFrame(\n",
    "            columns=['step',\n",
    "                     'start_stocks factory',\n",
    "                     'start_stocks distr_w',\n",
    "                     'demands',\n",
    "                     'prod level',\n",
    "                     'prod level max',\n",
    "                     'shipped stocks',\n",
    "                     'in transit stocks',\n",
    "                     'transp numbers',\n",
    "                     'transp capacities',\n",
    "                     'transp capacities used (in %)',\n",
    "                     'end_stocks factory',\n",
    "                     'factory capacities',\n",
    "                     'factory capacities used (in %)',\n",
    "                     'end_stocks distr_w',\n",
    "                     'distr_w capacities',\n",
    "                     'distr_w capacities used (in %)'])\n",
    "\n",
    "        for t in range(env.T):\n",
    "            results_ortools.loc[t] = [\n",
    "                steps[t],\n",
    "                results_stocks_factory[t-1],\n",
    "                results_stocks_distr_w[t-1],\n",
    "                results_demands[t],\n",
    "                results_prod_level[t],\n",
    "                env.prod_level_max,\n",
    "                results_shipped_stocks[t],\n",
    "                results_in_transit_stocks[t],\n",
    "                results_transportation_numbers[t],\n",
    "                transportation_capacities,\n",
    "                np.around(\n",
    "                    results_shipped_stocks[t] /\n",
    "                    ((results_transportation_numbers[t] +\n",
    "                      np.finfo('float').eps) *\n",
    "                     transportation_capacities) *\n",
    "                    100).astype(np.int32),\n",
    "                results_stocks_factory[t],\n",
    "                factory_capacities,\n",
    "                np.around(\n",
    "                    results_stocks_factory[t] /\n",
    "                    factory_capacities *\n",
    "                    100).astype(np.int32),\n",
    "                results_stocks_distr_w[t],\n",
    "                distr_w_capacities,\n",
    "                np.around(\n",
    "                    results_stocks_distr_w[t].flatten() /\n",
    "                    list(np.array(distr_w_capacities).flat) *\n",
    "                    100).astype(np.int32)]\n",
    "    else:\n",
    "        # results (as pandas DataFrame)\n",
    "        results_ortools = pd.DataFrame(\n",
    "            columns=['step',\n",
    "                     'start_stocks factory',\n",
    "                     'start_stocks distr_w',\n",
    "                     'demands',\n",
    "                     'prod level',\n",
    "                     'prod level max',\n",
    "                     'shipped stocks',\n",
    "                     'transp numbers',\n",
    "                     'transp capacities',\n",
    "                     'transp capacities used (in %)',\n",
    "                     'end_stocks factory',\n",
    "                     'factory capacities',\n",
    "                     'factory capacities used (in %)',\n",
    "                     'end_stocks distr_w',\n",
    "                     'distr_w capacities',\n",
    "                     'distr_w capacities used (in %)'])\n",
    "\n",
    "        for t in range(env.T):\n",
    "            results_ortools.loc[t] = [\n",
    "                steps[t],\n",
    "                results_stocks_factory[t-1],\n",
    "                results_stocks_distr_w[t-1],\n",
    "                results_demands[t],\n",
    "                results_prod_level[t],\n",
    "                env.prod_level_max,\n",
    "                results_shipped_stocks[t],\n",
    "                results_transportation_numbers[t],\n",
    "                transportation_capacities,\n",
    "                np.around(\n",
    "                    results_shipped_stocks[t] /\n",
    "                    ((results_transportation_numbers[t] +\n",
    "                      np.finfo('float').eps) *\n",
    "                     transportation_capacities) *\n",
    "                    100).astype(np.int32),\n",
    "                results_stocks_factory[t],\n",
    "                factory_capacities,\n",
    "                np.around(\n",
    "                    results_stocks_factory[t] /\n",
    "                    factory_capacities *\n",
    "                    100).astype(np.int32),\n",
    "                results_stocks_distr_w[t],\n",
    "                distr_w_capacities,\n",
    "                np.around(\n",
    "                    results_stocks_distr_w[t].flatten() /\n",
    "                    list(np.array(distr_w_capacities).flat) *\n",
    "                    100).astype(np.int32)]\n",
    "\n",
    "    # display results\n",
    "    display(results_ortools)\n",
    "\n",
    "    # creating necessary subdir and saving plot\n",
    "    if not os.path.exists(f\"{local_dir}/{plots_dir}/EVPI\"):\n",
    "        os.makedirs(f\"{local_dir}/{plots_dir}/EVPI\")\n",
    "\n",
    "    # saving pandas DataFrame as an image\n",
    "    dfi.export(results_ortools,\n",
    "               f\"{local_dir}/{plots_dir}\"\n",
    "               f\"/EVPI/results_ortools_df.png\",\n",
    "               table_conversion='matplotlib')\n",
    "    # saving pandas DataFrame as LaTeX table\n",
    "    f = open(f\"{local_dir}/{plots_dir}/EVPI\"\n",
    "             f\"/results_ortools_df.tex\",\n",
    "             'w', encoding='utf-8')\n",
    "    f.write(results_ortools.style.to_latex())\n",
    "    f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator Methods [OR-Tools]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.965613Z",
     "start_time": "2023-03-29T11:14:32.957628Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate_episode_ortools_det(env, prod_level, shipped_stocks, seed):\n",
    "    \"\"\"\n",
    "    OR-Tools single episode simulator.\n",
    "    \"\"\"\n",
    "    env.reset(seed)\n",
    "    state = env.initial_state()\n",
    "    transitions_full = []\n",
    "    transitions = []\n",
    "\n",
    "    logger.debug(f\"\\n-- simulate_episode_ortools_det --\"\n",
    "                 f\"\\nstate is \"\n",
    "                 f\"{state}\"\n",
    "                 f\"\\ntransitions_full is \"\n",
    "                 f\"{transitions_full}\"\n",
    "                 f\"\\ntransitions is \"\n",
    "                 f\"{transitions}\")\n",
    "\n",
    "    for t in range(env.T):\n",
    "        action = Action(state.product_types_num, state.distr_warehouses_num)\n",
    "        for j in range(state.distr_warehouses_num):\n",
    "            for i in range(state.product_types_num):\n",
    "                action.shipped_stocks[j][i] = \\\n",
    "                    shipped_stocks[t][j][i]\n",
    "\n",
    "        for i in range(state.product_types_num):\n",
    "            action.production_level[i] = prod_level[t][i]\n",
    "\n",
    "        state, reward, _ = env.step(state, action)\n",
    "        transitions_full.append(np.array(\n",
    "            [state, action, reward],\n",
    "            dtype=object))\n",
    "        if (t > env.lead_times_len-1 and t < env.T-env.lead_times_len):\n",
    "            transitions.append(np.array(\n",
    "                [state, action, reward],\n",
    "                dtype=object))\n",
    "\n",
    "        logger.debug(f\"\\naction is \"\n",
    "                     f\"{action}\"\n",
    "                     f\"\\naction.production_level is \"\n",
    "                     f\"{action.production_level}\"\n",
    "                     f\"\\naction.shipped_stocks is \"\n",
    "                     f\"{action.shipped_stocks}\"\n",
    "                     f\"\\nstate is \"\n",
    "                     f\"{state}\"\n",
    "                     f\"\\nstate.factory_stocks is \"\n",
    "                     f\"{state.factory_stocks}\"\n",
    "                     f\"\\nstate.distr_warehouses_stocks is \"\n",
    "                     f\"{state.distr_warehouses_stocks}\"\n",
    "                     f\"\\nstate.demand_history is \"\n",
    "                     f\"{state.demand_history}\"\n",
    "                     f\"\\nt is \"\n",
    "                     f\"{t}\"\n",
    "                     f\"\\nreward is \"\n",
    "                     f\"{reward}\")\n",
    "\n",
    "    logger.debug(f\"\\ntransitions_full [state, action, reward] is \"\n",
    "                 f\"{transitions_full}\"\n",
    "                 f\"\\ntransitions [state, action, reward] is \"\n",
    "                 f\"{transitions}\")\n",
    "\n",
    "    return [transitions_full, transitions]\n",
    "\n",
    "\n",
    "def simulate_ortools_det(env, prod_level, shipped_stocks, num_episodes=1, seed=SEED):\n",
    "    \"\"\"\n",
    "    OR-Tools simulator.\n",
    "    \"\"\"\n",
    "    returns_trace_full = []\n",
    "    returns_trace = []\n",
    "    time_ortools_det_testing = []\n",
    "\n",
    "    prod_level_episodes = np.array(\n",
    "        prod_level).reshape(num_episodes,\n",
    "                            env.T,\n",
    "                            env.product_types_num)\n",
    "    shipped_stocks_episodes = np.array(\n",
    "        shipped_stocks).reshape(num_episodes,\n",
    "                                env.T,\n",
    "                                env.distr_warehouses_num,\n",
    "                                env.product_types_num)\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        seed = None\n",
    "        if episode == 0:\n",
    "            seed = seed\n",
    "\n",
    "        start_ortools_det = default_timer()\n",
    "        rt_full, rt = simulate_episode_ortools_det(\n",
    "            env,\n",
    "            prod_level_episodes[episode],\n",
    "            shipped_stocks_episodes[episode],\n",
    "            seed)\n",
    "        end_ortools_det = default_timer()\n",
    "        \n",
    "        returns_trace_full.append(np.array(rt_full))\n",
    "        returns_trace.append(np.array(rt))\n",
    "        time_ortools_det_testing.append(end_ortools_det-start_ortools_det)\n",
    "\n",
    "    logger.debug(f\"\\n-- simulate_ortools_det --\"\n",
    "                 f\"\\nreturns_trace_full is \"\n",
    "                 f\"{returns_trace_full}\"\n",
    "                 f\"\\nreturns_trace is \"\n",
    "                 f\"{returns_trace}\")\n",
    "\n",
    "    return [returns_trace_full, returns_trace, time_ortools_det_testing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:32.978173Z",
     "start_time": "2023-03-29T11:14:32.968475Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate_episode_ortools(env, prod_level, shipped_stocks, seed):\n",
    "    \"\"\"\n",
    "    OR-Tools single episode simulator.\n",
    "    \"\"\"\n",
    "    env.reset(seed)\n",
    "    state = env.initial_state()\n",
    "    transitions_full = []\n",
    "    transitions = []\n",
    "\n",
    "    logger.debug(f\"\\n-- simulate_episode_ortools --\"\n",
    "                 f\"\\nstate is \"\n",
    "                 f\"{state}\"\n",
    "                 f\"\\ntransitions_full is \"\n",
    "                 f\"{transitions_full}\"\n",
    "                 f\"\\ntransitions is \"\n",
    "                 f\"{transitions}\")\n",
    "\n",
    "    for t in range(env.T):\n",
    "        action = Action(state.product_types_num, state.distr_warehouses_num)\n",
    "        for j in range(state.distr_warehouses_num):\n",
    "            for i in range(state.product_types_num):\n",
    "                action.shipped_stocks[j][i] = \\\n",
    "                    shipped_stocks[j][i][t].solution_value()\n",
    "\n",
    "        for i in range(state.product_types_num):\n",
    "            action.production_level[i] = prod_level[i][t].solution_value()\n",
    "\n",
    "        state, reward, _ = env.step(state, action)\n",
    "        transitions_full.append(np.array(\n",
    "            [state, action, reward],\n",
    "            dtype=object))\n",
    "        if (t > env.lead_times_len-1 and t < env.T-env.lead_times_len):\n",
    "            transitions.append(np.array(\n",
    "                [state, action, reward],\n",
    "                dtype=object))\n",
    "\n",
    "        logger.debug(f\"\\naction is \"\n",
    "                     f\"{action}\"\n",
    "                     f\"\\naction.production_level is \"\n",
    "                     f\"{action.production_level}\"\n",
    "                     f\"\\naction.shipped_stocks is \"\n",
    "                     f\"{action.shipped_stocks}\"\n",
    "                     f\"\\nstate is \"\n",
    "                     f\"{state}\"\n",
    "                     f\"\\nstate.factory_stocks is \"\n",
    "                     f\"{state.factory_stocks}\"\n",
    "                     f\"\\nstate.distr_warehouses_stocks is \"\n",
    "                     f\"{state.distr_warehouses_stocks}\"\n",
    "                     f\"\\nstate.demand_history is \"\n",
    "                     f\"{state.demand_history}\"\n",
    "                     f\"\\nt is \"\n",
    "                     f\"{t}\"\n",
    "                     f\"\\nreward is \"\n",
    "                     f\"{reward}\")\n",
    "\n",
    "    logger.debug(f\"\\ntransitions_full [state, action, reward] is \"\n",
    "                 f\"{transitions_full}\"\n",
    "                 f\"\\ntransitions [state, action, reward] is \"\n",
    "                 f\"{transitions}\")\n",
    "\n",
    "    return [transitions_full, transitions]\n",
    "\n",
    "\n",
    "def simulate_ortools(env, prod_level, shipped_stocks, num_episodes=1, seed=SEED):\n",
    "    \"\"\"\n",
    "    OR-Tools simulator.\n",
    "    \"\"\"\n",
    "    returns_trace_full = []\n",
    "    returns_trace = []\n",
    "    time_ortools_testing = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        seed = None\n",
    "        if episode == 0:\n",
    "            seed = seed\n",
    "\n",
    "        start_ortools = default_timer()\n",
    "        rt_full, rt = simulate_episode_ortools(\n",
    "            env,\n",
    "            prod_level,\n",
    "            shipped_stocks,\n",
    "            seed)\n",
    "        end_ortools = default_timer()\n",
    "        \n",
    "        returns_trace_full.append(np.array(rt_full))\n",
    "        returns_trace.append(np.array(rt))\n",
    "        time_ortools_testing.append(end_ortools-start_ortools)\n",
    "\n",
    "    logger.debug(f\"\\n-- simulate_ortools --\"\n",
    "                 f\"\\nreturns_trace_full is \"\n",
    "                 f\"{returns_trace_full}\"\n",
    "                 f\"\\nreturns_trace is \"\n",
    "                 f\"{returns_trace}\")\n",
    "\n",
    "    return [returns_trace_full, returns_trace, time_ortools_testing]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR-Tools Optimize (LP-DET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:33.510528Z",
     "start_time": "2023-03-29T11:14:32.980255Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cum_profit_solver_ortools_det = []\n",
    "time_ortools_iterations = []\n",
    "\n",
    "prod_level_ortools_det = []\n",
    "shipped_stocks_ortools_det = []\n",
    "\n",
    "np.random.seed(SEED)\n",
    "env.reset(SEED)\n",
    "for n in range(NUM_EPISODES):\n",
    "    # ortools parameters\n",
    "    (steps_ortools_det, demands_ortools_det, initial_stocks_ortools_det,\n",
    "     factory_capacities_ortools_det, distr_w_capacities_ortools_det,\n",
    "     transportation_capacities_ortools_det,\n",
    "     sale_prices_ortools_det, production_costs_ortools_det,\n",
    "     transportation_costs_fixed_ortools_det,\n",
    "     transportation_costs_unit_ortools_det,\n",
    "     factory_storage_costs_ortools_det, distr_w_storage_costs_ortools_det,\n",
    "     penalty_costs_ortools_det) = create_parameters_ortools(env)\n",
    "\n",
    "    # MIP solver (with SCIP backend)\n",
    "    # https://developers.google.com/optimization/mip/mip_example\n",
    "    # https://www.scipopt.org/\n",
    "    solver_det = pywraplp.Solver.CreateSolver('SCIP')\n",
    "    solver_det.SetSolverSpecificParametersAsString(\n",
    "        'randomization/randomseedshift=2023')\n",
    "    solver_det.set_time_limit(30*1000)\n",
    "\n",
    "    # ortools decision variables\n",
    "    (prod_level_det, stocks_factory_det,\n",
    "     in_transit_stocks_det,\n",
    "     shipped_stocks_det, stocks_distr_w_det,\n",
    "     transportation_numbers_det) = decision_variables_ortools(\n",
    "        env, solver_det)\n",
    "\n",
    "    # ortools constraints\n",
    "    constraints_ortools(env, solver_det, demands_ortools_det,\n",
    "                        initial_stocks_ortools_det,\n",
    "                        prod_level_det, stocks_factory_det,\n",
    "                        in_transit_stocks_det,\n",
    "                        shipped_stocks_det, stocks_distr_w_det,\n",
    "                        transportation_numbers_det,\n",
    "                        transportation_capacities_ortools_det,\n",
    "                        factory_capacities_ortools_det,\n",
    "                        distr_w_capacities_ortools_det)\n",
    "\n",
    "    # storage costs decision variables\n",
    "    (dummy_s_costs_factory_det,\n",
    "     dummy_s_costs_distr_w_det) = s_decision_variables_ortools(env, solver_det)\n",
    "    # storage costs constraints\n",
    "    s_constraints_ortools(env, solver_det,\n",
    "                          stocks_factory_det,\n",
    "                          factory_storage_costs_ortools_det,\n",
    "                          stocks_distr_w_det,\n",
    "                          distr_w_storage_costs_ortools_det,\n",
    "                          dummy_s_costs_factory_det, dummy_s_costs_distr_w_det)\n",
    "\n",
    "    # penalty costs decision variables\n",
    "    (dummy_p_costs_factory_det,\n",
    "     dummy_p_costs_distr_w_det) = p_decision_variables_ortools(env, solver_det)\n",
    "    # penalty costs constraints\n",
    "    p_constraints_ortools(env, solver_det, penalty_costs_ortools_det,\n",
    "                          stocks_factory_det, stocks_distr_w_det,\n",
    "                          dummy_p_costs_factory_det, dummy_p_costs_distr_w_det)\n",
    "\n",
    "    # reward\n",
    "    reward = obj_func_ortools(env, demands_ortools_det,\n",
    "                              sale_prices_ortools_det,\n",
    "                              prod_level_det, production_costs_ortools_det,\n",
    "                              shipped_stocks_det, transportation_numbers_det,\n",
    "                              transportation_costs_fixed_ortools_det,\n",
    "                              transportation_costs_unit_ortools_det,\n",
    "                              dummy_s_costs_factory_det,\n",
    "                              dummy_s_costs_distr_w_det,\n",
    "                              dummy_p_costs_factory_det,\n",
    "                              dummy_p_costs_distr_w_det)\n",
    "\n",
    "    # ortools solution\n",
    "    solver_det.Maximize(reward)\n",
    "    status_det = solver_det.Solve()\n",
    "\n",
    "    if (status_det == pywraplp.Solver.OPTIMAL or\n",
    "            status_det == pywraplp.Solver.FEASIBLE):\n",
    "        print(f\"objective value is {solver_det.Objective().Value()}\")\n",
    "        time_ortools_iteration = solver_det.wall_time()/1000\n",
    "        print(f\"problem solved in {time_ortools_iteration} seconds\")\n",
    "        print(f\"problem solved in {solver_det.iterations()} iterations\\n\")\n",
    "\n",
    "        for t in range(env.T):\n",
    "            for i in range(env.product_types_num):\n",
    "                prod_level_ortools_det.append(\n",
    "                    prod_level_det[i][t].solution_value())\n",
    "            for j in range(env.distr_warehouses_num):\n",
    "                for i in range(env.product_types_num):\n",
    "                    shipped_stocks_ortools_det.append(\n",
    "                        shipped_stocks_det[j][i][t].solution_value())\n",
    "    else:\n",
    "        print('NO OPTIMAL SOLUTION!')\n",
    "\n",
    "    cum_profit_solver_ortools_det.append(abs(solver_det.Objective().Value()))\n",
    "    time_ortools_iterations.append(time_ortools_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:33.515948Z",
     "start_time": "2023-03-29T11:14:33.512654Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculating and printing the LP-DET training time\n",
    "time_ortools_det_total_training = np.round((np.sum(time_ortools_iterations)), 6)\n",
    "time_ortools_det_mean_training = np.round((np.mean(time_ortools_iterations)), 6)\n",
    "time_ortools_det_std_training = np.round((np.std(time_ortools_iterations)), 6)\n",
    "print(f\"total training time LP-DET (in seconds) is {time_ortools_det_total_training}\")\n",
    "print(f\"mean training time LP-DET (in seconds) is {time_ortools_det_mean_training}\")\n",
    "print(f\"std training time LP-DET (in seconds) is {time_ortools_det_std_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:33.850456Z",
     "start_time": "2023-03-29T11:14:33.517649Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluating the LP-DET policy\n",
    "np.random.seed(SEED)\n",
    "env.reset(SEED)\n",
    "(returns_trace_ortools_det_full, returns_trace_ortools_det,\n",
    " time_ortools_det_testing) = simulate_ortools_det(env,\n",
    "                                                  prod_level_ortools_det,\n",
    "                                                  shipped_stocks_ortools_det,\n",
    "                                                  NUM_EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating and printing the LP-DET testing time\n",
    "time_ortools_det_total_testing = np.round((np.sum(time_ortools_det_testing)), 6)\n",
    "time_ortools_det_mean_testing = np.round((np.mean(time_ortools_det_testing)), 6)\n",
    "time_ortools_det_std_testing = np.round((np.std(time_ortools_det_testing)), 6)\n",
    "print(f\"total testing time LP-DET (in seconds) is {time_ortools_det_total_testing}\")\n",
    "print(f\"mean testing time LP-DET (in seconds) is {time_ortools_det_mean_testing}\")\n",
    "print(f\"std testing time LP-DET (in seconds) is {time_ortools_det_std_testing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:36.564056Z",
     "start_time": "2023-03-29T11:14:33.852354Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_transitions(returns_trace_ortools_det, 'PI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:36.568666Z",
     "start_time": "2023-03-29T11:14:36.565792Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cumulative profit of the LP-DET policy\n",
    "cum_profit_ortools_det = calculate_cum_profit(returns_trace_ortools_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:36.739968Z",
     "start_time": "2023-03-29T11:14:36.570571Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_cum_profit(cum_profit_ortools_det, 'PI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:36.752677Z",
     "start_time": "2023-03-29T11:14:36.741991Z"
    }
   },
   "outputs": [],
   "source": [
    "save_object(returns_trace_ortools_det_full, 'transitions_full', 'PI')\n",
    "save_object(returns_trace_ortools_det, 'transitions', 'PI')\n",
    "save_object(cum_profit_ortools_det, 'cum_profit', 'PI')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OR-Tools Optimize (LP-MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:36.809375Z",
     "start_time": "2023-03-29T11:14:36.754628Z"
    }
   },
   "outputs": [],
   "source": [
    "# ortools parameters\n",
    "(steps_ortools, demands_ortools, initial_stocks_ortools,\n",
    " factory_capacities_ortools, distr_w_capacities_ortools,\n",
    " transportation_capacities_ortools,\n",
    " sale_prices_ortools, production_costs_ortools,\n",
    " transportation_costs_fixed_ortools, transportation_costs_unit_ortools,\n",
    " factory_storage_costs_ortools, distr_w_storage_costs_ortools,\n",
    " penalty_costs_ortools) = create_parameters_ortools(env, NUM_EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:36.815491Z",
     "start_time": "2023-03-29T11:14:36.811340Z"
    }
   },
   "outputs": [],
   "source": [
    "# MIP solver (with SCIP backend)\n",
    "# https://developers.google.com/optimization/mip/mip_example\n",
    "# https://www.scipopt.org/\n",
    "solver_mean = pywraplp.Solver.CreateSolver('SCIP')\n",
    "solver_mean.SetSolverSpecificParametersAsString(\n",
    "    'randomization/randomseedshift=2023')\n",
    "solver_mean.set_time_limit(30*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:36.820733Z",
     "start_time": "2023-03-29T11:14:36.817429Z"
    }
   },
   "outputs": [],
   "source": [
    "# ortools decision variables\n",
    "(prod_level, stocks_factory,\n",
    " in_transit_stocks,\n",
    " shipped_stocks, stocks_distr_w,\n",
    " transportation_numbers) = decision_variables_ortools(env, solver_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:36.827239Z",
     "start_time": "2023-03-29T11:14:36.822748Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# ortools constraints\n",
    "constraints_ortools(env, solver_mean, demands_ortools, initial_stocks_ortools,\n",
    "                    prod_level, stocks_factory,\n",
    "                    in_transit_stocks,\n",
    "                    shipped_stocks, stocks_distr_w,\n",
    "                    transportation_numbers, transportation_capacities_ortools,\n",
    "                    factory_capacities_ortools, distr_w_capacities_ortools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:36.832860Z",
     "start_time": "2023-03-29T11:14:36.829066Z"
    }
   },
   "outputs": [],
   "source": [
    "# storage costs decision variables\n",
    "(dummy_s_costs_factory,\n",
    " dummy_s_costs_distr_w) = s_decision_variables_ortools(env, solver_mean)\n",
    "# storage costs constraints\n",
    "s_constraints_ortools(env, solver_mean,\n",
    "                      stocks_factory, factory_storage_costs_ortools,\n",
    "                      stocks_distr_w, distr_w_storage_costs_ortools,\n",
    "                      dummy_s_costs_factory, dummy_s_costs_distr_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:36.838836Z",
     "start_time": "2023-03-29T11:14:36.834875Z"
    }
   },
   "outputs": [],
   "source": [
    "# penalty costs decision variables\n",
    "(dummy_p_costs_factory,\n",
    " dummy_p_costs_distr_w) = p_decision_variables_ortools(env, solver_mean)\n",
    "# penalty costs constraints\n",
    "p_constraints_ortools(env, solver_mean, penalty_costs_ortools,\n",
    "                      stocks_factory, stocks_distr_w,\n",
    "                      dummy_p_costs_factory, dummy_p_costs_distr_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:36.844104Z",
     "start_time": "2023-03-29T11:14:36.840684Z"
    }
   },
   "outputs": [],
   "source": [
    "# reward\n",
    "reward = obj_func_ortools(env, demands_ortools, sale_prices_ortools,\n",
    "                          prod_level, production_costs_ortools,\n",
    "                          shipped_stocks, transportation_numbers,\n",
    "                          transportation_costs_fixed_ortools,\n",
    "                          transportation_costs_unit_ortools,\n",
    "                          dummy_s_costs_factory, dummy_s_costs_distr_w,\n",
    "                          dummy_p_costs_factory, dummy_p_costs_distr_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:36.860340Z",
     "start_time": "2023-03-29T11:14:36.846257Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ortools solution\n",
    "solver_mean.Maximize(reward)\n",
    "status = solver_mean.Solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:37.331057Z",
     "start_time": "2023-03-29T11:14:36.862132Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# printing the LP-MEAN results\n",
    "if status == pywraplp.Solver.OPTIMAL or status == pywraplp.Solver.FEASIBLE:\n",
    "    print(f\"objective value is {solver_mean.Objective().Value()}\")\n",
    "    print(f\"problem solved in {solver_mean.iterations()} iterations\")\n",
    "    time_ortools_total_training = np.round((solver_mean.wall_time()/1000), 6)\n",
    "    results_ortools(env, solver_mean,\n",
    "                    steps_ortools, demands_ortools,\n",
    "                    prod_level, stocks_factory,\n",
    "                    in_transit_stocks,\n",
    "                    shipped_stocks, stocks_distr_w,\n",
    "                    factory_capacities_ortools, distr_w_capacities_ortools,\n",
    "                    transportation_numbers, transportation_capacities_ortools,\n",
    "                    local_dir, plots_dir)\n",
    "else:\n",
    "    print('NO OPTIMAL SOLUTION!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:37.336308Z",
     "start_time": "2023-03-29T11:14:37.333213Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculating and printing the LP-MEAN training time\n",
    "print(f\"total training time LP-MEAN (in seconds) is {time_ortools_total_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:37.666174Z",
     "start_time": "2023-03-29T11:14:37.338057Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluating the ortools policy\n",
    "np.random.seed(SEED)\n",
    "env.reset(SEED)\n",
    "(returns_trace_ortools_full, returns_trace_ortools,\n",
    " time_ortools_testing) = simulate_ortools(env,\n",
    "                                          prod_level,\n",
    "                                          shipped_stocks,\n",
    "                                          NUM_EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating and printing the LP-MEAN testing time\n",
    "time_ortools_total_testing = np.round((np.sum(time_ortools_testing)), 6)\n",
    "time_ortools_mean_testing = np.round((np.mean(time_ortools_testing)), 6)\n",
    "time_ortools_std_testing = np.round((np.std(time_ortools_testing)), 6)\n",
    "print(f\"total testing time LP-MEAN (in seconds) is {time_ortools_total_testing}\")\n",
    "print(f\"mean testing time LP-MEAN (in seconds) is {time_ortools_mean_testing}\")\n",
    "print(f\"std testing time LP-MEAN (in seconds) is {time_ortools_det_std_testing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:40.256588Z",
     "start_time": "2023-03-29T11:14:37.668063Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_transitions(returns_trace_ortools, 'EVPI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:40.261328Z",
     "start_time": "2023-03-29T11:14:40.258340Z"
    }
   },
   "outputs": [],
   "source": [
    "# cumulative profit of the ortools policy\n",
    "cum_profit_ortools = calculate_cum_profit(returns_trace_ortools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:40.441189Z",
     "start_time": "2023-03-29T11:14:40.262784Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_cum_profit(cum_profit_ortools, 'EVPI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:40.635264Z",
     "start_time": "2023-03-29T11:14:40.443247Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_cum_profit([cum_profit_ortools,\n",
    "                      cum_profit_ortools_det],\n",
    "                     ['EVPI',\n",
    "                      'PI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:40.653092Z",
     "start_time": "2023-03-29T11:14:40.637479Z"
    }
   },
   "outputs": [],
   "source": [
    "save_object(returns_trace_ortools_full, 'transitions_full', 'EVPI')\n",
    "save_object(returns_trace_ortools, 'transitions', 'EVPI')\n",
    "save_object(cum_profit_ortools, 'cum_profit', 'EVPI')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gurobi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters [Gurobi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:40.658356Z",
     "start_time": "2023-03-29T11:14:40.655520Z"
    }
   },
   "outputs": [],
   "source": [
    "rolling_horizon = 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario Tree [Gurobi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:40.674231Z",
     "start_time": "2023-03-29T11:14:40.661222Z"
    }
   },
   "outputs": [],
   "source": [
    "class ScenarioTree(nx.DiGraph):\n",
    "    def __init__(self, branching_factors, r=0):\n",
    "        nx.DiGraph.__init__(self)\n",
    "\n",
    "        self.initial_value = 0\n",
    "        self.branching_factors = branching_factors\n",
    "        self.tree_depth = len(self.branching_factors)\n",
    "        self.scenarios_num = np.prod(self.branching_factors)\n",
    "\n",
    "        # generating demands (Gurobi solver knows the episodes' demands\n",
    "        # distribution a priori)\n",
    "        stationary_demands = []\n",
    "        stationary_demands.append(np.fromfunction(\n",
    "            lambda j, i, t: env.stationary_demand(j+1, i+1, t+r),\n",
    "            (env.distr_warehouses_num, env.product_types_num, env.T),\n",
    "            dtype=np.int32))\n",
    "        stationary_demands = np.array(stationary_demands[0]).tolist()\n",
    "\n",
    "        # root node\n",
    "        self.start_node = self.initial_value\n",
    "        self.add_node(self.start_node,\n",
    "                      obs=np.repeat(self.initial_value,\n",
    "                                    env.distr_warehouses_num),\n",
    "                      prob=1,\n",
    "                      node_id=0,\n",
    "                      step=0,\n",
    "                      stage=0)\n",
    "        last_nodes_added = [self.start_node]\n",
    "        nodes_count = 1\n",
    "        nodes_per_level_num = 1\n",
    "\n",
    "        self.outcomes = [\n",
    "            [0, 0],\n",
    "            [0, env.d_var[0]],\n",
    "            [env.d_var[0], 0],\n",
    "            [env.d_var[0], env.d_var[0]]\n",
    "            ]\n",
    "\n",
    "        # tree nodes\n",
    "        for t in range(self.tree_depth):\n",
    "            next_stage = []\n",
    "            nodes_per_level_num *= self.branching_factors[t]\n",
    "            for node_parent in last_nodes_added:\n",
    "                self.probs_scenario = 1 / self.branching_factors[t] \n",
    "                self.demands_scenario = [stationary_demands[j][0][t]\n",
    "                                         for j in range(env.distr_warehouses_num)]\n",
    "                for b in range(self.branching_factors[t]):\n",
    "                    node_new_id = nodes_count\n",
    "                    self.add_node(node_new_id,\n",
    "                                  obs=[sum(x) for x in zip(self.demands_scenario,\n",
    "                                                           self.outcomes[b])],\n",
    "                                  prob=self.nodes[node_parent]['prob'] *\n",
    "                                  self.probs_scenario,\n",
    "                                  node_id=nodes_count,\n",
    "                                  step=t+1,\n",
    "                                  stage=t+1)\n",
    "                    self.add_edge(node_parent, node_new_id)\n",
    "                    next_stage.append(node_new_id)\n",
    "                    nodes_count += 1\n",
    "            last_nodes_added = next_stage\n",
    "            self.nodes_num = nodes_count\n",
    "        self.leaves = last_nodes_added\n",
    "\n",
    "        print(f\"\\n{self.nodes()[i]}\" for i in range(self.nodes_num))\n",
    "\n",
    "        logger.debug(f\"\\n-- ScenarioTree -- __init__\"\n",
    "                     f\"\\nbranching_factors is \"\n",
    "                     f\"{self.branching_factors}\"\n",
    "                     f\"\\ntree_depth is \"\n",
    "                     f\"{self.tree_depth}\"\n",
    "                     f\"\\nscenarios_num is \"\n",
    "                     f\"{self.scenarios_num}\"\n",
    "                     f\"\\ndemands_scenario is \"\n",
    "                     f\"{self.demands_scenario}\"\n",
    "                     f\"\\nprobs_scenario is \"\n",
    "                     f\"{self.probs_scenario}\"\n",
    "                     f\"\\nstart_node is \"\n",
    "                     f\"{self.start_node}\")\n",
    "\n",
    "    def get_leaves(self):\n",
    "        return self.leaves\n",
    "\n",
    "    def plot(self, local_dir=local_dir, plots_dir=plots_dir):\n",
    "        \"\"\"Prints the tree.\"\"\"\n",
    "        try:\n",
    "            pos = graphviz_layout(self, prog=\"dot\")\n",
    "            nx.draw(self, pos,\n",
    "                    with_labels=True, arrows=True)\n",
    "\n",
    "            # creating necessary subdir and saving plot\n",
    "            if not os.path.exists(f\"{local_dir}/{plots_dir}/MS\"):\n",
    "                os.makedirs(f\"{local_dir}/{plots_dir}/MS\")\n",
    "            plt.savefig(f\"{local_dir}/{plots_dir}/MS\"\n",
    "                        f\"/plot_ScenarioTree.pdf\",\n",
    "                        format='pdf', bbox_inches='tight')\n",
    "        except Exception as e:\n",
    "            print(f\"{e.__class__} occurred!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Methods [Gurobi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:40.681764Z",
     "start_time": "2023-03-29T11:14:40.676360Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_parameters_gurobi(env):\n",
    "    \"\"\"\n",
    "    Transforms env parameters from numpy.array to lists.\n",
    "    \"\"\"\n",
    "    # initial stocks and capacities (as lists)\n",
    "    initial_stocks = 0\n",
    "    factory_capacities = env.storage_capacities.tolist()[0]\n",
    "    distr_w_capacities = env.storage_capacities.tolist()[1:]\n",
    "    transportation_capacities = env.transportation_capacities.tolist()\n",
    "\n",
    "    # costs (as lists)\n",
    "    sale_prices = env.sale_prices.tolist()\n",
    "    production_costs = env.production_costs.tolist()\n",
    "\n",
    "    transportation_costs_fixed = env.transportation_costs_fixed.tolist()\n",
    "    transportation_costs_unit = env.transportation_costs_unit.tolist()\n",
    "\n",
    "    factory_storage_costs = env.storage_costs.tolist()[0]\n",
    "    distr_w_storage_costs = env.storage_costs.tolist()[1:]\n",
    "    penalty_costs = env.penalty_costs.tolist()\n",
    "\n",
    "    logger.debug(f\"\\n-- Gurobi -- create_parameters_gurobi\"\n",
    "                 f\"\\ninitial_stocks is \"\n",
    "                 f\"{initial_stocks}\"\n",
    "                 f\"\\nfactory_capacities is \"\n",
    "                 f\"{factory_capacities}\"\n",
    "                 f\"\\ndistr_w_capacities is \"\n",
    "                 f\"{distr_w_capacities}\"\n",
    "                 f\"\\ntransportation_capacities is \"\n",
    "                 f\"{transportation_capacities}\"\n",
    "                 f\"\\nsale_prices is \"\n",
    "                 f\"{sale_prices}\"\n",
    "                 f\"\\nproduction_costs is \"\n",
    "                 f\"{production_costs}\"\n",
    "                 f\"\\ntransportation_costs_fixed is \"\n",
    "                 f\"{transportation_costs_fixed}\"\n",
    "                 f\"\\ntransportation_costs_unit is \"\n",
    "                 f\"{transportation_costs_unit}\"\n",
    "                 f\"\\nfactory_storage_costs is \"\n",
    "                 f\"{factory_storage_costs}\"\n",
    "                 f\"\\ndistr_w_storage_costs is \"\n",
    "                 f\"{distr_w_storage_costs}\"\n",
    "                 f\"\\npenalty_costs is \"\n",
    "                 f\"{penalty_costs}\")\n",
    "\n",
    "    return (initial_stocks,\n",
    "            factory_capacities, distr_w_capacities,\n",
    "            transportation_capacities,\n",
    "            sale_prices, production_costs,\n",
    "            transportation_costs_fixed, transportation_costs_unit,\n",
    "            factory_storage_costs, distr_w_storage_costs,\n",
    "            penalty_costs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Variables [Gurobi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:14:40.689811Z",
     "start_time": "2023-03-29T11:14:40.683663Z"
    }
   },
   "outputs": [],
   "source": [
    "def decision_variables_gurobi(env, solver,\n",
    "                              scenario_tree):\n",
    "    \"\"\"\n",
    "    Defines Gurobi decision variables for each warehouse (including factory)\n",
    "    and for each product type.\n",
    "    \"\"\"\n",
    "    # factory decision variables\n",
    "    prod_level = solver.addVars(\n",
    "        scenario_tree.nodes_num,\n",
    "        vtype=grb.GRB.INTEGER,\n",
    "        lb=0,\n",
    "        ub=env.prod_level_max[0],\n",
    "        name='prod_level')\n",
    "    stocks_factory = solver.addVars(\n",
    "        scenario_tree.nodes_num,\n",
    "        vtype=grb.GRB.INTEGER,\n",
    "        lb=0,\n",
    "        ub=grb.GRB.INFINITY,\n",
    "        name='stocks_factory')\n",
    "\n",
    "    # distr_w decision variables\n",
    "    shipped_stocks = solver.addVars(\n",
    "        env.distr_warehouses_num, scenario_tree.nodes_num,\n",
    "        vtype=grb.GRB.INTEGER,\n",
    "        lb=0,\n",
    "        ub=grb.GRB.INFINITY,\n",
    "        name='shipped_stocks')\n",
    "    stocks_distr_w_pos = solver.addVars(\n",
    "        env.distr_warehouses_num, scenario_tree.nodes_num,\n",
    "        vtype=grb.GRB.INTEGER,\n",
    "        lb=0,\n",
    "        ub=grb.GRB.INFINITY,\n",
    "        name='stocks_distr_w_pos')\n",
    "    stocks_distr_w_neg = solver.addVars(\n",
    "        env.distr_warehouses_num, scenario_tree.nodes_num,\n",
    "        vtype=grb.GRB.INTEGER,\n",
    "        lb=0,\n",
    "        ub=grb.GRB.INFINITY,\n",
    "        name='stocks_distr_w_neg')\n",
    "\n",
    "    # transportation decision variables\n",
    "    transportation_numbers = solver.addVars(\n",
    "        env.distr_warehouses_num, scenario_tree.nodes_num,\n",
    "        vtype=grb.GRB.INTEGER,\n",
    "        lb=0,\n",
    "        ub=grb.GRB.INFINITY,\n",
    "        name='transportation_numbers')\n",
    "\n",
    "    logger.debug(f\"\\n-- Gurobi -- decision_variables_gurobi\"\n",
    "                 f\"\\nprod_level is \"\n",
    "                 f\"{prod_level}\"\n",
    "                 f\"\\nstocks_factory is\"\n",
    "                 f\"{stocks_factory}\"\n",
    "                 f\"\\nshipped_stocks is \"\n",
    "                 f\"{shipped_stocks}\"\n",
    "                 f\"\\nstocks_distr_w_pos is \"\n",
    "                 f\"{stocks_distr_w_pos}\"\n",
    "                 f\"\\nstocks_distr_w_neg is \"\n",
    "                 f\"{stocks_distr_w_neg}\"\n",
    "                 f\"\\ntransportation_numbers is \"\n",
    "                 f\"{transportation_numbers}\")\n",
    "\n",
    "    return (prod_level, stocks_factory,\n",
    "            shipped_stocks, stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "            transportation_numbers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints [Gurobi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraints_gurobi(env, solver,\n",
    "                       scenario_tree,\n",
    "                       prod_level, stocks_factory,\n",
    "                       shipped_stocks, stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "                       transportation_numbers, transportation_capacities,\n",
    "                       factory_capacities, distr_w_capacities):\n",
    "    \"\"\"\n",
    "    Defines Gurobi constraints for each warehouse (including factory) and for\n",
    "    each product type.\n",
    "    \"\"\"\n",
    "    # step 0 (factory and warehouses)\n",
    "    solver.addConstrs((\n",
    "        stocks_factory[n] + prod_level[n] >=\n",
    "        grb.quicksum(\n",
    "        shipped_stocks[j, n]\n",
    "        for j in range(env.distr_warehouses_num))\n",
    "        for n in range(scenario_tree.nodes_num)),\n",
    "        name='no_backlog_factory_stocks')\n",
    "\n",
    "    solver.addConstrs(\n",
    "        (stocks_factory[n] + prod_level[n] <=\n",
    "         factory_capacities[0]\n",
    "         for n in range(scenario_tree.nodes_num)),\n",
    "        name='factory_capacities')\n",
    "    solver.addConstrs(\n",
    "        (stocks_distr_w_pos[j, n] + shipped_stocks[j, n] <=\n",
    "         distr_w_capacities[j][0]\n",
    "         for j in range(env.distr_warehouses_num)\n",
    "         for n in range(scenario_tree.nodes_num)),\n",
    "        name='distr_w_capacities')\n",
    "\n",
    "    # step 0 state (factory and warehouses)\n",
    "    state_gurobi = env.initial_state()\n",
    "    constr_factory_stocks = solver.addConstr(\n",
    "        stocks_factory[0] ==\n",
    "        state_gurobi.factory_stocks[0],\n",
    "        name='state_factory_stocks_0')\n",
    "    constr_distr_warehouses_stocks = solver.addConstrs(\n",
    "        (stocks_distr_w_pos[j, 0] - stocks_distr_w_neg[j, 0] ==\n",
    "         state_gurobi.distr_warehouses_stocks[j]\n",
    "         for j in range(env.distr_warehouses_num)),\n",
    "        name='state_distr_warehouses_stocks_0')\n",
    "\n",
    "    # steps > 0 (factory and warehouses)\n",
    "    constr_scenario_tree = []\n",
    "    for n in range(1, scenario_tree.nodes_num):\n",
    "        parent = list(scenario_tree.predecessors(n))[0]\n",
    "        solver.addConstr(\n",
    "            stocks_factory[n] ==\n",
    "            stocks_factory[parent] +\n",
    "            prod_level[parent] -\n",
    "            grb.quicksum(\n",
    "                shipped_stocks[j, parent]\n",
    "                for j in range(env.distr_warehouses_num)),\n",
    "            name=\"factory_stocks\")\n",
    "        constr_scenario_tree.append(solver.addConstrs(\n",
    "            (stocks_distr_w_pos[j, n] -\n",
    "             stocks_distr_w_neg[j, n] ==\n",
    "             stocks_distr_w_pos[j, parent] - stocks_distr_w_neg[j, parent] +\n",
    "             shipped_stocks[j, parent] - scenario_tree.nodes()[parent]['obs'][j]\n",
    "             for j in range(env.distr_warehouses_num)),\n",
    "            name=\"distr_warehouses_stocks\"))\n",
    "\n",
    "    solver.addConstrs(\n",
    "        (shipped_stocks[j, n] <= distr_w_capacities[j][0]\n",
    "         for j in range(env.distr_warehouses_num)\n",
    "         for n in range(scenario_tree.nodes_num)),\n",
    "        name='shipped_stocks_capacities')\n",
    "    solver.addConstrs(\n",
    "        (shipped_stocks[j, n] <= transportation_numbers[j, n] *\n",
    "         transportation_capacities[j][0]\n",
    "         for j in range(env.distr_warehouses_num)\n",
    "         for n in range(scenario_tree.nodes_num)),\n",
    "        name='transportation_capacities')\n",
    "\n",
    "    return (constr_factory_stocks, constr_distr_warehouses_stocks,\n",
    "            constr_scenario_tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function [Gurobi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T13:42:29.136906Z",
     "start_time": "2023-03-29T13:42:29.125785Z"
    }
   },
   "outputs": [],
   "source": [
    "def obj_func_gurobi(env, scenario_tree,\n",
    "                    stocks_factory,\n",
    "                    prod_level, production_costs,\n",
    "                    stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "                    shipped_stocks, transportation_numbers,\n",
    "                    transportation_costs_fixed, transportation_costs_unit,\n",
    "                    factory_storage_costs, distr_w_storage_costs,\n",
    "                    penalty_costs):\n",
    "    \"\"\"\n",
    "    Defines Gurobi objective function.\n",
    "    \"\"\"\n",
    "    # production costs\n",
    "    total_production_costs = grb.quicksum(\n",
    "        scenario_tree.nodes()[n]['prob'] *\n",
    "        production_costs[0] * prod_level[n]\n",
    "        for n in range(scenario_tree.nodes_num))\n",
    "\n",
    "    # transportation costs\n",
    "    total_transportation_costs_fixed = grb.quicksum(\n",
    "        scenario_tree.nodes()[n]['prob'] *\n",
    "        transportation_costs_fixed[j][0] * transportation_numbers[j, n]\n",
    "        for j in range(env.distr_warehouses_num)\n",
    "        for n in range(scenario_tree.nodes_num))\n",
    "    total_transportation_costs_unit = grb.quicksum(\n",
    "        scenario_tree.nodes()[n]['prob'] *\n",
    "        transportation_costs_unit[j][0] * shipped_stocks[j, n]\n",
    "        for j in range(env.distr_warehouses_num)\n",
    "        for n in range(scenario_tree.nodes_num))\n",
    "    total_transportation_costs = total_transportation_costs_fixed + \\\n",
    "        total_transportation_costs_fixed\n",
    "\n",
    "    # storage costs\n",
    "    total_factory_storage_costs = grb.quicksum(\n",
    "        scenario_tree.nodes()[n]['prob'] *\n",
    "        factory_storage_costs[0] * stocks_factory[n]\n",
    "        for n in range(scenario_tree.nodes_num))\n",
    "    total_distr_w_storage_costs = grb.quicksum(\n",
    "        scenario_tree.nodes()[n]['prob'] *\n",
    "        distr_w_storage_costs[j][0] * stocks_distr_w_pos[j, n]\n",
    "        for j in range(env.distr_warehouses_num)\n",
    "        for n in range(scenario_tree.nodes_num))\n",
    "    total_storage_costs = total_factory_storage_costs + \\\n",
    "        total_distr_w_storage_costs\n",
    "\n",
    "    # penalty costs\n",
    "    total_distr_w_penalty_costs = grb.quicksum(\n",
    "        scenario_tree.nodes()[n]['prob'] *\n",
    "        penalty_costs[0] * stocks_distr_w_neg[j, n]\n",
    "        for j in range(env.distr_warehouses_num)\n",
    "        for n in range(scenario_tree.nodes_num))\n",
    "    total_penalty_costs = total_distr_w_penalty_costs\n",
    "\n",
    "    # reward\n",
    "    reward = total_production_costs + \\\n",
    "        total_transportation_costs + total_storage_costs + total_penalty_costs\n",
    "\n",
    "    logger.debug(f\"\\n--- Gurobi --- objective_function_gurobi\"\n",
    "                 f\"\\ntotal_production_costs is \"\n",
    "                 f\"{total_production_costs}\"\n",
    "                 f\"\\ntotal_transportation_costs_fixed is \"\n",
    "                 f\"{total_transportation_costs_fixed}\"\n",
    "                 f\"\\ntotal_transportation_costs_unit is \"\n",
    "                 f\"{total_transportation_costs_unit}\"\n",
    "                 f\"\\ntotal_transportation_costs is \"\n",
    "                 f\"{total_transportation_costs}\"\n",
    "                 f\"\\ntotal_storage_costs is \"\n",
    "                 f\"{total_storage_costs}\"\n",
    "                 f\"\\ntotal_penalty_costs is \"\n",
    "                 f\"{total_penalty_costs}\"\n",
    "                 f\"\\nreward is \"\n",
    "                 f\"{reward}\")\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator Methods [Gurobi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T13:42:29.829337Z",
     "start_time": "2023-03-29T13:42:29.811331Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate_episode_gurobi(env, solver,\n",
    "                            prod_level, shipped_stocks,\n",
    "                            stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "                            constr_factory_stocks,\n",
    "                            constr_distr_warehouses_stocks,\n",
    "                            constr_scenario_tree,\n",
    "                            rolling_horizon, seed):\n",
    "    \"\"\"\n",
    "    Gurobi single episode simulator.\n",
    "    \"\"\"\n",
    "    env.reset(seed)\n",
    "    state = env.initial_state()\n",
    "    transitions_full = []\n",
    "    transitions = []\n",
    "\n",
    "    logger.debug(f\"\\n-- simulate_episode_gurobi --\"\n",
    "                 f\"\\nstate is \"\n",
    "                 f\"{state}\"\n",
    "                 f\"\\ntransitions_full is \"\n",
    "                 f\"{transitions_full}\"\n",
    "                 f\"\\ntransitions is \"\n",
    "                 f\"{transitions}\")\n",
    "\n",
    "    for t in range(env.T):\n",
    "        action = Action(state.product_types_num, state.distr_warehouses_num)\n",
    "        scenario_tree = ScenarioTree(branching_factors=np.repeat(\n",
    "            4, rolling_horizon),\n",
    "            r=t)\n",
    "        for i in range(state.product_types_num):\n",
    "            constr_factory_stocks.rhs = state.factory_stocks[i]\n",
    "        for j in range(state.distr_warehouses_num):\n",
    "            for i in range(state.product_types_num):\n",
    "                constr_distr_warehouses_stocks[j].rhs = \\\n",
    "                    state.distr_warehouses_stocks[j][i]\n",
    "\n",
    "        for n in range(1, scenario_tree.nodes_num):\n",
    "            parent = list(scenario_tree.predecessors(n))[0]\n",
    "            solver.remove(constr_scenario_tree[n-1])\n",
    "            constr_scenario_tree[n-1] = solver.addConstrs(\n",
    "                (stocks_distr_w_pos[j, n] - stocks_distr_w_neg[j, n] ==\n",
    "                 stocks_distr_w_pos[j, parent] -\n",
    "                 stocks_distr_w_neg[j, parent] +\n",
    "                 shipped_stocks[j, parent] - scenario_tree.nodes()[n]['obs'][j]\n",
    "                 for j in range(env.distr_warehouses_num)),\n",
    "                name=\"distr_warehouses_stocks\")\n",
    "\n",
    "        # updating the model\n",
    "        solver.update()\n",
    "        if not os.path.exists(f\"{local_dir}/{plots_dir}/MS\"):\n",
    "            os.makedirs(f\"{local_dir}/{plots_dir}/MS\")\n",
    "        solver.write(f\"{local_dir}/{plots_dir}/MS\"\n",
    "                     f\"/MS_{t}.lp\")\n",
    "        # solving the model\n",
    "        solver.optimize()\n",
    "        if solver.Status in (grb.GRB.INF_OR_UNBD,\n",
    "                             grb.GRB.INFEASIBLE,\n",
    "                             grb.GRB.UNBOUNDED):\n",
    "            print(f\"THE MODEL CANNOT BE SOLVED! ({solver.Status})\")\n",
    "        else:\n",
    "            if solver.Status != grb.GRB.OPTIMAL:\n",
    "                print(f\"SOLUTION NON OPTIMAL! ({solver.Status})\")\n",
    "            else:\n",
    "                print(f\"SOLUTION OPTIMAL! ({solver.Status})\")\n",
    "            for j in range(state.distr_warehouses_num):\n",
    "                for i in range(state.product_types_num):\n",
    "                    action.production_level[i] = prod_level[0].X\n",
    "                    action.shipped_stocks[j][i] = shipped_stocks[j, 0].X\n",
    "\n",
    "            state, reward, _ = env.step(state, action)\n",
    "            transitions_full.append(np.array(\n",
    "                [state, action, reward],\n",
    "                dtype=object))\n",
    "            if (t > env.lead_times_len-1 and t < env.T-env.lead_times_len):\n",
    "                transitions.append(np.array(\n",
    "                    [state, action, reward],\n",
    "                    dtype=object))\n",
    "\n",
    "            logger.debug(f\"\\naction is \"\n",
    "                         f\"{action}\"\n",
    "                         f\"\\naction.production_level is \"\n",
    "                         f\"{action.production_level}\"\n",
    "                         f\"\\naction.shipped_stocks is \"\n",
    "                         f\"{action.shipped_stocks}\"\n",
    "                         f\"\\nstate is \"\n",
    "                         f\"{state}\"\n",
    "                         f\"\\nstate.factory_stocks is \"\n",
    "                         f\"{state.factory_stocks}\"\n",
    "                         f\"\\nstate.distr_warehouses_stocks is \"\n",
    "                         f\"{state.distr_warehouses_stocks}\"\n",
    "                         f\"\\nstate.demand_history is \"\n",
    "                         f\"{state.demand_history}\"\n",
    "                         f\"\\nt is \"\n",
    "                         f\"{t}\"\n",
    "                         f\"\\nreward is \"\n",
    "                         f\"{reward}\")\n",
    "\n",
    "    logger.debug(f\"\\ntransitions_full [state, action, reward] is \"\n",
    "                 f\"{transitions_full}\"\n",
    "                 f\"\\ntransitions [state, action, reward] is \"\n",
    "                 f\"{transitions}\")\n",
    "\n",
    "    return [transitions_full, transitions]\n",
    "\n",
    "\n",
    "def simulate_gurobi(env, solver,\n",
    "                    prod_level, shipped_stocks,\n",
    "                    stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "                    constr_factory_stocks,\n",
    "                    constr_distr_warehouses_stocks,\n",
    "                    constr_scenario_tree,\n",
    "                    rolling_horizon,\n",
    "                    num_episodes=1, seed=SEED):\n",
    "    \"\"\"\n",
    "    Gurobi simulator.\n",
    "    \"\"\"\n",
    "    returns_trace_full = []\n",
    "    returns_trace = []\n",
    "    time_gurobi_testing = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        seed = None\n",
    "        if episode == 0:\n",
    "            seed = seed\n",
    "\n",
    "        start_gurobi = default_timer()\n",
    "        rt_full, rt = simulate_episode_gurobi(\n",
    "            env, solver,\n",
    "            prod_level, shipped_stocks,\n",
    "            stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "            constr_factory_stocks,\n",
    "            constr_distr_warehouses_stocks,\n",
    "            constr_scenario_tree,\n",
    "            rolling_horizon, seed)\n",
    "        end_gurobi = default_timer()\n",
    "        returns_trace_full.append(np.array(rt_full))\n",
    "        returns_trace.append(np.array(rt))\n",
    "        time_gurobi_testing.append(end_gurobi-start_gurobi)\n",
    "\n",
    "    logger.debug(f\"\\n-- simulate_gurobi --\"\n",
    "                 f\"\\nreturns_trace_full is \"\n",
    "                 f\"{returns_trace_full}\"\n",
    "                 f\"\\nreturns_trace is \"\n",
    "                 f\"{returns_trace}\")\n",
    "\n",
    "    return [returns_trace_full, returns_trace, time_gurobi_testing]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gurobi Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T13:42:30.468792Z",
     "start_time": "2023-03-29T13:42:30.440727Z"
    }
   },
   "outputs": [],
   "source": [
    "# initializing the scenario tree\n",
    "scenario_tree = ScenarioTree(branching_factors=np.repeat(4, rolling_horizon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T13:42:31.914343Z",
     "start_time": "2023-03-29T13:42:30.828375Z"
    }
   },
   "outputs": [],
   "source": [
    "# plotting the scenario tree\n",
    "scenario_tree.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T13:42:38.855044Z",
     "start_time": "2023-03-29T13:42:38.849209Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gurobi solver (with multiple scenarios)\n",
    "# https://www.gurobi.com/documentation/9.5/refman/multiple_scenarios.html\n",
    "# https://www.gurobi.com/documentation/9.5/examples/multiscenario_py.html\n",
    "solver_st = grb.Model('Gurobi_solver')\n",
    "# setting the seed\n",
    "solver_st.setParam('Seed', SEED)\n",
    "# setting the time limit (in seconds)\n",
    "solver_st.setParam('TimeLimit', 60)\n",
    "# silencing the computation output\n",
    "solver_st.setParam('OutputFlag', 0)\n",
    "# updating the solver\n",
    "solver_st.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T13:42:39.319549Z",
     "start_time": "2023-03-29T13:42:39.316050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gurobi parameters\n",
    "(initial_stocks_gurobi,\n",
    " factory_capacities_gurobi, distr_w_capacities_gurobi,\n",
    " transportation_capacities_gurobi,\n",
    " sale_prices_gurobi, production_costs_gurobi,\n",
    " transportation_costs_fixed_gurobi, transportation_costs_unit_gurobi,\n",
    " factory_storage_costs_gurobi, distr_w_storage_costs_gurobi,\n",
    " penalty_costs_gurobi) = create_parameters_gurobi(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T13:42:39.638234Z",
     "start_time": "2023-03-29T13:42:39.616879Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gurobi decision variables\n",
    "(prod_level, stocks_factory,\n",
    " shipped_stocks, stocks_distr_w_pos, stocks_distr_w_neg,\n",
    " transportation_numbers) = decision_variables_gurobi(env, solver_st,\n",
    "                                                     scenario_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T13:42:40.081633Z",
     "start_time": "2023-03-29T13:42:40.019863Z"
    }
   },
   "outputs": [],
   "source": [
    "# Gurobi constraints\n",
    "(constr_factory_stocks, constr_distr_warehouses_stocks,\n",
    " constr_scenario_tree) = constraints_gurobi(\n",
    "    env, solver_st,\n",
    "    scenario_tree,\n",
    "    prod_level, stocks_factory,\n",
    "    shipped_stocks, stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "    transportation_numbers, transportation_capacities_gurobi,\n",
    "    factory_capacities_gurobi, distr_w_capacities_gurobi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T13:42:40.976094Z",
     "start_time": "2023-03-29T13:42:40.952668Z"
    }
   },
   "outputs": [],
   "source": [
    "# reward\n",
    "reward = obj_func_gurobi(env, scenario_tree,\n",
    "                         stocks_factory,\n",
    "                         prod_level, production_costs_gurobi,\n",
    "                         stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "                         shipped_stocks, transportation_numbers,\n",
    "                         transportation_costs_fixed_gurobi,\n",
    "                         transportation_costs_unit_gurobi,\n",
    "                         factory_storage_costs_gurobi, distr_w_storage_costs_gurobi,\n",
    "                         penalty_costs_gurobi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T13:42:41.496837Z",
     "start_time": "2023-03-29T13:42:41.387652Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting the objective function\n",
    "solver_st.setObjective(reward, grb.GRB.MINIMIZE)\n",
    "# updating the solver\n",
    "solver_st.update()\n",
    "# optimizing the solver\n",
    "solver_st.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T13:42:42.245304Z",
     "start_time": "2023-03-29T13:42:42.241335Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"number of variables is {len(solver_st.getVars())}\")\n",
    "print(f\"number of constraints is {len(solver_st.getConstrs())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T13:42:59.563008Z",
     "start_time": "2023-03-29T13:42:43.480839Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# evaluating the Gurobi policy\n",
    "np.random.seed(SEED)\n",
    "env.reset(SEED)\n",
    "(returns_trace_gurobi_full, returns_trace_gurobi,\n",
    " time_gurobi_testing) = simulate_gurobi(env, solver_st,\n",
    "                                        prod_level, shipped_stocks,\n",
    "                                        stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "                                        constr_factory_stocks,\n",
    "                                        constr_distr_warehouses_stocks,\n",
    "                                        constr_scenario_tree,\n",
    "                                        rolling_horizon,\n",
    "                                        NUM_EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating and printing the Gurobi training time\n",
    "time_gurobi_total_training =  np.round((np.sum(time_gurobi_testing)), 6)\n",
    "time_gurobi_mean_training = np.round((np.mean(time_gurobi_testing)), 6)\n",
    "time_gurobi_std_training = np.round((np.std(time_gurobi_testing)), 6)\n",
    "print(f\"total training time Gurobi (in seconds) is {time_gurobi_total_training}\")\n",
    "print(f\"mean training time Gurobi (in seconds) is {time_gurobi_mean_training}\")\n",
    "print(f\"std training time Gurobi (in seconds) is {time_gurobi_std_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T13:43:39.983025Z",
     "start_time": "2023-03-29T13:43:37.322388Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_transitions(returns_trace_gurobi, 'MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:56.259401Z",
     "start_time": "2023-03-29T11:21:56.255765Z"
    }
   },
   "outputs": [],
   "source": [
    "# cumulative profit of the Gurobi policy\n",
    "cum_profit_gurobi = calculate_cum_profit(returns_trace_gurobi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:56.472222Z",
     "start_time": "2023-03-29T11:21:56.261139Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_cum_profit(cum_profit_gurobi, 'MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:56.685857Z",
     "start_time": "2023-03-29T11:21:56.474262Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_cum_profit([cum_profit_gurobi,\n",
    "                      cum_profit_ortools_det],\n",
    "                     ['MS',\n",
    "                      'PI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:56.903867Z",
     "start_time": "2023-03-29T11:21:56.688018Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_cum_profit([cum_profit_gurobi,\n",
    "                      cum_profit_ortools,\n",
    "                      cum_profit_ortools_det],\n",
    "                     ['MS',\n",
    "                      'EVPI',\n",
    "                      'PI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:56.917327Z",
     "start_time": "2023-03-29T11:21:56.906051Z"
    }
   },
   "outputs": [],
   "source": [
    "save_object(returns_trace_gurobi_full, 'transitions_full', 'MS')\n",
    "save_object(returns_trace_gurobi, 'transitions', 'MS')\n",
    "save_object(cum_profit_gurobi, 'cum_profit', 'MS')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sQ-Policy Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sQPolicy:\n",
    "    \"\"\"\n",
    "    To assess and compare performances achieved by the adopted DRL algorithms,\n",
    "    we implement a static reorder policy known in the specialized literature as\n",
    "    the (s, Q)-policy. This policy can be expressed by a rule, which can be\n",
    "    summarized as follows: at each time step t, the current stock level for a\n",
    "    specific warehouse and product type is compared to the reorder point s.\n",
    "    If the stock level falls below the reorder point s, then the (s, Q)-policy\n",
    "    orders Q units of product; otherwise, it does not take any action.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, factory_s, factory_Q, warehouses_s, warehouses_Q):\n",
    "        self.factory_s = factory_s\n",
    "        self.factory_Q = factory_Q\n",
    "        self.warehouses_s = warehouses_s\n",
    "        self.warehouses_Q = warehouses_Q\n",
    "\n",
    "        logger.debug(f\"\\n--- sQPolicy --- __init__\"\n",
    "                     f\"\\nfactory_s is \"\n",
    "                     f\"{self.factory_s}\"\n",
    "                     f\"\\nfactory_Q is \"\n",
    "                     f\"{self.factory_Q}\"\n",
    "                     f\"\\nwarehouses_s is \"\n",
    "                     f\"{self.warehouses_s}\"\n",
    "                     f\"\\nwarehouses_Q is \"\n",
    "                     f\"{self.warehouses_Q}\")\n",
    "\n",
    "    def select_action(self, state):\n",
    "        action = Action(state.product_types_num, state.distr_warehouses_num)\n",
    "\n",
    "        # reordering decisions are made independently for factory and\n",
    "        # distribution warehouses, so policy parameters (s and Q) can be\n",
    "        # different for each warehouse\n",
    "        for j in range(state.distr_warehouses_num):\n",
    "            for i in range(state.product_types_num):\n",
    "                if state.distr_warehouses_stocks[j][i] < \\\n",
    "                        self.warehouses_s[j][i]:\n",
    "                    action.shipped_stocks[j][i] = \\\n",
    "                        self.warehouses_Q[j][i]\n",
    "\n",
    "        for i in range(state.product_types_num):\n",
    "            if (state.factory_stocks[i] -\n",
    "                    np.sum(action.shipped_stocks, axis=0)[i]) < \\\n",
    "                    self.factory_s[i]:\n",
    "                action.production_level[i] = \\\n",
    "                    self.factory_Q[i]\n",
    "\n",
    "        logger.debug(f\"\\n--- sQPolicy --- select_action\"\n",
    "                     f\"\\nstate is \"\n",
    "                     f\"{state}\"\n",
    "                     f\"\\naction is \"\n",
    "                     f\"{action}\"\n",
    "                     f\"\\nstate.distr_warehouses_stocks is \"\n",
    "                     f\"{state.distr_warehouses_stocks}\"\n",
    "                     f\"\\nwarehouses_s is \"\n",
    "                     f\"{self.warehouses_s}\"\n",
    "                     f\"\\nwarehouses_Q is \"\n",
    "                     f\"{self.warehouses_Q}\"\n",
    "                     f\"\\naction.shipped_stocks is \"\n",
    "                     f\"{action.shipped_stocks}\"\n",
    "                     f\"\\nstate.factory_stocks is \"\n",
    "                     f\"{state.factory_stocks}\"\n",
    "                     f\"\\nnp.sum(action.shipped_stocks, axis=0) is \"\n",
    "                     f\"{np.sum(action.shipped_stocks, axis=0)}\"\n",
    "                     f\"\\nstate.factory_stocks - \"\n",
    "                     f\"np.sum(action.shipped_stocks, axis=0) is \"\n",
    "                     f\"\"\"{state.factory_stocks -\n",
    "                         np.sum(action.shipped_stocks, axis=0)}\"\"\"\n",
    "                     f\"\\nfactory_s is \"\n",
    "                     f\"{self.factory_s}\"\n",
    "                     f\"\\nfactory_Q is \"\n",
    "                     f\"{self.factory_Q}\"\n",
    "                     f\"\\naction.production_level is \"\n",
    "                     f\"{action.production_level}\")\n",
    "\n",
    "        return action"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sQ-Policy Config [Ax]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sQ Parameters [Ax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total trials for Ax (s, Q)-policy optimization\n",
    "total_trials_sQ = 75\n",
    "# number of episodes for each trial\n",
    "num_episodes_sQ = [NUM_EPISODES]\n",
    "# number of iterations for each number of episodes\n",
    "iterations_sQ = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sQ Parameters Methods [Ax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parameters_sQ(env):\n",
    "    \"\"\"\n",
    "    Create Ax (s, Q)-policy parameters (s and Q) for the factory, the\n",
    "    distribution warehouses and for each product type.\n",
    "    \"\"\"\n",
    "    # factory parameters\n",
    "    factory_parameters = [\n",
    "        {'name': 'factory',\n",
    "         'type': 'range',\n",
    "         'value_type': 'int', },\n",
    "    ]\n",
    "\n",
    "    factory_parameters_sQ = []\n",
    "\n",
    "    # factory parameters (s and Q) for each product type, according to storage\n",
    "    # capacities\n",
    "    for factory_parameter in factory_parameters:\n",
    "        for i in range(env.product_types_num):\n",
    "            factory_parameters_sQ.append(\n",
    "                {**factory_parameter,\n",
    "                 'name': factory_parameter['name'] + '_s_' + str(i+1),\n",
    "                 'bounds': [0, env.storage_capacities[0][i].item(0)], })\n",
    "            factory_parameters_sQ.append(\n",
    "                {**factory_parameter,\n",
    "                 'name': factory_parameter['name'] + '_Q_' + str(i+1),\n",
    "                 'bounds': [0, env.prod_level_max[i].item(0)], })\n",
    "\n",
    "    # distribution warehouses parameters\n",
    "    w_parameters = [\n",
    "        {'name': 'w',\n",
    "         'type': 'range',\n",
    "         'value_type': 'int', },\n",
    "    ]\n",
    "\n",
    "    w_parameters_sQ = []\n",
    "\n",
    "    # distribution warehouses parameters (s and Q) for each product type,\n",
    "    # according to storage capacities\n",
    "    for w_parameter in w_parameters:\n",
    "        for j in range(env.distr_warehouses_num):\n",
    "            for i in range(env.product_types_num):\n",
    "                w_parameters_sQ.append(\n",
    "                    {**w_parameter,\n",
    "                     'name': w_parameter['name'] + str(j+1) + '_s_' + str(i+1),\n",
    "                     'bounds': [0, env.storage_capacities[j+1][i].item(0)], })\n",
    "                w_parameters_sQ.append(\n",
    "                    {**w_parameter,\n",
    "                     'name': w_parameter['name'] + str(j+1) + '_Q_' + str(i+1),\n",
    "                     'bounds': [0, env.storage_capacities[j+1][i].item(0)], })\n",
    "\n",
    "    # final Ax (s, Q)-policy parameters\n",
    "    parameters_sQ = factory_parameters_sQ + w_parameters_sQ\n",
    "\n",
    "    logger.debug(f\"\\n-- create_parameters_SQ --\"\n",
    "                 f\"\\nparameters_SQ is \"\n",
    "                 f\"{parameters_sQ}\")\n",
    "\n",
    "    return parameters_sQ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator Methods [Ax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_episode_policy(env, policy, seed):\n",
    "    \"\"\"\n",
    "    Single episode simulator.\n",
    "    \"\"\"\n",
    "    env.reset(seed)\n",
    "    state = env.initial_state()\n",
    "    transitions_full = []\n",
    "    transitions = []\n",
    "\n",
    "    logger.debug(f\"\\n-- simulate_episode_policy --\"\n",
    "                 f\"\\nstate is \"\n",
    "                 f\"{state}\"\n",
    "                 f\"\\ntransitions_full is \"\n",
    "                 f\"{transitions_full}\"\n",
    "                 f\"\\ntransitions is \"\n",
    "                 f\"{transitions}\")\n",
    "\n",
    "    for t in range(env.T):\n",
    "        action = policy.select_action(state)\n",
    "        state, reward, _ = env.step(state, action)\n",
    "        transitions_full.append(np.array(\n",
    "            [state, action, reward],\n",
    "            dtype=object))\n",
    "        if (t > env.lead_times_len-1 and t < env.T-env.lead_times_len):\n",
    "            transitions.append(np.array(\n",
    "                [state, action, reward],\n",
    "                dtype=object))\n",
    "\n",
    "        logger.debug(f\"\\naction is \"\n",
    "                     f\"{action}\"\n",
    "                     f\"\\naction.production_level is \"\n",
    "                     f\"{action.production_level}\"\n",
    "                     f\"\\naction.shipped_stocks is \"\n",
    "                     f\"{action.shipped_stocks}\"\n",
    "                     f\"\\nstate is \"\n",
    "                     f\"{state}\"\n",
    "                     f\"\\nstate.factory_stocks is \"\n",
    "                     f\"{state.factory_stocks}\"\n",
    "                     f\"\\nstate.distr_warehouses_stocks is \"\n",
    "                     f\"{state.distr_warehouses_stocks}\"\n",
    "                     f\"\\nstate.demand_history is \"\n",
    "                     f\"{state.demand_history}\"\n",
    "                     f\"\\nt is \"\n",
    "                     f\"{t}\"\n",
    "                     f\"\\nreward is \"\n",
    "                     f\"{reward}\")\n",
    "\n",
    "    logger.debug(f\"\\ntransitions_full [state, action, reward] is \"\n",
    "                 f\"{transitions_full}\"\n",
    "                 f\"\\ntransitions [state, action, reward] is \"\n",
    "                 f\"{transitions}\")\n",
    "\n",
    "    return [transitions_full, transitions]\n",
    "\n",
    "\n",
    "def simulate_policy(env, policy, testing=True, num_episodes=1, seed=SEED):\n",
    "    \"\"\"\n",
    "    Simulator.\n",
    "    \"\"\"\n",
    "    returns_trace_full = []\n",
    "    returns_trace = []\n",
    "    time_policy_testing = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        seed = None\n",
    "        if testing == True and episode == 0:\n",
    "            seed = seed\n",
    "        start_policy = default_timer()\n",
    "        rt_full, rt = simulate_episode_policy(env,\n",
    "                                              policy,\n",
    "                                              seed)\n",
    "        end_policy = default_timer()\n",
    "        \n",
    "        returns_trace_full.append(np.array(rt_full))\n",
    "        returns_trace.append(np.array(rt))\n",
    "        time_policy_testing.append(end_policy-start_policy)\n",
    "\n",
    "    logger.debug(f\"\\n-- simulate_policy --\"\n",
    "                 f\"\\nreturns_trace_full is \"\n",
    "                 f\"{returns_trace_full}\"\n",
    "                 f\"\\nreturns_trace is \"\n",
    "                 f\"{returns_trace}\")\n",
    "\n",
    "    return [returns_trace_full, returns_trace, time_policy_testing]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sQ-Policy Methods [Ax]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize sQ Methods [Ax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt_func_sQ(p):\n",
    "    \"\"\"\n",
    "    Evaluation function to optimize (to maximize).\n",
    "    \"\"\"\n",
    "    args = [[],\n",
    "            [],\n",
    "            [],\n",
    "            []]\n",
    "\n",
    "    # nested list for warehouses parameters\n",
    "    args[2] = [[] for _ in range(env.distr_warehouses_num)]\n",
    "    args[3] = [[] for _ in range(env.distr_warehouses_num)]\n",
    "\n",
    "    for i in range(env.product_types_num):\n",
    "        args[0].append(p[f\"factory_s_{i+1}\"])\n",
    "        args[1].append(p[f\"factory_Q_{i+1}\"])\n",
    "        for j in range(env.distr_warehouses_num):\n",
    "            args[2][j].append(p[f\"w{j+1}_s_{i+1}\"])\n",
    "            args[3][j].append(p[f\"w{j+1}_Q_{i+1}\"])\n",
    "\n",
    "    policy = sQPolicy(*args)\n",
    "\n",
    "    return -np.mean(calculate_cum_profit(simulate_policy(env, policy,\n",
    "                                                         False, NUM_EPISODES)[0],\n",
    "                                                         print_reward=False))\n",
    "\n",
    "\n",
    "def optimize_sQ(num_episodes_sQ, iterations_sQ, parameters_sQ, total_trials_sQ,\n",
    "                seed, num_episodes=1):\n",
    "    \"\"\"\n",
    "    Brute force search through the parameter space using the Adaptive\n",
    "    Experimentation Platform developed by Facebook. This framework provides a\n",
    "    very convenient API and uses Bayesian optimization internally.\n",
    "    \"\"\"\n",
    "    best_mean_cum_profit_sQ = None\n",
    "    for num_episode_sQ in num_episodes_sQ:\n",
    "        for iteration in range(iterations_sQ):\n",
    "            # Ax optimization runs total_trials times, each trial sees a given\n",
    "            # number of episodes and this procedure is repeated for each\n",
    "            # iteration, searching the best parameters for the Ax (s, Q)-policy\n",
    "            start_sQ = default_timer()\n",
    "            parameters, values, experiment, model = optimize(\n",
    "                parameters=parameters_sQ,\n",
    "                evaluation_function=opt_func_sQ,\n",
    "                objective_name='episode_reward_mean',\n",
    "                minimize=False,\n",
    "                total_trials=total_trials_sQ,\n",
    "                random_seed=seed)\n",
    "            end_sQ = default_timer()\n",
    "            time_training_sQ = end_sQ-start_sQ\n",
    "\n",
    "            # setting the optimised parameters for current num episodes and\n",
    "            # iteration\n",
    "            policy_sQ = sQPolicy(\n",
    "                [parameters[f\"factory_s_{i+1}\"]\n",
    "                 for i in range(env.product_types_num)],\n",
    "                [parameters[f\"factory_Q_{i+1}\"]\n",
    "                 for i in range(env.product_types_num)],\n",
    "                [[parameters[f\"w{j+1}_s_{i+1}\"]\n",
    "                  for i in range(env.product_types_num)]\n",
    "                 for j in range(env.distr_warehouses_num)],\n",
    "                [[parameters[f\"w{j+1}_Q_{i+1}\"]\n",
    "                  for i in range(env.product_types_num)]\n",
    "                 for j in range(env.distr_warehouses_num)])\n",
    "\n",
    "            # evaluating the Ax (s, Q)-policy for current num episodes and\n",
    "            # iteration\n",
    "            np.random.seed(seed)\n",
    "            env.reset(seed)\n",
    "            (returns_trace_sQ_full, returns_trace_sQ,\n",
    "             time_testing_sQ) = simulate_policy(env, policy_sQ, True, num_episodes)\n",
    "            \n",
    "            # printing current num episodes and iteration\n",
    "            print(f\"--num episodes: {num_episode_sQ}, \"\n",
    "                  f\"iteration: {iteration+1}\")\n",
    "\n",
    "            # cumulative profit of the Ax (s, Q)-policy for current\n",
    "            # num episodes and iteration\n",
    "            cum_profit_sQ_full = calculate_cum_profit(returns_trace_sQ_full)\n",
    "\n",
    "            # finding the best parameters for the Ax (s, Q)-policy\n",
    "            if (best_mean_cum_profit_sQ is None or\n",
    "                    np.mean(cum_profit_sQ_full) > best_mean_cum_profit_sQ):\n",
    "                best_mean_cum_profit_sQ = np.mean(cum_profit_sQ_full)\n",
    "                best_num_episodes = num_episode_sQ\n",
    "                best_iteration = iteration\n",
    "                best_parameters = parameters\n",
    "                best_values = values\n",
    "                best_experiment = experiment\n",
    "                best_model = model\n",
    "                time_sQ = [time_training_sQ, time_testing_sQ]\n",
    "                best_policy_sQ = policy_sQ\n",
    "                best_returns_trace_sQ_full = returns_trace_sQ_full\n",
    "                best_returns_trace_sQ = returns_trace_sQ\n",
    "                best_cum_profit_sQ = calculate_cum_profit(returns_trace_sQ)\n",
    "\n",
    "    logger.debug(f\"\\n-- optimize_sQ --\"\n",
    "                 f\"\\nbest_mean_cum_profit_sQ is \"\n",
    "                 f\"{best_mean_cum_profit_sQ}\"\n",
    "                 f\"\\nbest_num_episodes is \"\n",
    "                 f\"{best_num_episodes}\"\n",
    "                 f\"\\nbest_iteration is \"\n",
    "                 f\"{best_iteration}\"\n",
    "                 f\"\\nbest_parameters is \"\n",
    "                 f\"{best_parameters}\"\n",
    "                 f\"\\nbest_values is \"\n",
    "                 f\"{best_values}\"\n",
    "                 f\"\\nbest_experiment is \"\n",
    "                 f\"{best_experiment}\"\n",
    "                 f\"\\nbest_model is \"\n",
    "                 f\"{best_model}\"\n",
    "                 f\"\\ntime_sQ is \"\n",
    "                 f\"{time_sQ}\"\n",
    "                 f\"\\nbest_policy_sQ is \"\n",
    "                 f\"{best_policy_sQ}\"\n",
    "                 f\"\\nbest_returns_trace_sQ_full is \"\n",
    "                 f\"{best_returns_trace_sQ_full}\"\n",
    "                 f\"\\nbest_returns_trace_sQ is \"\n",
    "                 f\"{best_returns_trace_sQ}\"\n",
    "                 f\"\\nbest_cum_profit_sQ is \"\n",
    "                 f\"{best_cum_profit_sQ}\")\n",
    "\n",
    "    return (best_mean_cum_profit_sQ, best_num_episodes, best_iteration,\n",
    "            best_parameters, best_values, best_experiment, best_model,\n",
    "            time_sQ, best_policy_sQ, best_returns_trace_sQ_full,\n",
    "            best_returns_trace_sQ, best_cum_profit_sQ)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Rewards Methods [Ax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_optimization_trace_sQ(experiment, verbose,\n",
    "                                    local_dir=local_dir, plots_dir=plots_dir):\n",
    "    \"\"\"\n",
    "    Plot the mean reward along the trials iterations.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        best_objectives = np.array(\n",
    "            [[trial.objective_mean\n",
    "              for trial in experiment.trials.values()]])\n",
    "        best_objective_plot = optimization_trace_single_method_plotly(\n",
    "            y=np.maximum.accumulate(best_objectives, axis=1),\n",
    "            ylabel='Reward Mean',\n",
    "            title='sQ Performance vs. Trials Iterations')\n",
    "        if verbose == 3:\n",
    "            best_objective_plot.show()\n",
    "        # creating necessary subdir and saving plot\n",
    "        if not os.path.exists(f\"{local_dir}/{plots_dir}\"\n",
    "                              f\"/sQ\"):\n",
    "            os.makedirs(f\"{local_dir}/{plots_dir}\"\n",
    "                        f\"/sQ\")\n",
    "        best_objective_plot.write_image(f\"{local_dir}/{plots_dir}\"\n",
    "                                        f\"/sQ\"\n",
    "                                        f\"/optimization_trace.pdf\")\n",
    "    except Exception as e:\n",
    "        print(f\"{e.__class__} occurred!\")\n",
    "\n",
    "\n",
    "def visualize_contour_sQ(model, parameters, env, verbose,\n",
    "                         local_dir=local_dir, plots_dir=plots_dir):\n",
    "    \"\"\"\n",
    "    Plot the contours, showing the episode reward mean as a function of two\n",
    "    selected parameters (e.g., 'factory_s_1' and 'factory_Q_1').\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # creating necessary subdir\n",
    "        if not os.path.exists(f\"{local_dir}/{plots_dir}\"\n",
    "                              f\"/sQ/contours\"):\n",
    "            os.makedirs(f\"{local_dir}/{plots_dir}\"\n",
    "                        f\"/sQ/contours\")\n",
    "\n",
    "        # saving plots\n",
    "        if env.product_types_num == 2:\n",
    "            for p in range(0,\n",
    "                           env.product_types_num,\n",
    "                           1):\n",
    "                contour = plot_contour_plotly(\n",
    "                    model=model,\n",
    "                    metric_name='episode_reward_mean',\n",
    "                    param_x=list(parameters)[p],\n",
    "                    param_y=list(parameters)[p+2])\n",
    "                contour.write_image(f\"{local_dir}/{plots_dir}\"\n",
    "                                    f\"/sQ/contours\"\n",
    "                                    f\"/contour_\"\n",
    "                                    f\"{list(parameters)[p]}_\"\n",
    "                                    f\"{list(parameters)[p+2]}.pdf\")\n",
    "                if verbose == 3:\n",
    "                    contour.show()\n",
    "            for p in range(2*env.product_types_num,\n",
    "                           len(parameters),\n",
    "                           2):\n",
    "                contour = plot_contour_plotly(\n",
    "                    model=model,\n",
    "                    metric_name='episode_reward_mean',\n",
    "                    param_x=list(parameters)[p],\n",
    "                    param_y=list(parameters)[p+1])\n",
    "                contour.write_image(f\"{local_dir}/{plots_dir}\"\n",
    "                                    f\"/sQ/contours\"\n",
    "                                    f\"/contour_\"\n",
    "                                    f\"{list(parameters)[p]}_\"\n",
    "                                    f\"{list(parameters)[p+1]}.pdf\")\n",
    "                if verbose == 3:\n",
    "                    contour.show()\n",
    "        elif env.product_types_num == 1:\n",
    "            for p in range(0,\n",
    "                           len(parameters),\n",
    "                           2):\n",
    "                contour = plot_contour_plotly(\n",
    "                    model=model,\n",
    "                    metric_name='episode_reward_mean',\n",
    "                    param_x=list(parameters)[p],\n",
    "                    param_y=list(parameters)[p+1])\n",
    "                contour.write_image(f\"{local_dir}/{plots_dir}\"\n",
    "                                    f\"/sQ/contours\"\n",
    "                                    f\"/contour_\"\n",
    "                                    f\"{list(parameters)[p]}_\"\n",
    "                                    f\"{list(parameters)[p+1]}.pdf\")\n",
    "                if verbose == 3:\n",
    "                    contour.show()\n",
    "\n",
    "        # interactive contour plot\n",
    "        if verbose == 3:\n",
    "            render(interact_contour(model=model,\n",
    "                   metric_name='episode_reward_mean'))\n",
    "    except Exception as e:\n",
    "        print(f\"{e.__class__} occurred!\")\n",
    "\n",
    "\n",
    "def move_dir_sQ(local_dir=local_dir, plots_dir=plots_dir):\n",
    "    \"\"\"\n",
    "    Move dirs whose name starts with 'sQ_' (related to all optimizations) in\n",
    "    the main sQ dir.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        src_dir = f\"{local_dir}/{plots_dir}/\"\n",
    "        dst_dir = f\"{local_dir}/{plots_dir}/sQ\"\n",
    "\n",
    "        pattern = src_dir + \"sQ_*\"\n",
    "        for file in glob.iglob(pattern, recursive=True):\n",
    "            shutil.move(file, dst_dir)\n",
    "            print('moved:', file)\n",
    "    except Exception as e:\n",
    "        print(f\"{e.__class__} occurred!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sQ-Policy Optimize [Ax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (s, Q)-policy parameters\n",
    "parameters_sQ = create_parameters_sQ(env)\n",
    "parameters_sQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (s, Q)-policy optimization\n",
    "(best_mean_cum_profit_sQ, best_num_episodes_sQ, best_iteration_sQ,\n",
    " best_parameters_sQ, best_values_sQ, best_experiment_sQ, best_model_sQ,\n",
    " time_sQ, best_policy_sQ, best_returns_trace_sQ_full,\n",
    " best_returns_trace_sQ, best_cum_profit_sQ) = \\\n",
    "    optimize_sQ(num_episodes_sQ, iterations_sQ, parameters_sQ, total_trials_sQ,\n",
    "                SEED, NUM_EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing the best Ax mean cum profit with related num episodes and iteration\n",
    "print(f\"best num episodes is {best_num_episodes_sQ} \"\n",
    "      f\"at iteration {best_iteration_sQ+1} \"\n",
    "      f\"\\nmean cum profit: {best_mean_cum_profit_sQ}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_optimization_trace_sQ(best_experiment_sQ, VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_contour_sQ(best_model_sQ, best_parameters_sQ, env, VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# displaying and saving the (s, Q)-policy best parameters\n",
    "display(best_parameters_sQ)\n",
    "save_checkpoint(str(best_parameters_sQ), 'sQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating and printing the (s, Q)-policy training time\n",
    "time_sQ_training = time_sQ[0]\n",
    "time_sQ_total_training = np.round(convert_seconds_to_min_sec(time_sQ[0]), 6)\n",
    "print(f\"total training time sQ (in minutes) is {time_sQ_total_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating and printing the (s, Q)-policy testing time\n",
    "time_sQ_testing = time_sQ[1]\n",
    "time_sQ_total_testing = np.round((np.sum(time_sQ_testing)), 6)\n",
    "time_sQ_mean_testing = np.round((np.mean(time_sQ_testing)), 6)\n",
    "time_sQ_std_testing = np.round((np.std(time_sQ_testing)), 6)\n",
    "print(f\"total testing time sQ (in seconds) is {time_sQ_total_testing}\")\n",
    "print(f\"mean testing time sQ (in seconds) is {time_sQ_mean_testing}\")\n",
    "print(f\"std testing time sQ (in seconds) is {time_sQ_std_testing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_transitions(best_returns_trace_sQ, 'sQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_cum_profit(best_cum_profit_sQ, 'sQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_cum_profit([best_cum_profit_sQ,\n",
    "                      cum_profit_ortools_det],\n",
    "                     ['sQ',\n",
    "                      'PI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving the (s, Q)-policy optimization dirs in the main sQ dir\n",
    "move_dir_sQ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_object(best_returns_trace_sQ_full, 'transitions_full', 'sQ')\n",
    "save_object(best_returns_trace_sQ, 'transitions', 'sQ')\n",
    "save_object(best_cum_profit_sQ, 'cum_profit', 'sQ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "oy1b_YoLVGRp"
   },
   "source": [
    "# Reinforcement Learning Config [Tune]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "EiwOPnzDpfbd"
   },
   "source": [
    "## Parameters [Tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.065640Z",
     "start_time": "2023-03-29T11:21:58.065620Z"
    },
    "gather": {
     "logged": 1633624174057
    }
   },
   "outputs": [],
   "source": [
    "# number of episodes for RLib agents\n",
    "num_episodes_ray = 75000\n",
    "# stop trials at least from this number of episodes\n",
    "grace_period_ray = num_episodes_ray / 10\n",
    "# number of episodes to consider\n",
    "std_episodes_ray = 5.0\n",
    "# number of epochs to wait for a change in the episodes\n",
    "top_episodes_ray = NUM_EPISODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.067197Z",
     "start_time": "2023-03-29T11:21:58.067184Z"
    },
    "gather": {
     "logged": 1633624174703
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "# dir for saving Ray results\n",
    "ray_dir = 'ray_results'\n",
    "# creating necessary dir\n",
    "if not os.path.exists(f\"{local_dir+'/'+ray_dir}\"):\n",
    "    os.makedirs(f\"{local_dir+'/'+ray_dir}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "U_CzF14Hov7E"
   },
   "source": [
    "## Algorithms [Tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.068697Z",
     "start_time": "2023-03-29T11:21:58.068675Z"
    },
    "gather": {
     "logged": 1633624175356
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "6IIRRpP90Alc"
   },
   "outputs": [],
   "source": [
    "# https://docs.ray.io/en/latest/rllib-algorithms.html\n",
    "# https://docs.ray.io/en/master/rllib-training.html#common-parameters\n",
    "# adopted algorithms\n",
    "algorithms = {\n",
    "    'PPO': ppo.PPO,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO Config [Tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.070467Z",
     "start_time": "2023-03-29T11:21:58.070451Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://docs.ray.io/en/master/rllib-algorithms.html#ppo\n",
    "config_PPO = ppo.DEFAULT_CONFIG.copy()\n",
    "config_PPO['seed'] = SEED\n",
    "config_PPO['log_level'] = 'WARN'\n",
    "\n",
    "config_PPO['env'] = SupplyChain\n",
    "config_PPO['horizon'] = env.T-1\n",
    "config_PPO['batch_mode'] = 'complete_episodes'\n",
    "\n",
    "config_PPO['model']['fcnet_hiddens'] = tune.grid_search([[64, 64]])\n",
    "config_PPO['model']['fcnet_activation'] = tune.grid_search(['relu'])\n",
    "\n",
    "config_PPO['lr'] = tune.grid_search([5e-5])\n",
    "config_PPO['gamma'] = .99\n",
    "\n",
    "config_PPO['rollout_fragment_length'] = tune.grid_search(['auto'])\n",
    "config_PPO['train_batch_size'] = tune.grid_search([8000])\n",
    "\n",
    "config_PPO['num_sgd_iter'] = tune.grid_search([15])\n",
    "config_PPO['sgd_minibatch_size'] = tune.grid_search([512])\n",
    "\n",
    "config_PPO['num_workers'] = NUM_CPUS-1\n",
    "config_PPO['num_gpus'] = NUM_GPUS\n",
    "\n",
    "config_PPO['framework'] = 'torch'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "MWsHZOfjnDcj"
   },
   "source": [
    "# Reinforcement Learning Methods [Tune]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "xOvro1oF_5ME"
   },
   "source": [
    "## Train Agents Methods [Tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.072149Z",
     "start_time": "2023-03-29T11:21:58.072135Z"
    },
    "gather": {
     "logged": 1633624177645
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "qo9YSeyxwObs"
   },
   "outputs": [],
   "source": [
    "def train(algorithm, config, verbose,\n",
    "          num_episodes_ray=num_episodes_ray, grace_period_ray=grace_period_ray,\n",
    "          std_episodes_ray=std_episodes_ray, top_episodes_ray=top_episodes_ray,\n",
    "          local_dir=local_dir, ray_dir=ray_dir):\n",
    "    \"\"\"\n",
    "    Train a RLib Agent.\n",
    "    \"\"\"\n",
    "    # initializing Ray\n",
    "    ray.shutdown()\n",
    "    ray.init(log_to_driver=False)\n",
    "\n",
    "    logger.debug(f\"\\n-- train --\"\n",
    "                 f\"\\nalgorithm is \"\n",
    "                 f\"{algorithm}\"\n",
    "                 f\"\\nconfig is \"\n",
    "                 f\"{config}\")\n",
    "\n",
    "    # https://docs.ray.io/en/latest/tune/api_docs/execution.html\n",
    "    # https://docs.ray.io/en/master/tune/api_docs/schedulers.html\n",
    "    # https://docs.ray.io/en/latest/tune/api_docs/stoppers.html\n",
    "    # https://docs.ray.io/en/master/tune/api_docs/analysis.html\n",
    "    analysis = tune.run(algorithm,\n",
    "                        config=config,\n",
    "                        metric='episode_reward_mean',\n",
    "                        mode='max',\n",
    "                        scheduler=ASHAScheduler(\n",
    "                            time_attr='episodes_total',\n",
    "                            max_t=num_episodes_ray,\n",
    "                            grace_period=grace_period_ray,\n",
    "                            reduction_factor=5),\n",
    "                        stop=CombinedStopper(\n",
    "                            ExperimentPlateauStopper(\n",
    "                                metric='episode_reward_mean',\n",
    "                                std=std_episodes_ray,\n",
    "                                top=top_episodes_ray,\n",
    "                                mode='max',\n",
    "                                patience=5),\n",
    "                            MaximumIterationStopper(\n",
    "                                max_iter=num_episodes_ray)\n",
    "                        ),\n",
    "                        checkpoint_freq=1,\n",
    "                        keep_checkpoints_num=1,\n",
    "                        checkpoint_score_attr='episode_reward_mean',\n",
    "                        progress_reporter=tune.JupyterNotebookReporter(\n",
    "                            overwrite=True),\n",
    "                        max_failures=5,\n",
    "                        verbose=verbose,\n",
    "                        local_dir=os.getcwd()+'/'+local_dir+'/'+ray_dir)\n",
    "\n",
    "    trial_dataframes = analysis.trial_dataframes\n",
    "    best_result_df = analysis.best_result_df\n",
    "    best_config = analysis.best_config\n",
    "    best_checkpoint = analysis.best_checkpoint._local_path\n",
    "    print(f\"\\ncheckpoint saved at {best_checkpoint}\")\n",
    "\n",
    "    # stopping Ray\n",
    "    ray.shutdown()\n",
    "\n",
    "    return trial_dataframes, best_result_df, best_config, best_checkpoint\n",
    "\n",
    "\n",
    "def result_df_as_image(result_df, algorithm,\n",
    "                       local_dir=local_dir, plots_dir=plots_dir):\n",
    "    \"\"\"\n",
    "    Visualize the (DataFrame) RLib Agent's result as an image.\n",
    "    \"\"\"\n",
    "    # creating necessary subdir and saving plot\n",
    "    if not os.path.exists(f\"{local_dir}/{plots_dir}/{algorithm}\"):\n",
    "        os.makedirs(f\"{local_dir}/{plots_dir}/{algorithm}\")\n",
    "    dfi.export(result_df.iloc[:, np.r_[:3, 9]],\n",
    "               f\"{local_dir}/{plots_dir}/{algorithm}\"\n",
    "               f\"/best_result_{algorithm}.png\",\n",
    "               table_conversion='matplotlib')\n",
    "    # saving pandas DataFrame as LaTeX table\n",
    "    f = open(f\"{local_dir}/{plots_dir}/{algorithm}\"\n",
    "             f\"/best_result_{algorithm}.tex\",\n",
    "             'w', encoding='utf-8')\n",
    "    f.write(result_df.iloc[:, np.r_[:3, 9]].style.to_latex())\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def calculate_training_time(result_df):\n",
    "    \"\"\"\n",
    "    Calculate a RLib Agent training time (minutes).\n",
    "    \"\"\"\n",
    "    return result_df.time_total_s[0]\n",
    "\n",
    "\n",
    "def calculate_training_episodes(result_df):\n",
    "    \"\"\"\n",
    "    Calculate a RLib Agent training episodes (number).\n",
    "    \"\"\"\n",
    "    return round(result_df.episodes_total[0],\n",
    "                 -len(str(result_df.episodes_total[0]))+2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator Methods [Tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.074488Z",
     "start_time": "2023-03-29T11:21:58.074466Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate_episode_tune(env, policy, seed):\n",
    "    \"\"\"\n",
    "    Single episode simulator.\n",
    "    \"\"\"\n",
    "    env.reset(seed)\n",
    "    state = env.initial_state()\n",
    "    transitions_full = []\n",
    "    transitions = []\n",
    "\n",
    "    logger.debug(f\"\\n-- simulate_episode_tune --\"\n",
    "                 f\"\\nstate is \"\n",
    "                 f\"{state}\"\n",
    "                 f\"\\ntransitions_full is \"\n",
    "                 f\"{transitions_full}\"\n",
    "                 f\"\\ntransitions is \"\n",
    "                 f\"{transitions}\")\n",
    "\n",
    "    for t in range(env.T):\n",
    "        action = policy.compute_single_action(state.to_array(),\n",
    "                                              normalize_actions=True,\n",
    "                                              explore=False)[0].astype(\n",
    "            np.int32)\n",
    "        action_obj = Action(env.product_types_num,\n",
    "                            env.distr_warehouses_num)\n",
    "        action_obj.production_level = np.minimum(\n",
    "            action[:env.product_types_num],\n",
    "            env.prod_level_max)\n",
    "        action_obj.shipped_stocks = action[\n",
    "            env.product_types_num:\n",
    "        ].reshape(env.distr_warehouses_num, env.product_types_num)\n",
    "\n",
    "        state, reward, _ = env.step(state, action_obj)\n",
    "        transitions_full.append(np.array(\n",
    "            [state, action_obj, reward],\n",
    "            dtype=object))\n",
    "        if (t > env.lead_times_len-1 and t < env.T-env.lead_times_len):\n",
    "            transitions.append(np.array(\n",
    "                [state, action_obj, reward],\n",
    "                dtype=object))\n",
    "\n",
    "        logger.debug(f\"\\naction is \"\n",
    "                     f\"{action}\"\n",
    "                     f\"\\naction_obj is \"\n",
    "                     f\"{action_obj}\"\n",
    "                     f\"\\naction_obj.production_level is \"\n",
    "                     f\"{action_obj.production_level}\"\n",
    "                     f\"\\naction_obj.shipped_stocks is \"\n",
    "                     f\"{action_obj.shipped_stocks}\"\n",
    "                     f\"\\nstate is \"\n",
    "                     f\"{state}\"\n",
    "                     f\"\\nstate.factory_stocks is \"\n",
    "                     f\"{state.factory_stocks}\"\n",
    "                     f\"\\nstate.distr_warehouses_stocks is \"\n",
    "                     f\"{state.distr_warehouses_stocks}\"\n",
    "                     f\"\\nstate.demand_history is \"\n",
    "                     f\"{state.demand_history}\"\n",
    "                     f\"\\nt is \"\n",
    "                     f\"{t}\"\n",
    "                     f\"\\nreward is \"\n",
    "                     f\"{reward}\")\n",
    "\n",
    "    logger.debug(f\"\\ntransitions_full [state, action, reward] is \"\n",
    "                 f\"{transitions_full}\"\n",
    "                 f\"\\ntransitions [state, action, reward] is \"\n",
    "                 f\"{transitions}\")\n",
    "\n",
    "    return [transitions_full, transitions]\n",
    "\n",
    "\n",
    "def simulate_tune(env, policy, num_episodes=1, seed=SEED):\n",
    "    \"\"\"\n",
    "    Simulator.\n",
    "    \"\"\"\n",
    "    returns_trace_full = []\n",
    "    returns_trace = []\n",
    "    time_tune = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        seed = None\n",
    "        if episode == 0:\n",
    "            seed = seed\n",
    "\n",
    "        start_tune = default_timer()\n",
    "        rt_full, rt = simulate_episode_tune(env,\n",
    "                                            policy,\n",
    "                                            seed)\n",
    "        end_tune = default_timer()\n",
    "        \n",
    "        returns_trace_full.append(np.array(rt_full))\n",
    "        returns_trace.append(np.array(rt))\n",
    "        time_tune.append(end_tune-start_tune)\n",
    "\n",
    "    logger.debug(f\"\\n-- simulate_tune --\"\n",
    "                 f\"\\nreturns_trace_full is \"\n",
    "                 f\"{returns_trace_full}\"\n",
    "                 f\"\\nreturns_trace is \"\n",
    "                 f\"{returns_trace}\")\n",
    "\n",
    "    return [returns_trace_full, returns_trace, time_tune]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "VFPY1kX_fbhI",
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Policy Methods [Tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.076524Z",
     "start_time": "2023-03-29T11:21:58.076508Z"
    },
    "gather": {
     "logged": 1633624178852
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "-J4CGhsIfbhI",
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def load_policy(algorithm, config, checkpoint):\n",
    "    \"\"\"\n",
    "    Load a RLib Agent policy.\n",
    "    \"\"\"\n",
    "    # initializing Ray\n",
    "    ray.shutdown()\n",
    "    ray.init(log_to_driver=False)\n",
    "\n",
    "    # loading policy\n",
    "    trainer = algorithm(config=config)\n",
    "    trainer.restore(f\"{checkpoint}\")\n",
    "    policy = trainer.get_policy()\n",
    "\n",
    "    # stopping Ray\n",
    "    ray.shutdown()\n",
    "\n",
    "    logger.debug(f\"\\n-- load_policy --\"\n",
    "                 f\"\\nalgorithm is \"\n",
    "                 f\"{algorithm}\"\n",
    "                 f\"\\nconfig is \"\n",
    "                 f\"{config}\"\n",
    "                 f\"\\ncheckpoint is \"\n",
    "                 f\"{checkpoint}\"\n",
    "                 f\"\\ntrainer is \"\n",
    "                 f\"{trainer}\"\n",
    "                 f\"\\npolicy is \"\n",
    "                 f\"{policy}\")\n",
    "\n",
    "    return policy\n",
    "\n",
    "\n",
    "def fix_best_checkpoint(checkpoint):\n",
    "    \"\"\"\n",
    "    Fix a RLib Agent best checkpoint path.\n",
    "    \"\"\"\n",
    "    # searching all checkpoints related to the best agent's result\n",
    "    checkpoint_dir = checkpoint.rsplit('/', 1)[0]\n",
    "    sub_dirs = [sub_dir for sub_dir in os.listdir(checkpoint_dir)\n",
    "                if os.path.isdir(os.path.join(checkpoint_dir, sub_dir))]\n",
    "    # finding the most recent checkpoint (the best one)\n",
    "    sub_dirs.sort(reverse=True)\n",
    "\n",
    "    # creating the fixed best checkpoint path\n",
    "    fixed_checkpoint_dir = checkpoint_dir + '/' + sub_dirs[0] + '/'\n",
    "    fixed_checkpoint_files = os.listdir(fixed_checkpoint_dir)\n",
    "    fixed_checkpoint_files.sort()\n",
    "    fixed_checkpoint_file = fixed_checkpoint_files[0].split('.')[0]\n",
    "    best_checkpoint = fixed_checkpoint_dir + fixed_checkpoint_file\n",
    "\n",
    "    logger.debug(f\"\\n-- fix_best_checkpoint --\"\n",
    "                 f\"\\nfixed_checkpoint_dir is \"\n",
    "                 f\"{fixed_checkpoint_dir}\"\n",
    "                 f\"\\nfixed_checkpoint_file is \"\n",
    "                 f\"{fixed_checkpoint_file}\"\n",
    "                 f\"\\nbest_checkpoint is \"\n",
    "                 f\"{best_checkpoint}\")\n",
    "\n",
    "    return best_checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Visualize Rewards Methods [Tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.078165Z",
     "start_time": "2023-03-29T11:21:58.078149Z"
    },
    "gather": {
     "logged": 1633624178272
    },
    "hideCode": true,
    "hidePrompt": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def apply_style_plot(ax, xticks_total, episodes_total, legend):\n",
    "    \"\"\"\n",
    "    Auxiliary function.\n",
    "    \"\"\"\n",
    "    ax.set_xticks([0,\n",
    "                  xticks_total//2,\n",
    "                  xticks_total])\n",
    "    ax.set_xticklabels([str(0),\n",
    "                       str(episodes_total//2),\n",
    "                       str(episodes_total)])\n",
    "    ax.set_xlabel('Episodes')\n",
    "    ax.legend(legend, bbox_to_anchor=(1.04, .5), borderaxespad=0,\n",
    "              frameon=False, loc='center left', fancybox=True, shadow=True)\n",
    "    ax.ticklabel_format(axis='y', style='plain',\n",
    "                        useOffset=False)\n",
    "\n",
    "\n",
    "def visualize_rewards(results, best_result, algorithm, legend=[],\n",
    "                      local_dir=local_dir, plots_dir=plots_dir):\n",
    "    \"\"\"\n",
    "    Visualize the min, mean and max rewards along the episodes.\n",
    "    \"\"\"\n",
    "    # creating necessary subdir and saving plot\n",
    "    if not os.path.exists(f\"{local_dir}/{plots_dir}/{algorithm}\"):\n",
    "        os.makedirs(f\"{local_dir}/{plots_dir}/{algorithm}\")\n",
    "    xticks_total = len(list(results.values())[0])-1\n",
    "    episodes_total = calculate_training_episodes(best_result)\n",
    "\n",
    "    # min reward\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    for result in results.values():\n",
    "        ax = result.episode_reward_min.plot(ax=ax)\n",
    "    apply_style_plot(ax, xticks_total, episodes_total, legend)\n",
    "    ax.set_ylabel('Min Reward')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{local_dir}/{plots_dir}/{algorithm}\"\n",
    "                f\"/episode_reward_min_{algorithm}.pdf\",\n",
    "                format='pdf', bbox_inches='tight')\n",
    "\n",
    "    # mean reward\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    for result in results.values():\n",
    "        ax = result.episode_reward_mean.plot(ax=ax)\n",
    "    apply_style_plot(ax, xticks_total, episodes_total, legend)\n",
    "    ax.set_ylabel('Mean Reward')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{local_dir}/{plots_dir}/{algorithm}\"\n",
    "                f\"/episode_reward_mean_{algorithm}.pdf\",\n",
    "                format='pdf', bbox_inches='tight')\n",
    "\n",
    "    # max reward\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    for result in results.values():\n",
    "        ax = result.episode_reward_max.plot(ax=ax)\n",
    "    apply_style_plot(ax, xticks_total, episodes_total, legend)\n",
    "    ax.set_ylabel('Max Reward')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{local_dir}/{plots_dir}/{algorithm}\"\n",
    "                f\"/episode_reward_max_{algorithm}.pdf\",\n",
    "                format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "Q61DceAPAJDN"
   },
   "source": [
    "# Reinforcement Learning Train Agents [Tune]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "SelC881AO8ro"
   },
   "source": [
    "## PPO Agent [Tune]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.080132Z",
     "start_time": "2023-03-29T11:21:58.080115Z"
    },
    "gather": {
     "logged": 1630703897399
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "Ig01XproO8r0"
   },
   "outputs": [],
   "source": [
    "# training a PPO agent\n",
    "(results_PPO, best_result_PPO,\n",
    " best_config_PPO, checkpoint_PPO) = train(algorithms['PPO'],\n",
    "                                          config_PPO,\n",
    "                                          VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.082370Z",
     "start_time": "2023-03-29T11:21:58.082351Z"
    },
    "gather": {
     "logged": 1632126612616
    },
    "hideCode": true,
    "hidePrompt": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# saving and showing the best result of the PPO agent\n",
    "result_df_as_image(best_result_PPO, 'PPO')\n",
    "best_result_PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.083804Z",
     "start_time": "2023-03-29T11:21:58.083787Z"
    },
    "gather": {
     "logged": 1632126625836
    },
    "hideCode": true,
    "hidePrompt": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_rewards(results_PPO, best_result_PPO, 'PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.085799Z",
     "start_time": "2023-03-29T11:21:58.085777Z"
    },
    "gather": {
     "logged": 1632126629117
    },
    "hideCode": true,
    "hidePrompt": true
   },
   "outputs": [],
   "source": [
    "# calculating and printing the PPO training time\n",
    "time_PPO = calculate_training_time(best_result_PPO)\n",
    "time_PPO_total_training = np.round(convert_seconds_to_min_sec(time_PPO), 6)\n",
    "print(f\"total training time PPO (in minutes) is {time_PPO_total_training}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.088213Z",
     "start_time": "2023-03-29T11:21:58.088192Z"
    },
    "gather": {
     "logged": 1632126633520
    },
    "hideCode": true,
    "hidePrompt": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# (fixing and) saving the PPO best checkpoint\n",
    "best_checkpoint_PPO = fix_best_checkpoint(checkpoint_PPO)\n",
    "save_checkpoint(best_checkpoint_PPO, 'PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.090118Z",
     "start_time": "2023-03-29T11:21:58.090100Z"
    },
    "gather": {
     "logged": 1632126647379
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "o83MXxurO8r1"
   },
   "outputs": [],
   "source": [
    "# loading the best PPO agent's policy\n",
    "policy_PPO = load_policy(algorithms['PPO'],\n",
    "                         best_config_PPO,\n",
    "                         best_checkpoint_PPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.092061Z",
     "start_time": "2023-03-29T11:21:58.092039Z"
    },
    "gather": {
     "logged": 1632126700546
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "oZ7jcRZRjsr7"
   },
   "outputs": [],
   "source": [
    "# evaluating the best PPO agent's policy\n",
    "np.random.seed(SEED)\n",
    "env.reset(SEED)\n",
    "(returns_trace_PPO_full, returns_trace_PPO,\n",
    " time_PPO_testing) = simulate_tune(env, policy_PPO, NUM_EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating and printing the PPO testing time\n",
    "time_PPO_total_testing = np.round((np.sum(time_PPO_testing)), 6)\n",
    "time_PPO_mean_testing = np.round((np.mean(time_PPO_testing)), 6)\n",
    "time_PPO_std_testing = np.round((np.std(time_PPO_testing)), 6)\n",
    "print(f\"total testing time PPO (in seconds) is {time_PPO_total_testing}\")\n",
    "print(f\"mean testing time PPO (in seconds) is {time_PPO_mean_testing}\")\n",
    "print(f\"std testing time PPO (in seconds) is {time_PPO_std_testing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.094248Z",
     "start_time": "2023-03-29T11:21:58.094200Z"
    },
    "gather": {
     "logged": 1632126709671
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "Pb7QLvQ_O8r2"
   },
   "outputs": [],
   "source": [
    "visualize_transitions(returns_trace_PPO, 'PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.095920Z",
     "start_time": "2023-03-29T11:21:58.095907Z"
    },
    "gather": {
     "logged": 1632126713957
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "6oZajepvjsr7"
   },
   "outputs": [],
   "source": [
    "# cumulative profit of the best PPO agent's policy\n",
    "cum_profit_PPO = calculate_cum_profit(returns_trace_PPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.097671Z",
     "start_time": "2023-03-29T11:21:58.097659Z"
    },
    "gather": {
     "logged": 1632126717669
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "p-_IOhFSjsr7"
   },
   "outputs": [],
   "source": [
    "visualize_cum_profit(cum_profit_PPO, 'PPO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.099648Z",
     "start_time": "2023-03-29T11:21:58.099632Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_cum_profit([cum_profit_PPO,\n",
    "                      cum_profit_ortools_det],\n",
    "                     ['PPO',\n",
    "                      'PI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.101198Z",
     "start_time": "2023-03-29T11:21:58.101182Z"
    }
   },
   "outputs": [],
   "source": [
    "save_object(returns_trace_PPO_full, 'transitions_full', 'PPO')\n",
    "save_object(returns_trace_PPO, 'transitions', 'PPO')\n",
    "save_object(cum_profit_PPO, 'cum_profit', 'PPO')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters [Heuristic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.103124Z",
     "start_time": "2023-03-29T11:21:58.103107Z"
    }
   },
   "outputs": [],
   "source": [
    "rolling_horizon = 2\n",
    "bound_demands_scenario_1 = 0\n",
    "bound_demands_scenario_2 = env.d_var[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario Tree [Heuristic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScenarioTree(nx.DiGraph):\n",
    "    def __init__(self, branching_factors, r=0,\n",
    "                 bound_demands_1=bound_demands_scenario_1,\n",
    "                 bound_demands_2=bound_demands_scenario_2):\n",
    "        nx.DiGraph.__init__(self)\n",
    "\n",
    "        self.initial_value = 0\n",
    "        self.branching_factors = branching_factors\n",
    "        self.tree_depth = len(self.branching_factors)\n",
    "        self.scenarios_num = np.prod(self.branching_factors)\n",
    "\n",
    "        # generating demands (Gurobi solver knows the episodes' demands\n",
    "        # distribution a priori)\n",
    "        stationary_demands = []\n",
    "        stationary_demands.append(np.fromfunction(\n",
    "            lambda j, i, t: env.stationary_demand(j+1, i+1, t+r),\n",
    "            (env.distr_warehouses_num, env.product_types_num, env.T),\n",
    "            dtype=np.int32))\n",
    "        stationary_demands = np.array(stationary_demands[0]).tolist()\n",
    "\n",
    "        # root node\n",
    "        self.start_node = self.initial_value\n",
    "        self.add_node(self.start_node,\n",
    "                      obs=np.repeat(self.initial_value,\n",
    "                                    env.distr_warehouses_num),\n",
    "                      prob=1,\n",
    "                      node_id=0,\n",
    "                      step=0,\n",
    "                      stage=0)\n",
    "        last_nodes_added = [self.start_node]\n",
    "        nodes_count = 1\n",
    "        nodes_per_level_num = 1\n",
    "\n",
    "        self.outcomes = [\n",
    "            [bound_demands_1] * env.distr_warehouses_num,\n",
    "            [bound_demands_2] * env.distr_warehouses_num,\n",
    "            ]\n",
    "\n",
    "        # tree nodes\n",
    "        for t in range(self.tree_depth):\n",
    "            next_stage = []\n",
    "            nodes_per_level_num *= self.branching_factors[t]\n",
    "            for node_parent in last_nodes_added:\n",
    "                self.probs_scenario = 1 / self.branching_factors[t] \n",
    "                self.demands_scenario = [stationary_demands[j][0][t]\n",
    "                                         for j in range(env.distr_warehouses_num)]\n",
    "                for b in range(self.branching_factors[t]):\n",
    "                    node_new_id = nodes_count\n",
    "                    self.add_node(node_new_id,\n",
    "                                  obs=[sum(x) for x in zip(self.demands_scenario,\n",
    "                                                           self.outcomes[b])],\n",
    "                                  prob=self.nodes[node_parent]['prob'] *\n",
    "                                  self.probs_scenario,\n",
    "                                  node_id=nodes_count,\n",
    "                                  step=t+1,\n",
    "                                  stage=t+1)\n",
    "                    self.add_edge(node_parent, node_new_id)\n",
    "                    next_stage.append(node_new_id)\n",
    "                    nodes_count += 1\n",
    "            last_nodes_added = next_stage\n",
    "            self.nodes_num = nodes_count\n",
    "        self.leaves = last_nodes_added\n",
    "\n",
    "        print(f\"\\n{self.nodes()[i]}\" for i in range(self.nodes_num))\n",
    "\n",
    "        logger.debug(f\"\\n-- ScenarioTree -- __init__\"\n",
    "                     f\"\\nbranching_factors is \"\n",
    "                     f\"{self.branching_factors}\"\n",
    "                     f\"\\ntree_depth is \"\n",
    "                     f\"{self.tree_depth}\"\n",
    "                     f\"\\nscenarios_num is \"\n",
    "                     f\"{self.scenarios_num}\"\n",
    "                     f\"\\ndemands_scenario is \"\n",
    "                     f\"{self.demands_scenario}\"\n",
    "                     f\"\\nprobs_scenario is \"\n",
    "                     f\"{self.probs_scenario}\"\n",
    "                     f\"\\nstart_node is \"\n",
    "                     f\"{self.start_node}\")\n",
    "\n",
    "    def get_leaves(self):\n",
    "        return self.leaves\n",
    "\n",
    "    def plot(self, local_dir=local_dir, plots_dir=plots_dir):\n",
    "        \"\"\"Prints the tree.\"\"\"\n",
    "        try:\n",
    "            pos = graphviz_layout(self, prog=\"dot\")\n",
    "            nx.draw(self, pos,\n",
    "                    with_labels=True, arrows=True)\n",
    "\n",
    "            # creating necessary subdir and saving plot\n",
    "            if not os.path.exists(f\"{local_dir}/{plots_dir}/MS\"):\n",
    "                os.makedirs(f\"{local_dir}/{plots_dir}/MS\")\n",
    "            plt.savefig(f\"{local_dir}/{plots_dir}/MS\"\n",
    "                        f\"/plot_ScenarioTree.pdf\",\n",
    "                        format='pdf', bbox_inches='tight')\n",
    "        except Exception as e:\n",
    "            print(f\"{e.__class__} occurred!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters Methods [Heuristic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.106385Z",
     "start_time": "2023-03-29T11:21:58.106371Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_parameters_heuristic(env):\n",
    "    \"\"\"\n",
    "    Transforms env parameters from numpy.array to lists.\n",
    "    \"\"\"\n",
    "    # capacities (as lists)\n",
    "    distr_w_capacities = env.storage_capacities.tolist()[1:]\n",
    "    transportation_capacities = env.transportation_capacities.tolist()\n",
    "\n",
    "    # costs (as lists)\n",
    "    factory_storage_costs = env.storage_costs.tolist()[0]\n",
    "    distr_w_storage_costs = env.storage_costs.tolist()[1:]\n",
    "\n",
    "    transportation_costs_fixed = env.transportation_costs_fixed.tolist()\n",
    "    transportation_costs_unit = env.transportation_costs_unit.tolist()\n",
    "\n",
    "    sale_prices = env.sale_prices.tolist()\n",
    "    penalty_costs = env.penalty_costs.tolist()\n",
    "\n",
    "    logger.debug(f\"\\n-- Heuristic -- create_parameters_heuristic\"\n",
    "                 f\"\\ndistr_w_capacities is \"\n",
    "                 f\"{distr_w_capacities}\"\n",
    "                 f\"\\ntransportation_capacities is \"\n",
    "                 f\"{transportation_capacities}\"\n",
    "                 f\"\\nfactory_storage_costs is \"\n",
    "                 f\"{factory_storage_costs}\"\n",
    "                 f\"\\ndistr_w_storage_costs is \"\n",
    "                 f\"{distr_w_storage_costs}\"\n",
    "                 f\"\\ntransportation_costs_fixed is \"\n",
    "                 f\"{transportation_costs_fixed}\"\n",
    "                 f\"\\ntransportation_costs_unit is \"\n",
    "                 f\"{transportation_costs_unit}\"\n",
    "                 f\"\\nsale_prices is \"\n",
    "                 f\"{sale_prices}\"\n",
    "                 f\"\\npenalty_costs is \"\n",
    "                 f\"{penalty_costs}\")\n",
    "\n",
    "    return (distr_w_capacities,\n",
    "            transportation_capacities,\n",
    "            factory_storage_costs, distr_w_storage_costs,\n",
    "            transportation_costs_fixed, transportation_costs_unit,\n",
    "            sale_prices, penalty_costs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Variables [Heuristic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.108086Z",
     "start_time": "2023-03-29T11:21:58.108066Z"
    }
   },
   "outputs": [],
   "source": [
    "def decision_variables_heuristic(env, solver,\n",
    "                                 scenario_tree):\n",
    "    \"\"\"\n",
    "    Defines Heuristic decision variables for each warehouse (including factory)\n",
    "    and for each product type.\n",
    "    \"\"\"\n",
    "    # factory decision variables\n",
    "    prod_level = solver.addVars(\n",
    "        scenario_tree.nodes_num,\n",
    "        vtype=grb.GRB.CONTINUOUS,\n",
    "        lb=0,\n",
    "        ub=env.prod_level_max[0],\n",
    "        name='prod_level')\n",
    "    stocks_factory = solver.addVars(\n",
    "        scenario_tree.nodes_num,\n",
    "        vtype=grb.GRB.CONTINUOUS,\n",
    "        lb=0,\n",
    "        ub=grb.GRB.INFINITY,\n",
    "        name='stocks_factory')\n",
    "\n",
    "    # distr_w decision variables\n",
    "    shipped_stocks = solver.addVars(\n",
    "        env.distr_warehouses_num, scenario_tree.nodes_num,\n",
    "        vtype=grb.GRB.CONTINUOUS,\n",
    "        lb=0,\n",
    "        ub=grb.GRB.INFINITY,\n",
    "        name='shipped_stocks')\n",
    "    stocks_distr_w_pos = solver.addVars(\n",
    "        env.distr_warehouses_num, scenario_tree.nodes_num,\n",
    "        vtype=grb.GRB.CONTINUOUS,\n",
    "        lb=0,\n",
    "        ub=grb.GRB.INFINITY,\n",
    "        name='stocks_distr_w_pos')\n",
    "    stocks_distr_w_neg = solver.addVars(\n",
    "        env.distr_warehouses_num, scenario_tree.nodes_num,\n",
    "        vtype=grb.GRB.CONTINUOUS,\n",
    "        lb=0,\n",
    "        ub=grb.GRB.INFINITY,\n",
    "        name='stocks_distr_w_neg')\n",
    "\n",
    "    # transportation decision variables\n",
    "    transportation_numbers = solver.addVars(\n",
    "        env.distr_warehouses_num, scenario_tree.nodes_num,\n",
    "        vtype=grb.GRB.CONTINUOUS,\n",
    "        lb=0,\n",
    "        ub=grb.GRB.INFINITY,\n",
    "        name='transportation_numbers')\n",
    "\n",
    "    logger.debug(f\"\\n-- Heuristic -- decision_variables_heuristic\"\n",
    "                 f\"\\nprod_level is \"\n",
    "                 f\"{prod_level}\"\n",
    "                 f\"\\nstocks_factory is \"\n",
    "                 f\"{stocks_factory}\"\n",
    "                 f\"\\nshipped_stocks is \"\n",
    "                 f\"{shipped_stocks}\"\n",
    "                 f\"\\nstocks_distr_w_pos is \"\n",
    "                 f\"{stocks_distr_w_pos}\"\n",
    "                 f\"\\nstocks_distr_w_neg is \"\n",
    "                 f\"{stocks_distr_w_neg}\"\n",
    "                 f\"\\ntransportation_numbers is \"\n",
    "                 f\"{transportation_numbers}\")\n",
    "\n",
    "    return (prod_level, stocks_factory,\n",
    "            shipped_stocks, stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "            transportation_numbers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints [Heuristic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraints_heuristic(env, solver,\n",
    "                          scenario_tree,\n",
    "                          prod_level, stocks_factory,\n",
    "                          shipped_stocks,\n",
    "                          stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "                          transportation_numbers, transportation_capacities,\n",
    "                          distr_w_capacities):\n",
    "    \"\"\"\n",
    "    Defines Heuristic constraints for each warehouse (including factory) and\n",
    "    for each product type.\n",
    "    \"\"\"\n",
    "    # step 0 action (factory)\n",
    "    action_heuristic = Action(\n",
    "        env.product_types_num,\n",
    "        env.distr_warehouses_num)\n",
    "    constr_action_prod_level = solver.addConstr(\n",
    "        prod_level[0] ==\n",
    "        action_heuristic.production_level[0],\n",
    "        name='action_prod_level_0')\n",
    "\n",
    "    # step 0 (factory and warehouses)\n",
    "    solver.addConstrs((\n",
    "        stocks_factory[n] + prod_level[n] >=\n",
    "        grb.quicksum(\n",
    "            shipped_stocks[j, n]\n",
    "            for j in range(env.distr_warehouses_num))\n",
    "            for n in range(scenario_tree.nodes_num)),\n",
    "        name='no_backlog_factory_stocks')\n",
    "    solver.addConstrs(\n",
    "        (stocks_distr_w_pos[j, n] + shipped_stocks[j, n] <=\n",
    "         distr_w_capacities[j][0]\n",
    "         for j in range(env.distr_warehouses_num)\n",
    "         for n in range(scenario_tree.nodes_num)),\n",
    "        name='distr_w_capacities')\n",
    "\n",
    "    # step 0 state (factory and warehouses)\n",
    "    state_heuristic = env.initial_state()\n",
    "    constr_factory_stocks = solver.addConstr(\n",
    "        stocks_factory[0] ==\n",
    "        state_heuristic.factory_stocks[0],\n",
    "        name='state_factory_stocks_0')\n",
    "    constr_distr_warehouses_stocks = solver.addConstrs(\n",
    "        (stocks_distr_w_pos[j, 0] - stocks_distr_w_neg[j, 0] ==\n",
    "         state_heuristic.distr_warehouses_stocks[j]\n",
    "         for j in range(env.distr_warehouses_num)),\n",
    "        name='state_distr_warehouses_stocks_0')\n",
    "\n",
    "    # steps > 0 (factory and warehouses)\n",
    "    constr_scenario_tree = []\n",
    "    for n in range(1, scenario_tree.nodes_num):\n",
    "        parent = list(scenario_tree.predecessors(n))[0]\n",
    "        solver.addConstr(\n",
    "            stocks_factory[n] ==\n",
    "            stocks_factory[parent] +\n",
    "            prod_level[parent] -\n",
    "            grb.quicksum(\n",
    "                shipped_stocks[j, parent]\n",
    "                for j in range(env.distr_warehouses_num)),\n",
    "            name=\"factory_stocks\")\n",
    "        constr_scenario_tree.append(solver.addConstrs(\n",
    "            (stocks_distr_w_pos[j, n] -\n",
    "             stocks_distr_w_neg[j, n] ==\n",
    "             stocks_distr_w_pos[j, parent] - stocks_distr_w_neg[j, parent] +\n",
    "             shipped_stocks[j, parent] - scenario_tree.nodes()[n]['obs'][j]\n",
    "             for j in range(env.distr_warehouses_num)),\n",
    "            name=\"distr_warehouses_stocks\"))\n",
    "\n",
    "    solver.addConstrs(\n",
    "        (shipped_stocks[j, n] <= transportation_numbers[j, n] *\n",
    "         transportation_capacities[j][0]\n",
    "         for j in range(env.distr_warehouses_num)\n",
    "         for n in range(scenario_tree.nodes_num)),\n",
    "        name='transportation_capacities')\n",
    "\n",
    "    return (constr_factory_stocks, constr_distr_warehouses_stocks,\n",
    "            constr_action_prod_level,\n",
    "            constr_scenario_tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function [Heuristic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.114355Z",
     "start_time": "2023-03-29T11:21:58.114325Z"
    }
   },
   "outputs": [],
   "source": [
    "def obj_func_heuristic(env, scenario_tree,\n",
    "                       stocks_factory,\n",
    "                       factory_storage_costs,\n",
    "                       stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "                       distr_w_storage_costs,\n",
    "                       shipped_stocks, transportation_numbers,\n",
    "                       transportation_costs_fixed, transportation_costs_unit,\n",
    "                       penalty_costs):\n",
    "    \"\"\"\n",
    "    Defines Gurobi objective function.\n",
    "    \"\"\"\n",
    "    # transportation costs\n",
    "    total_transportation_costs_fixed = grb.quicksum(\n",
    "        scenario_tree.nodes()[n]['prob'] *\n",
    "        transportation_costs_fixed[j][0] * transportation_numbers[j, n]\n",
    "        for j in range(env.distr_warehouses_num)\n",
    "        for n in range(scenario_tree.nodes_num))\n",
    "    total_transportation_costs_unit = grb.quicksum(\n",
    "        scenario_tree.nodes()[n]['prob'] *\n",
    "        transportation_costs_unit[j][0] * shipped_stocks[j, n]\n",
    "        for j in range(env.distr_warehouses_num)\n",
    "        for n in range(scenario_tree.nodes_num))\n",
    "    total_transportation_costs = total_transportation_costs_fixed + \\\n",
    "        total_transportation_costs_fixed\n",
    "\n",
    "    # storage costs\n",
    "    total_factory_storage_costs = grb.quicksum(\n",
    "        scenario_tree.nodes()[n]['prob'] *\n",
    "        factory_storage_costs[0] * stocks_factory[n]\n",
    "        for n in range(scenario_tree.nodes_num))\n",
    "    total_distr_w_storage_costs = grb.quicksum(\n",
    "        scenario_tree.nodes()[n]['prob'] *\n",
    "        distr_w_storage_costs[j][0] * stocks_distr_w_pos[j, n]\n",
    "        for j in range(env.distr_warehouses_num)\n",
    "        for n in range(scenario_tree.nodes_num))\n",
    "    total_storage_costs = total_factory_storage_costs + \\\n",
    "        total_distr_w_storage_costs\n",
    "\n",
    "    # penalty costs\n",
    "    total_distr_w_penalty_costs = grb.quicksum(\n",
    "        scenario_tree.nodes()[n]['prob'] *\n",
    "        penalty_costs[0] * stocks_distr_w_neg[j, n]\n",
    "        for j in range(env.distr_warehouses_num)\n",
    "        for n in range(scenario_tree.nodes_num))\n",
    "    total_penalty_costs = total_distr_w_penalty_costs\n",
    "\n",
    "    # reward\n",
    "    reward = \\\n",
    "        total_transportation_costs + total_storage_costs + total_penalty_costs\n",
    "\n",
    "    logger.debug(f\"\\n--- Gurobi --- objective_function_gurobi\"\n",
    "                 f\"\\ntotal_transportation_costs_fixed is \"\n",
    "                 f\"{total_transportation_costs_fixed}\"\n",
    "                 f\"\\ntotal_transportation_costs_unit is \"\n",
    "                 f\"{total_transportation_costs_unit}\"\n",
    "                 f\"\\ntotal_transportation_costs is \"\n",
    "                 f\"{total_transportation_costs}\"\n",
    "                 f\"\\ntotal_storage_costs is \"\n",
    "                 f\"{total_storage_costs}\"\n",
    "                 f\"\\ntotal_penalty_costs is \"\n",
    "                 f\"{total_penalty_costs}\"\n",
    "                 f\"\\nreward is \"\n",
    "                 f\"{reward}\")\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulator Methods [Heuristic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.116215Z",
     "start_time": "2023-03-29T11:21:58.116201Z"
    }
   },
   "outputs": [],
   "source": [
    "def simulate_episode_heuristic(env, solver, policy,\n",
    "                               prod_level, shipped_stocks,\n",
    "                               stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "                               constr_factory_stocks,\n",
    "                               constr_distr_warehouses_stocks,\n",
    "                               constr_action_prod_level,\n",
    "                               constr_scenario_tree,\n",
    "                               rolling_horizon, seed):\n",
    "    \"\"\"\n",
    "    Single episode simulator.\n",
    "    \"\"\"\n",
    "    env.reset(seed)\n",
    "    state = env.initial_state()\n",
    "    transitions_full = []\n",
    "    transitions = []\n",
    "\n",
    "    logger.debug(f\"\\n-- simulate_episode_heuristic --\"\n",
    "                 f\"\\nstate is \"\n",
    "                 f\"{state}\"\n",
    "                 f\"\\ntransitions_full is \"\n",
    "                 f\"{transitions_full}\"\n",
    "                 f\"\\ntransitions is \"\n",
    "                 f\"{transitions}\")\n",
    "\n",
    "    for t in range(env.T):\n",
    "        # RLib action\n",
    "        action = policy.compute_single_action(state.to_array(),\n",
    "                                              normalize_actions=True,\n",
    "                                              explore=False)[0].astype(\n",
    "            np.int32)\n",
    "\n",
    "        action_obj = Action(env.product_types_num,\n",
    "                            env.distr_warehouses_num)\n",
    "        action_obj.production_level = np.minimum(\n",
    "            action[:env.product_types_num],\n",
    "            env.prod_level_max)\n",
    "        action_obj.shipped_stocks = action[\n",
    "            env.product_types_num:\n",
    "        ].reshape(env.distr_warehouses_num, env.product_types_num)\n",
    "\n",
    "        # heuristic action\n",
    "        action_heuristic = Action(env.product_types_num,\n",
    "                                  env.distr_warehouses_num)\n",
    "        action_heuristic.production_level = \\\n",
    "            np.minimum(\n",
    "                action_obj.production_level,\n",
    "                env.storage_capacities[0] - state.factory_stocks)\n",
    "\n",
    "        # scenario tree\n",
    "        scenario_tree = ScenarioTree(branching_factors=np.repeat(\n",
    "            2, rolling_horizon),\n",
    "            r=t)\n",
    "        for i in range(env.product_types_num):\n",
    "            constr_action_prod_level.rhs = \\\n",
    "                action_heuristic.production_level[i]\n",
    "            constr_factory_stocks.rhs = state.factory_stocks[i]\n",
    "        for j in range(env.distr_warehouses_num):\n",
    "            for i in range(env.product_types_num):\n",
    "                constr_distr_warehouses_stocks[j].rhs = \\\n",
    "                    state.distr_warehouses_stocks[j][i]\n",
    "\n",
    "        for n in range(1, scenario_tree.nodes_num):\n",
    "            parent = list(scenario_tree.predecessors(n))[0]\n",
    "            solver.remove(constr_scenario_tree[n-1])\n",
    "            constr_scenario_tree[n-1] = solver.addConstrs(\n",
    "                (stocks_distr_w_pos[j, n] - stocks_distr_w_neg[j, n] ==\n",
    "                 stocks_distr_w_pos[j, parent] -\n",
    "                 stocks_distr_w_neg[j, parent] +\n",
    "                 shipped_stocks[j, parent] - scenario_tree.nodes()[n]['obs'][j]\n",
    "                 for j in range(env.distr_warehouses_num)),\n",
    "                name=\"distr_warehouses_stocks\")\n",
    "\n",
    "        # updating the model\n",
    "        solver.update()\n",
    "        if not os.path.exists(f\"{local_dir}/{plots_dir}/DRL-MS\"):\n",
    "            os.makedirs(f\"{local_dir}/{plots_dir}/DRL-MS\")\n",
    "            solver.write(f\"{local_dir}/{plots_dir}/DRL-MS\"\n",
    "                         f\"/DRL-MS_{t}.lp\")\n",
    "        # solving the model\n",
    "        solver.optimize()\n",
    "        if solver.Status in (grb.GRB.INF_OR_UNBD,\n",
    "                             grb.GRB.INFEASIBLE,\n",
    "                             grb.GRB.UNBOUNDED):\n",
    "            print(f\"THE MODEL CANNOT BE SOLVED! ({solver.Status})\")\n",
    "        else:\n",
    "            if solver.Status != grb.GRB.OPTIMAL:\n",
    "                print(f\"SOLUTION NON OPTIMAL! ({solver.Status})\")\n",
    "            else:\n",
    "                print(f\"SOLUTION OPTIMAL! ({solver.Status})\")\n",
    "            for j in range(state.distr_warehouses_num):\n",
    "                for i in range(state.product_types_num):\n",
    "                    action_heuristic.shipped_stocks[j][i] = \\\n",
    "                        shipped_stocks[j, 0].X\n",
    "\n",
    "        state, reward, _ = env.step(state, action_heuristic)\n",
    "        transitions_full.append(np.array(\n",
    "            [state, action_heuristic, reward],\n",
    "            dtype=object))\n",
    "        if (t > env.lead_times_len-1 and t < env.T-env.lead_times_len):\n",
    "            transitions.append(np.array(\n",
    "                [state, action_heuristic, reward],\n",
    "                dtype=object))\n",
    "\n",
    "        logger.debug(f\"\\naction is \"\n",
    "                     f\"{action}\"\n",
    "                     f\"\\naction_obj is \"\n",
    "                     f\"{action_obj}\"\n",
    "                     f\"\\naction_obj.production_level is \"\n",
    "                     f\"{action_obj.production_level}\"\n",
    "                     f\"\\naction_obj.shipped_stocks is \"\n",
    "                     f\"{action_obj.shipped_stocks}\"\n",
    "                     f\"\\naction_heuristic is \"\n",
    "                     f\"{action_heuristic}\"\n",
    "                     f\"\\naction_heuristic.production_level is \"\n",
    "                     f\"{action_heuristic.production_level}\"\n",
    "                     f\"\\naction_heuristic.shipped_stocks is \"\n",
    "                     f\"{action_heuristic.shipped_stocks}\"\n",
    "                     f\"\\nstate is \"\n",
    "                     f\"{state}\"\n",
    "                     f\"\\nstate.factory_stocks is \"\n",
    "                     f\"{state.factory_stocks}\"\n",
    "                     f\"\\nstate.distr_warehouses_stocks is \"\n",
    "                     f\"{state.distr_warehouses_stocks}\"\n",
    "                     f\"\\nstate.demand_history is \"\n",
    "                     f\"{state.demand_history}\"\n",
    "                     f\"\\nt is \"\n",
    "                     f\"{t}\"\n",
    "                     f\"\\nreward is \"\n",
    "                     f\"{reward}\")\n",
    "\n",
    "    logger.debug(f\"\\ntransitions_full [state, action, reward] is \"\n",
    "                 f\"{transitions_full}\"\n",
    "                 f\"\\ntransitions [state, action, reward] is \"\n",
    "                 f\"{transitions}\")\n",
    "\n",
    "    return [transitions_full, transitions]\n",
    "\n",
    "\n",
    "def simulate_heuristic(env, solver, policy,\n",
    "                       prod_level, shipped_stocks,\n",
    "                       stocks_dist_w_pos, stocks_dist_w_neg,\n",
    "                       constr_factory_stocks,\n",
    "                       constr_distr_warehouses_stocks,\n",
    "                       constr_action_prod_level,\n",
    "                       constr_scenario_tree,\n",
    "                       rolling_horizon,\n",
    "                       num_episodes=1, seed=SEED):\n",
    "    \"\"\"\n",
    "    Simulator.\n",
    "    \"\"\"\n",
    "    returns_trace_full = []\n",
    "    returns_trace = []\n",
    "    time_heuristic = []\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        seed = None\n",
    "        if episode == 0:\n",
    "            seed = seed\n",
    "\n",
    "        start_heuristic = default_timer()\n",
    "        rt_full, rt = simulate_episode_heuristic(\n",
    "            env, solver, policy,\n",
    "            prod_level, shipped_stocks,\n",
    "            stocks_dist_w_pos, stocks_dist_w_neg,\n",
    "            constr_factory_stocks,\n",
    "            constr_distr_warehouses_stocks,\n",
    "            constr_action_prod_level,\n",
    "            constr_scenario_tree,\n",
    "            rolling_horizon, seed)\n",
    "        end_heuristic = default_timer()\n",
    "        \n",
    "        returns_trace_full.append(np.array(rt_full))\n",
    "        returns_trace.append(np.array(rt))\n",
    "        time_heuristic.append(end_heuristic-start_heuristic)\n",
    "\n",
    "    logger.debug(f\"\\n-- simulate_heuristic --\"\n",
    "                 f\"\\nreturns_trace_full is \"\n",
    "                 f\"{returns_trace_full}\"\n",
    "                 f\"\\nreturns_trace is \"\n",
    "                 f\"{returns_trace}\")\n",
    "\n",
    "    return [returns_trace_full, returns_trace, time_heuristic]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heuristic Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.118211Z",
     "start_time": "2023-03-29T11:21:58.118185Z"
    }
   },
   "outputs": [],
   "source": [
    "# initializing the scenario tree\n",
    "scenario_tree = ScenarioTree(branching_factors=np.repeat(2, rolling_horizon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.120627Z",
     "start_time": "2023-03-29T11:21:58.120603Z"
    }
   },
   "outputs": [],
   "source": [
    "# heuristic solver (with multiple scenarios)\n",
    "# https://www.gurobi.com/documentation/9.5/refman/multiple_scenarios.html\n",
    "# https://www.gurobi.com/documentation/9.5/examples/multiscenario_py.html\n",
    "solver_h = grb.Model('Heuristic_solver')\n",
    "# setting the seed\n",
    "solver_h.setParam('Seed', SEED)\n",
    "# setting the time limit (in seconds)\n",
    "solver_h.setParam('TimeLimit', 30)\n",
    "# silencing the computation output\n",
    "solver_h.setParam('OutputFlag', 0)\n",
    "# updating the solver\n",
    "solver_h.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.123294Z",
     "start_time": "2023-03-29T11:21:58.123266Z"
    }
   },
   "outputs": [],
   "source": [
    "# heuristic parameters\n",
    "(distr_w_capacities_heuristic,\n",
    " transportation_capacities_heuristic,\n",
    " factory_storage_costs_heuristic, distr_w_storage_costs_heuristic,\n",
    " transportation_costs_fixed_heuristic, transportation_costs_unit_heuristic,\n",
    " sale_prices_heuristic, penalty_costs_heuristic) = create_parameters_heuristic(\n",
    "    env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.125899Z",
     "start_time": "2023-03-29T11:21:58.125876Z"
    }
   },
   "outputs": [],
   "source": [
    "# heuristic decision variables\n",
    "(prod_level, stocks_factory,\n",
    " shipped_stocks, stocks_distr_w_pos, stocks_distr_w_neg,\n",
    " transportation_numbers) = decision_variables_heuristic(env, solver_h,\n",
    "                                                        scenario_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.128429Z",
     "start_time": "2023-03-29T11:21:58.128404Z"
    }
   },
   "outputs": [],
   "source": [
    "# heuristic constraints\n",
    "(constr_factory_stocks, constr_distr_warehouses_stocks,\n",
    " constr_action_prod_level, constr_scenario_tree) = constraints_heuristic(\n",
    "    env, solver_h,\n",
    "    scenario_tree,\n",
    "    prod_level, stocks_factory,\n",
    "    shipped_stocks,\n",
    "    stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "    transportation_numbers, transportation_capacities_heuristic,\n",
    "    distr_w_capacities_heuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.130763Z",
     "start_time": "2023-03-29T11:21:58.130741Z"
    }
   },
   "outputs": [],
   "source": [
    "# reward\n",
    "reward = obj_func_heuristic(env, scenario_tree,\n",
    "                            stocks_factory,\n",
    "                            factory_storage_costs_heuristic,\n",
    "                            stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "                            distr_w_storage_costs_heuristic,\n",
    "                            shipped_stocks, transportation_numbers,\n",
    "                            transportation_costs_fixed_heuristic,\n",
    "                            transportation_costs_unit_heuristic,\n",
    "                            penalty_costs_heuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.132804Z",
     "start_time": "2023-03-29T11:21:58.132781Z"
    }
   },
   "outputs": [],
   "source": [
    "# setting the objective function\n",
    "solver_h.setObjective(reward, grb.GRB.MINIMIZE)\n",
    "# updating the solver\n",
    "solver_h.update()\n",
    "# optimizing the solver\n",
    "solver_h.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.135241Z",
     "start_time": "2023-03-29T11:21:58.135218Z"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"number of variables is {len(solver_h.getVars())}\")\n",
    "print(f\"number of constraints is {len(solver_h.getConstrs())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.137667Z",
     "start_time": "2023-03-29T11:21:58.137643Z"
    }
   },
   "outputs": [],
   "source": [
    "# evaluating the best heuristic agent's policy\n",
    "np.random.seed(SEED)\n",
    "env.reset(SEED)\n",
    "(returns_trace_heuristic_full, returns_trace_heuristic,\n",
    " time_heuristic) = simulate_heuristic(env, solver_h, policy_PPO,\n",
    "                                      prod_level, shipped_stocks,\n",
    "                                      stocks_distr_w_pos, stocks_distr_w_neg,\n",
    "                                      constr_factory_stocks,\n",
    "                                      constr_distr_warehouses_stocks,\n",
    "                                      constr_action_prod_level,\n",
    "                                      constr_scenario_tree,\n",
    "                                      rolling_horizon,\n",
    "                                      NUM_EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating and printing the heuristic testing time\n",
    "time_heuristic_total_testing = np.round((np.sum(time_heuristic)), 6)\n",
    "time_heuristic_mean_testing = np.round((np.mean(time_heuristic)), 6)\n",
    "time_heuristic_std_testing = np.round((np.std(time_heuristic)), 6)\n",
    "print(f\"total testing time heuristic (in seconds) is {time_heuristic_total_testing}\")\n",
    "print(f\"mean testing time heuristic (in seconds) is {time_heuristic_mean_testing}\")\n",
    "print(f\"std testing time heuristic (in seconds) is {time_heuristic_std_testing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.140155Z",
     "start_time": "2023-03-29T11:21:58.140135Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_transitions(returns_trace_heuristic, 'DRL-MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.144582Z",
     "start_time": "2023-03-29T11:21:58.144563Z"
    }
   },
   "outputs": [],
   "source": [
    "# cumulative profit of the heuristic policy\n",
    "cum_profit_heuristic = calculate_cum_profit(returns_trace_heuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.146658Z",
     "start_time": "2023-03-29T11:21:58.146613Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_cum_profit(cum_profit_heuristic, 'DRL-MS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.149802Z",
     "start_time": "2023-03-29T11:21:58.149739Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_cum_profit([cum_profit_heuristic,\n",
    "                      cum_profit_PPO],\n",
    "                     ['DRL-MS',\n",
    "                      'DRL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.152976Z",
     "start_time": "2023-03-29T11:21:58.152952Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_cum_profit([cum_profit_heuristic,\n",
    "                      cum_profit_gurobi],\n",
    "                     ['DRL-MS',\n",
    "                      'MS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.155309Z",
     "start_time": "2023-03-29T11:21:58.155289Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_cum_profit([cum_profit_heuristic,\n",
    "                      cum_profit_ortools_det],\n",
    "                     ['DRL-MS',\n",
    "                      'PI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.158051Z",
     "start_time": "2023-03-29T11:21:58.158029Z"
    }
   },
   "outputs": [],
   "source": [
    "save_object(returns_trace_heuristic_full, 'transitions_full', 'DRL-MS')\n",
    "save_object(returns_trace_heuristic, 'transitions', 'DRL-MS')\n",
    "save_object(cum_profit_heuristic, 'cum_profit', 'DRL-MS')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "pgR6ta4sjsr9"
   },
   "source": [
    "# Final Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## Cumulative Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.160764Z",
     "start_time": "2023-03-29T11:21:58.160740Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_cum_profit([cum_profit_heuristic,\n",
    "                      cum_profit_PPO,\n",
    "                      cum_profit_gurobi,\n",
    "                      cum_profit_ortools_det],\n",
    "                     ['DRL-MS',\n",
    "                      'DRL',\n",
    "                      'MS',\n",
    "                      'PI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.162706Z",
     "start_time": "2023-03-29T11:21:58.162684Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_cum_profit([cum_profit_heuristic,\n",
    "                      cum_profit_PPO,\n",
    "                      cum_profit_gurobi,\n",
    "                      cum_profit_ortools,\n",
    "                      cum_profit_ortools_det],\n",
    "                     ['DRL-MS',\n",
    "                      'DRL',\n",
    "                      'MS',\n",
    "                      'EVPI',\n",
    "                      'PI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.166391Z",
     "start_time": "2023-03-29T11:21:58.166368Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_cum_profit([cum_profit_heuristic,\n",
    "                      cum_profit_PPO,\n",
    "                      best_cum_profit_sQ,\n",
    "                      cum_profit_gurobi,\n",
    "                      cum_profit_ortools,\n",
    "                      cum_profit_ortools_det],\n",
    "                     ['DRL-MS',\n",
    "                      'DRL',\n",
    "                      'sQ',\n",
    "                      'MS',\n",
    "                      'EVPI',\n",
    "                      'PI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.167778Z",
     "start_time": "2023-03-29T11:21:58.167765Z"
    }
   },
   "outputs": [],
   "source": [
    "# cumulative profit of all policies\n",
    "cum_profit_total = {\n",
    "    'Algorithm':\n",
    "    ['DRL-MS',\n",
    "     'DRL',\n",
    "     'sQ',\n",
    "     'MS',\n",
    "     'EVPI',\n",
    "     'PI'],\n",
    "    'Cumulative Costs':\n",
    "    [f\"{int(np.round(np.mean(cum_profit_heuristic), 0))}\"\n",
    "     f\" +- {int(np.round(np.std(cum_profit_heuristic), 0))}\",\n",
    "     f\"{int(np.round(np.mean(cum_profit_PPO), 0))}\"\n",
    "     f\" +- {int(np.round(np.std(cum_profit_PPO), 0))}\",\n",
    "     f\"{int(np.round(np.mean(best_cum_profit_sQ), 0))}\"\n",
    "     f\" +- {int(np.round(np.std(best_cum_profit_sQ), 0))}\",\n",
    "     f\"{int(np.round(np.mean(cum_profit_gurobi), 0))}\"\n",
    "     f\" +- {int(np.round(np.std(cum_profit_gurobi), 0))}\",\n",
    "     f\"{int(np.round(np.mean(cum_profit_ortools), 0))}\"\n",
    "     f\" +- {int(np.round(np.std(cum_profit_ortools), 0))}\",\n",
    "     f\"{int(np.round(np.mean(cum_profit_ortools_det), 0))}\"\n",
    "     f\" +- {int(np.round(np.std(cum_profit_ortools_det), 0))}\"]\n",
    "}\n",
    "# creating pandas DataFrame\n",
    "cum_profit_total_df = pd.DataFrame(data=cum_profit_total)\n",
    "cum_profit_total_df.set_index('Algorithm', inplace=True)\n",
    "# saving pandas DataFrame as an image\n",
    "dfi.export(cum_profit_total_df,\n",
    "           f\"{local_dir}/{plots_dir}\"\n",
    "           f\"/cum_profit_total_df.png\",\n",
    "           table_conversion='matplotlib')\n",
    "# saving pandas DataFrame as LaTeX table\n",
    "f = open(f\"{local_dir}/{plots_dir}\"\n",
    "         f\"/cum_profit_total_df.tex\",\n",
    "         'w', encoding='utf-8')\n",
    "f.write(cum_profit_total_df.style.to_latex())\n",
    "f.close()\n",
    "# printing training time of all policies\n",
    "print(tabulate(cum_profit_total_df, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.169847Z",
     "start_time": "2023-03-29T11:21:58.169827Z"
    }
   },
   "outputs": [],
   "source": [
    "# optimality gap of all policies (with respect to the Gurobi policy)\n",
    "cum_profit_heuristic = np.array(cum_profit_heuristic)\n",
    "cum_profit_PPO = np.array(cum_profit_PPO)\n",
    "best_cum_profit_sQ = np.array(best_cum_profit_sQ)\n",
    "cum_profit_gurobi = np.array(cum_profit_gurobi)\n",
    "cum_profit_ortools = np.array(cum_profit_ortools)\n",
    "cum_profit_ortools_det = np.array(cum_profit_ortools_det)\n",
    "\n",
    "gap_heuristic = (\n",
    "    (cum_profit_heuristic - cum_profit_gurobi) / cum_profit_gurobi) * 100\n",
    "gap_PPO = (\n",
    "    (cum_profit_PPO - cum_profit_gurobi) / cum_profit_gurobi) * 100\n",
    "gap_sQ = (\n",
    "    (best_cum_profit_sQ - cum_profit_gurobi) / cum_profit_gurobi) * 100\n",
    "gap_gurobi = (\n",
    "    (cum_profit_gurobi - cum_profit_gurobi) / cum_profit_gurobi) * 100\n",
    "gap_ortools = (\n",
    "    (cum_profit_ortools - cum_profit_gurobi) / cum_profit_gurobi) * 100\n",
    "gap_ortools_det = (\n",
    "    (cum_profit_ortools_det - cum_profit_gurobi) / cum_profit_gurobi) * 100\n",
    "\n",
    "gurobi_gap = {\n",
    "    'Algorithm':\n",
    "    ['DRL-MS',\n",
    "     'DRL',\n",
    "     'sQ',\n",
    "     'MS',\n",
    "     'EVPI',\n",
    "     'PI'],\n",
    "    'MS Gap':\n",
    "    [f\"{np.round(np.mean(gap_heuristic), 2)}\"\n",
    "     f\" +- {np.round(np.std(gap_heuristic), 2)}\",\n",
    "     f\"{np.round(np.mean(gap_PPO), 2)}\"\n",
    "     f\" +- {np.round(np.std(gap_PPO), 2)}\",\n",
    "     f\"{np.round(np.mean(gap_sQ), 2)}\"\n",
    "     f\" +- {np.round(np.std(gap_sQ), 2)}\",\n",
    "     f\"{np.round(np.mean(gap_gurobi), 2)}\"\n",
    "     f\" +- {np.round(np.std(gap_gurobi), 2)}\",\n",
    "     f\"{np.round(np.mean(gap_ortools), 2)}\"\n",
    "     f\" +- {np.round(np.std(gap_ortools), 2)}\",\n",
    "     f\"{np.round(np.mean(gap_ortools_det), 2)}\"\n",
    "     f\" +- {np.round(np.std(gap_ortools_det), 2)}\"]\n",
    "}\n",
    "# creating pandas DataFrame\n",
    "gurobi_gap_df = pd.DataFrame(data=gurobi_gap)\n",
    "gurobi_gap_df.set_index('Algorithm', inplace=True)\n",
    "# saving pandas DataFrame as an image\n",
    "dfi.export(gurobi_gap_df,\n",
    "           f\"{local_dir}/{plots_dir}\"\n",
    "           f\"/gurobi_gap_df.png\",\n",
    "           table_conversion='matplotlib')\n",
    "# saving pandas DataFrame as LaTeX table\n",
    "f = open(f\"{local_dir}/{plots_dir}\"\n",
    "         f\"/gurobi_gap_df.tex\",\n",
    "         'w', encoding='utf-8')\n",
    "f.write(gurobi_gap_df.style.to_latex())\n",
    "f.close()\n",
    "# printing training time of all policies\n",
    "print(tabulate(gurobi_gap_df, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.171417Z",
     "start_time": "2023-03-29T11:21:58.171401Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_hist_costs(cum_profit_PPO, cum_profit_heuristic,\n",
    "                   local_dir=local_dir, plots_dir=plots_dir):\n",
    "    \"\"\"\n",
    "    Visualize an histogram between the PPO and heuristic gaps.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlabel('Total Costs [k€]')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # plotting plot\n",
    "    plt.hist(cum_profit_PPO, bins=22,\n",
    "             color='blue', alpha=.5, histtype='bar', label='PPO')\n",
    "    plt.hist(cum_profit_heuristic, bins=8,\n",
    "             color='green', alpha=.5, histtype='bar', label='DRLBD')\n",
    "\n",
    "    # plotting legend\n",
    "    plt.legend()\n",
    "\n",
    "    # saving plot\n",
    "    plt.savefig(f\"{local_dir}/{plots_dir}\"\n",
    "                f\"/gurobi_gap_hist_costs.pdf\",\n",
    "                format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.173229Z",
     "start_time": "2023-03-29T11:21:58.173211Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_hist_costs(cum_profit_PPO, cum_profit_heuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hist_gap(gap_PPO, gap_heuristic,\n",
    "                   local_dir=local_dir, plots_dir=plots_dir):\n",
    "    \"\"\"\n",
    "    Visualize an histogram between the PPO and heuristic gaps.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.xlabel('Opt-gap [%]')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # plotting plot\n",
    "    plt.hist(gap_PPO, bins=20,\n",
    "             color='blue', alpha=.5, histtype='bar', label='PPO')\n",
    "    plt.hist(gap_heuristic, bins=15,\n",
    "             color='green', alpha=.5, histtype='bar', label='DRLBD')\n",
    "\n",
    "    # plotting legend\n",
    "    plt.legend()\n",
    "\n",
    "    # saving plot\n",
    "    plt.savefig(f\"{local_dir}/{plots_dir}\"\n",
    "                f\"/gurobi_gap_hist_gap.pdf\",\n",
    "                format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_hist_gap(gap_PPO, gap_heuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_arrays(arr1, arr2):\n",
    "    count = 0\n",
    "    indices = []\n",
    "    # Assume arr1 and arr2 have the same length\n",
    "    for i in range(len(arr1)):\n",
    "        if arr1[i] > arr2[i]:\n",
    "            count += 1\n",
    "            indices.append(i)\n",
    "    return count, indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_arrays(cum_profit_ortools_det, cum_profit_ortools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_arrays(cum_profit_ortools_det, best_cum_profit_sQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_arrays(cum_profit_ortools_det, cum_profit_PPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_arrays(cum_profit_ortools_det, cum_profit_heuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_arrays(cum_profit_gurobi, cum_profit_ortools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_arrays(cum_profit_gurobi, best_cum_profit_sQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_arrays(cum_profit_gurobi, cum_profit_PPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_arrays(cum_profit_gurobi, cum_profit_heuristic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.176008Z",
     "start_time": "2023-03-29T11:21:58.175984Z"
    }
   },
   "outputs": [],
   "source": [
    "# optimality gap of all policies (with respect to the ortools policy)\n",
    "cum_profit_heuristic = np.array(cum_profit_heuristic)\n",
    "cum_profit_PPO = np.array(cum_profit_PPO)\n",
    "best_cum_profit_sQ = np.array(best_cum_profit_sQ)\n",
    "cum_profit_gurobi = np.array(cum_profit_gurobi)\n",
    "cum_profit_ortools = np.array(cum_profit_ortools)\n",
    "cum_profit_ortools_det = np.array(cum_profit_ortools_det)\n",
    "\n",
    "gap_heuristic = (\n",
    "    (cum_profit_heuristic - cum_profit_ortools_det) / cum_profit_ortools_det) * 100\n",
    "gap_PPO = (\n",
    "    (cum_profit_PPO - cum_profit_ortools_det) / cum_profit_ortools_det) * 100\n",
    "gap_sQ = (\n",
    "    (best_cum_profit_sQ - cum_profit_ortools_det) / cum_profit_ortools_det) * 100\n",
    "gap_gurobi = (\n",
    "    (cum_profit_gurobi - cum_profit_ortools_det) / cum_profit_ortools_det) * 100\n",
    "gap_ortools = (\n",
    "    (cum_profit_ortools - cum_profit_ortools_det) / cum_profit_ortools_det) * 100\n",
    "gap_ortools_det = (\n",
    "    (cum_profit_ortools_det - cum_profit_ortools_det) / cum_profit_ortools_det) * 100\n",
    "\n",
    "ortools_det_gap = {\n",
    "    'Algorithm':\n",
    "    ['DRL-MS',\n",
    "     'DRL',\n",
    "     'sQ',\n",
    "     'MS',\n",
    "     'EVPI',\n",
    "     'PI'],\n",
    "    'PI Gap':\n",
    "    [f\"{np.round(np.mean(gap_heuristic), 2)}\"\n",
    "     f\" +- {np.round(np.std(gap_heuristic), 2)}\",\n",
    "     f\"{np.round(np.mean(gap_PPO), 2)}\"\n",
    "     f\" +- {np.round(np.std(gap_PPO), 2)}\",\n",
    "     f\"{np.round(np.mean(gap_sQ), 2)}\"\n",
    "     f\" +- {np.round(np.std(gap_sQ), 2)}\",\n",
    "     f\"{np.round(np.mean(gap_gurobi), 2)}\"\n",
    "     f\" +- {np.round(np.std(gap_gurobi), 2)}\",\n",
    "     f\"{np.round(np.mean(gap_ortools), 2)}\"\n",
    "     f\" +- {np.round(np.std(gap_ortools), 2)}\",\n",
    "     f\"{np.round(np.mean(gap_ortools_det), 2)}\"\n",
    "     f\" +- {np.round(np.std(gap_ortools_det), 2)}\"]\n",
    "}\n",
    "# creating pandas DataFrame\n",
    "ortools_det_gap_df = pd.DataFrame(data=ortools_det_gap)\n",
    "ortools_det_gap_df.set_index('Algorithm', inplace=True)\n",
    "# saving pandas DataFrame as an image\n",
    "dfi.export(ortools_det_gap_df,\n",
    "           f\"{local_dir}/{plots_dir}\"\n",
    "           f\"/ortools_det_gap_df.png\",\n",
    "           table_conversion='matplotlib')\n",
    "# saving pandas DataFrame as LaTeX table\n",
    "f = open(f\"{local_dir}/{plots_dir}\"\n",
    "         f\"/ortools_det_gap_df.tex\",\n",
    "         'w', encoding='utf-8')\n",
    "f.write(ortools_det_gap_df.style.to_latex())\n",
    "f.close()\n",
    "# printing training time of all policies\n",
    "print(tabulate(ortools_det_gap_df, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.178309Z",
     "start_time": "2023-03-29T11:21:58.178287Z"
    }
   },
   "outputs": [],
   "source": [
    "def move_dir_plots(local_dir=local_dir, plots_dir=plots_dir):\n",
    "    \"\"\"\n",
    "    Move dirs whose name starts with 'BS_' (related to all optimizations) in\n",
    "    the main BS dir.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # creating necessary subdir and saving plot\n",
    "        if not os.path.exists(f\"{local_dir}/{plots_dir}/cum_profit\"):\n",
    "            os.makedirs(f\"{local_dir}/{plots_dir}/cum_profit\")\n",
    "        src_dir = f\"{local_dir}/{plots_dir}/\"\n",
    "        dst_dir = f\"{local_dir}/{plots_dir}/cum_profit\"\n",
    "\n",
    "        pattern = src_dir + \"['*\"\n",
    "        for file in glob.iglob(pattern, recursive=True):\n",
    "            shutil.move(file, dst_dir)\n",
    "            print('moved:', file)\n",
    "    except Exception as e:\n",
    "        print(f\"{e.__class__} occurred!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.180866Z",
     "start_time": "2023-03-29T11:21:58.180842Z"
    }
   },
   "outputs": [],
   "source": [
    "move_dir_plots()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "## Training Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training time of all policies\n",
    "times_training_total = {'Algorithm':\n",
    "               ['DRL-MS',\n",
    "                'DRL',\n",
    "                'sQ',\n",
    "                'MS',\n",
    "                'EVPI',\n",
    "                'PI'],\n",
    "               f\"Training Time\":\n",
    "                [f\"{time_PPO_total_training} (in minutes)\",\n",
    "                f\"{time_PPO_total_training} (in minutes)\",\n",
    "                f\"{time_sQ_total_training} (in minutes)\",\n",
    "                f\"-\",\n",
    "                f\"{time_ortools_total_training} (in seconds)\",\n",
    "                f\"-\"],\n",
    "               f\"Testing Time ({NUM_EPISODES} Episodes)\":\n",
    "                [f\"{time_heuristic_total_testing} (in seconds)\",\n",
    "                f\"{time_PPO_total_testing} (in seconds)\",\n",
    "                f\"{time_sQ_total_testing} (in seconds)\",\n",
    "                f\"{time_gurobi_total_training} (in seconds)\",\n",
    "                f\"{time_ortools_total_testing} (in seconds)\",\n",
    "                f\"{time_ortools_det_total_training} (in seconds)\"],\n",
    "               f\"Testing Time (Mean +- Std)\":\n",
    "                [f\"{time_heuristic_mean_testing} +- {time_heuristic_std_testing} (in seconds)\",\n",
    "                f\"{time_PPO_mean_testing} +- {time_PPO_std_testing} (in seconds)\",\n",
    "                f\"{time_sQ_mean_testing} +- {time_sQ_std_testing} (in seconds)\",\n",
    "                f\"{time_gurobi_mean_training} +- {time_gurobi_std_training} (in seconds)\",\n",
    "                f\"{time_ortools_mean_testing} +- {time_ortools_std_testing} (in seconds)\",\n",
    "                f\"{time_ortools_det_mean_training} +- {time_ortools_det_std_training} (in seconds)\"]}\n",
    "# creating pandas DataFrame\n",
    "times_training_total_df = pd.DataFrame(data=times_training_total)\n",
    "times_training_total_df.set_index('Algorithm', inplace=True)\n",
    "# saving pandas DataFrame as an image\n",
    "dfi.export(times_training_total_df,\n",
    "           f\"{local_dir}/{plots_dir}\"\n",
    "           f\"/times_training_total_df.png\",\n",
    "           table_conversion='matplotlib')\n",
    "# saving pandas DataFrame as LaTeX table\n",
    "f = open(f\"{local_dir}/{plots_dir}\"\n",
    "         f\"/times_training_total_df.tex\",\n",
    "         'w', encoding='utf-8')\n",
    "f.write(times_training_total_df.style.to_latex())\n",
    "f.close()\n",
    "# printing training time of all policies\n",
    "print(tabulate(times_training_total_df, headers='keys', tablefmt='grid'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true
   },
   "source": [
    "# Compress Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.192746Z",
     "start_time": "2023-03-29T11:21:58.192723Z"
    },
    "gather": {
     "logged": 1632127478541
    },
    "hideCode": true,
    "hidePrompt": true,
    "id": "YuI_ela_jsr9"
   },
   "outputs": [],
   "source": [
    "# creating a tar file containing plots and Ray results\n",
    "try:\n",
    "    cmd = f\"tar -zcvf {local_dir}.tar.gz ./{local_dir}\"\n",
    "    print(f\"cmd is {cmd}\")\n",
    "    os.system(cmd)\n",
    "except Exception as e:\n",
    "    print(f\"{e.__class__} occurred!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "id": "NkajbqUKc9wm"
   },
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.200071Z",
     "start_time": "2023-03-29T11:21:58.200045Z"
    },
    "gather": {
     "logged": 1630704118445
    }
   },
   "outputs": [],
   "source": [
    "# checking if PPO best checkpoint is defined\n",
    "try:\n",
    "    best_checkpoint_PPO\n",
    "except Exception as e:\n",
    "    print(f\"{e.__class__} occurred!\")\n",
    "    best_checkpoint_PPO = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.202000Z",
     "start_time": "2023-03-29T11:21:58.201978Z"
    },
    "gather": {
     "logged": 1630704118882
    }
   },
   "outputs": [],
   "source": [
    "# TensorBoard dir for Ray results (the first best checkpoint not None)\n",
    "tb_dir = next(checkpoint for checkpoint in [best_checkpoint_PPO]\n",
    "              if checkpoint is not None).rsplit('/', 4)[0]\n",
    "tb_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-29T11:21:58.203838Z",
     "start_time": "2023-03-29T11:21:58.203825Z"
    },
    "gather": {
     "logged": 1630704119654
    },
    "hideCode": true,
    "hidePrompt": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# loading TensorBoard\n",
    "try:\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir $tb_dir\n",
    "except Exception as e:\n",
    "    print(f\"{e.__class__} occurred!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MultiProduct_SupplyChain_V5_0.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "hide_code_all_hidden": true,
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "292px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "375px",
    "left": "1059px",
    "right": "20px",
    "top": "120px",
    "width": "361px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
